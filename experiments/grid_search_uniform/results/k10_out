2017-07-03 06:47:11
Finding best parameters for k = 10
=========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003084    	average train batch reward = 0.534
validation accuracy = 0.080		average validation NDCG = 0.664

epoch 2
average train loss = 0.004436    	average train batch reward = 0.535
validation accuracy = 0.079		average validation NDCG = 0.663

epoch 3
average train loss = -0.003687    	average train batch reward = 0.535
validation accuracy = 0.078		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.66358185317599649, -1, -1]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007366    	average train batch reward = 0.540
validation accuracy = 0.102		average validation NDCG = 0.670

epoch 2
average train loss = 0.002161    	average train batch reward = 0.539
validation accuracy = 0.101		average validation NDCG = 0.669

epoch 3
average train loss = 0.007504    	average train batch reward = 0.537
validation accuracy = 0.101		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), ()], which got scores of [0.66952960980153775, 0.66358185317599649, -1]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004257    	average train batch reward = 0.546
validation accuracy = 0.110		average validation NDCG = 0.670

epoch 2
average train loss = -0.003790    	average train batch reward = 0.546
validation accuracy = 0.110		average validation NDCG = 0.670

epoch 3
average train loss = 0.011321    	average train batch reward = 0.546
validation accuracy = 0.110		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 0.2), ()], which got scores of [0.66997460559879896, 0.66952960980153775, -1]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010262    	average train batch reward = 0.533
validation accuracy = 0.107		average validation NDCG = 0.667

epoch 2
average train loss = 0.001238    	average train batch reward = 0.534
validation accuracy = 0.107		average validation NDCG = 0.667

epoch 3
average train loss = -0.007124    	average train batch reward = 0.534
validation accuracy = 0.104		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.66997460559879896, 0.66952960980153775, 0.66673198128424271]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002520    	average train batch reward = 0.551
validation accuracy = 0.087		average validation NDCG = 0.680

epoch 2
average train loss = -0.002997    	average train batch reward = 0.551
validation accuracy = 0.085		average validation NDCG = 0.680

epoch 3
average train loss = 0.000675    	average train batch reward = 0.552
validation accuracy = 0.085		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.67999167228778812, 0.66997460559879896, 0.66673198128424271]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000274    	average train batch reward = 0.543
validation accuracy = 0.061		average validation NDCG = 0.675

epoch 2
average train loss = -0.013615    	average train batch reward = 0.544
validation accuracy = 0.061		average validation NDCG = 0.675

epoch 3
average train loss = -0.003581    	average train batch reward = 0.543
validation accuracy = 0.060		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.67999167228778812, 0.67531893611036509, 0.66997460559879896]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004736    	average train batch reward = 0.529
validation accuracy = 0.080		average validation NDCG = 0.663

epoch 2
average train loss = 0.010968    	average train batch reward = 0.528
validation accuracy = 0.080		average validation NDCG = 0.663

epoch 3
average train loss = 0.011847    	average train batch reward = 0.530
validation accuracy = 0.079		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.67999167228778812, 0.67531893611036509, 0.66997460559879896]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009391    	average train batch reward = 0.548
validation accuracy = 0.085		average validation NDCG = 0.681

epoch 2
average train loss = -0.003186    	average train batch reward = 0.547
validation accuracy = 0.083		average validation NDCG = 0.681

epoch 3
average train loss = 0.006317    	average train batch reward = 0.548
validation accuracy = 0.084		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.68112602091093455, 0.67999167228778812, 0.66997460559879896]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015178    	average train batch reward = 0.562
validation accuracy = 0.112		average validation NDCG = 0.692

epoch 2
average train loss = 0.021172    	average train batch reward = 0.561
validation accuracy = 0.112		average validation NDCG = 0.692

epoch 3
average train loss = 0.040110    	average train batch reward = 0.563
validation accuracy = 0.112		average validation NDCG = 0.692

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 0.5), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.69249781970903013, 0.68112602091093455, 0.66997460559879896]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002791    	average train batch reward = 0.534
validation accuracy = 0.091		average validation NDCG = 0.670

epoch 2
average train loss = -0.015617    	average train batch reward = 0.534
validation accuracy = 0.090		average validation NDCG = 0.670

epoch 3
average train loss = -0.022388    	average train batch reward = 0.532
validation accuracy = 0.090		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 0.5), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.69249781970903013, 0.68112602091093455, 0.66997460559879896]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.022794    	average train batch reward = 0.542
validation accuracy = 0.093		average validation NDCG = 0.682

epoch 2
average train loss = 0.045012    	average train batch reward = 0.542
validation accuracy = 0.092		average validation NDCG = 0.682

epoch 3
average train loss = -0.022066    	average train batch reward = 0.543
validation accuracy = 0.092		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.0), (9.9999999999999995e-07, 0.25, 0.5)], which got scores of [0.69249781970903013, 0.68202913760427342, 0.68112602091093455]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003366    	average train batch reward = 0.546
validation accuracy = 0.108		average validation NDCG = 0.685

epoch 2
average train loss = -0.076654    	average train batch reward = 0.546
validation accuracy = 0.107		average validation NDCG = 0.685

epoch 3
average train loss = 0.104036    	average train batch reward = 0.545
validation accuracy = 0.107		average validation NDCG = 0.685

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68202913760427342]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.084788    	average train batch reward = 0.540
validation accuracy = 0.080		average validation NDCG = 0.671

epoch 2
average train loss = -0.024761    	average train batch reward = 0.542
validation accuracy = 0.079		average validation NDCG = 0.670

epoch 3
average train loss = 0.057000    	average train batch reward = 0.541
validation accuracy = 0.079		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68202913760427342]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.201819    	average train batch reward = 0.525
validation accuracy = 0.075		average validation NDCG = 0.646

epoch 2
average train loss = -0.205073    	average train batch reward = 0.527
validation accuracy = 0.075		average validation NDCG = 0.646

epoch 3
average train loss = 0.019190    	average train batch reward = 0.527
validation accuracy = 0.075		average validation NDCG = 0.646

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68202913760427342]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.168765    	average train batch reward = 0.531
validation accuracy = 0.111		average validation NDCG = 0.666

epoch 2
average train loss = -0.205133    	average train batch reward = 0.532
validation accuracy = 0.111		average validation NDCG = 0.666

epoch 3
average train loss = 0.213893    	average train batch reward = 0.533
validation accuracy = 0.111		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68202913760427342]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 7.288743    	average train batch reward = 0.542
validation accuracy = 0.101		average validation NDCG = 0.679

epoch 2
average train loss = 0.410799    	average train batch reward = 0.543
validation accuracy = 0.100		average validation NDCG = 0.679

epoch 3
average train loss = 0.026934    	average train batch reward = 0.544
validation accuracy = 0.100		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68202913760427342]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 3.103272    	average train batch reward = 0.545
validation accuracy = 0.144		average validation NDCG = 0.683

epoch 2
average train loss = 1.743183    	average train batch reward = 0.543
validation accuracy = 0.144		average validation NDCG = 0.683

epoch 3
average train loss = 0.930266    	average train batch reward = 0.544
validation accuracy = 0.144		average validation NDCG = 0.683

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68309290825369862]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.186911    	average train batch reward = 0.538
validation accuracy = 0.097		average validation NDCG = 0.660

epoch 2
average train loss = -3.736856    	average train batch reward = 0.538
validation accuracy = 0.097		average validation NDCG = 0.660

epoch 3
average train loss = -1.403690    	average train batch reward = 0.538
validation accuracy = 0.097		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68309290825369862]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.174375    	average train batch reward = 0.534
validation accuracy = 0.074		average validation NDCG = 0.654

epoch 2
average train loss = -2.275630    	average train batch reward = 0.535
validation accuracy = 0.074		average validation NDCG = 0.654

epoch 3
average train loss = -1.561168    	average train batch reward = 0.535
validation accuracy = 0.074		average validation NDCG = 0.654

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.5, 0.2), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.69249781970903013, 0.68495836646106512, 0.68309290825369862]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 3.867185    	average train batch reward = 0.551
validation accuracy = 0.147		average validation NDCG = 0.706

epoch 2
average train loss = 3.041881    	average train batch reward = 0.552
validation accuracy = 0.148		average validation NDCG = 0.706

epoch 3
average train loss = 4.037433    	average train batch reward = 0.552
validation accuracy = 0.147		average validation NDCG = 0.706

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68309290825369862]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003019    	average train batch reward = 0.556
validation accuracy = 0.135		average validation NDCG = 0.676

epoch 2
average train loss = 0.003104    	average train batch reward = 0.552
validation accuracy = 0.133		average validation NDCG = 0.672

epoch 3
average train loss = 0.001346    	average train batch reward = 0.547
validation accuracy = 0.125		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68309290825369862]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001130    	average train batch reward = 0.551
validation accuracy = 0.092		average validation NDCG = 0.687

epoch 2
average train loss = -0.006368    	average train batch reward = 0.552
validation accuracy = 0.090		average validation NDCG = 0.686

epoch 3
average train loss = -0.011345    	average train batch reward = 0.549
validation accuracy = 0.084		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009454    	average train batch reward = 0.506
validation accuracy = 0.091		average validation NDCG = 0.643

epoch 2
average train loss = -0.008594    	average train batch reward = 0.508
validation accuracy = 0.090		average validation NDCG = 0.642

epoch 3
average train loss = -0.008849    	average train batch reward = 0.506
validation accuracy = 0.091		average validation NDCG = 0.642

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001275    	average train batch reward = 0.515
validation accuracy = 0.083		average validation NDCG = 0.651

epoch 2
average train loss = 0.002102    	average train batch reward = 0.513
validation accuracy = 0.077		average validation NDCG = 0.650

epoch 3
average train loss = -0.003430    	average train batch reward = 0.512
validation accuracy = 0.077		average validation NDCG = 0.649

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003165    	average train batch reward = 0.512
validation accuracy = 0.060		average validation NDCG = 0.655

epoch 2
average train loss = -0.005241    	average train batch reward = 0.513
validation accuracy = 0.058		average validation NDCG = 0.654

epoch 3
average train loss = -0.007766    	average train batch reward = 0.510
validation accuracy = 0.056		average validation NDCG = 0.653

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.024108    	average train batch reward = 0.527
validation accuracy = 0.090		average validation NDCG = 0.668

epoch 2
average train loss = -0.025447    	average train batch reward = 0.529
validation accuracy = 0.092		average validation NDCG = 0.667

epoch 3
average train loss = -0.038401    	average train batch reward = 0.528
validation accuracy = 0.092		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.014408    	average train batch reward = 0.546
validation accuracy = 0.124		average validation NDCG = 0.677

epoch 2
average train loss = -0.006010    	average train batch reward = 0.545
validation accuracy = 0.123		average validation NDCG = 0.677

epoch 3
average train loss = 0.001992    	average train batch reward = 0.543
validation accuracy = 0.116		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009986    	average train batch reward = 0.522
validation accuracy = 0.084		average validation NDCG = 0.657

epoch 2
average train loss = -0.001127    	average train batch reward = 0.522
validation accuracy = 0.083		average validation NDCG = 0.654

epoch 3
average train loss = -0.033875    	average train batch reward = 0.521
validation accuracy = 0.082		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005452    	average train batch reward = 0.529
validation accuracy = 0.077		average validation NDCG = 0.665

epoch 2
average train loss = -0.015147    	average train batch reward = 0.528
validation accuracy = 0.073		average validation NDCG = 0.663

epoch 3
average train loss = 0.001249    	average train batch reward = 0.527
validation accuracy = 0.072		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002541    	average train batch reward = 0.544
validation accuracy = 0.145		average validation NDCG = 0.680

epoch 2
average train loss = 0.018413    	average train batch reward = 0.542
validation accuracy = 0.134		average validation NDCG = 0.675

epoch 3
average train loss = -0.013688    	average train batch reward = 0.543
validation accuracy = 0.125		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68658417524078241]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.107244    	average train batch reward = 0.548
validation accuracy = 0.113		average validation NDCG = 0.687

epoch 2
average train loss = 0.058261    	average train batch reward = 0.550
validation accuracy = 0.114		average validation NDCG = 0.688

epoch 3
average train loss = 0.059074    	average train batch reward = 0.550
validation accuracy = 0.110		average validation NDCG = 0.687

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 0.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68795628957221455]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.105372    	average train batch reward = 0.543
validation accuracy = 0.110		average validation NDCG = 0.679

epoch 2
average train loss = 0.051560    	average train batch reward = 0.544
validation accuracy = 0.103		average validation NDCG = 0.677

epoch 3
average train loss = -0.034913    	average train batch reward = 0.542
validation accuracy = 0.106		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 0.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68795628957221455]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.039758    	average train batch reward = 0.532
validation accuracy = 0.092		average validation NDCG = 0.663

epoch 2
average train loss = 0.040617    	average train batch reward = 0.531
validation accuracy = 0.091		average validation NDCG = 0.662

epoch 3
average train loss = -0.098080    	average train batch reward = 0.533
validation accuracy = 0.091		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 0.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.68795628957221455]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.054539    	average train batch reward = 0.552
validation accuracy = 0.077		average validation NDCG = 0.692

epoch 2
average train loss = -0.043094    	average train batch reward = 0.552
validation accuracy = 0.072		average validation NDCG = 0.691

epoch 3
average train loss = -0.016290    	average train batch reward = 0.551
validation accuracy = 0.068		average validation NDCG = 0.688

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004179    	average train batch reward = 0.545
validation accuracy = 0.089		average validation NDCG = 0.681

epoch 2
average train loss = -0.027984    	average train batch reward = 0.547
validation accuracy = 0.090		average validation NDCG = 0.681

epoch 3
average train loss = -0.004940    	average train batch reward = 0.545
validation accuracy = 0.088		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 2.186693    	average train batch reward = 0.537
validation accuracy = 0.088		average validation NDCG = 0.664

epoch 2
average train loss = 1.172743    	average train batch reward = 0.536
validation accuracy = 0.086		average validation NDCG = 0.663

epoch 3
average train loss = -2.769727    	average train batch reward = 0.538
validation accuracy = 0.083		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.872341    	average train batch reward = 0.541
validation accuracy = 0.107		average validation NDCG = 0.681

epoch 2
average train loss = 1.844351    	average train batch reward = 0.542
validation accuracy = 0.105		average validation NDCG = 0.681

epoch 3
average train loss = -1.952845    	average train batch reward = 0.543
validation accuracy = 0.106		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.825522    	average train batch reward = 0.539
validation accuracy = 0.054		average validation NDCG = 0.665

epoch 2
average train loss = -3.625227    	average train batch reward = 0.539
validation accuracy = 0.056		average validation NDCG = 0.666

epoch 3
average train loss = -3.486440    	average train batch reward = 0.538
validation accuracy = 0.056		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.810365    	average train batch reward = 0.536
validation accuracy = 0.097		average validation NDCG = 0.658

epoch 2
average train loss = -1.905473    	average train batch reward = 0.535
validation accuracy = 0.095		average validation NDCG = 0.657

epoch 3
average train loss = -3.868720    	average train batch reward = 0.535
validation accuracy = 0.097		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 3.668084    	average train batch reward = 0.543
validation accuracy = 0.112		average validation NDCG = 0.675

epoch 2
average train loss = 2.037930    	average train batch reward = 0.541
validation accuracy = 0.111		average validation NDCG = 0.675

epoch 3
average train loss = -0.249654    	average train batch reward = 0.543
validation accuracy = 0.109		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.008478    	average train batch reward = 0.530
validation accuracy = 0.076		average validation NDCG = 0.659

epoch 2
average train loss = -0.016193    	average train batch reward = 0.520
validation accuracy = 0.058		average validation NDCG = 0.661

epoch 3
average train loss = -0.013612    	average train batch reward = 0.518
validation accuracy = 0.028		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005863    	average train batch reward = 0.525
validation accuracy = 0.056		average validation NDCG = 0.644

epoch 2
average train loss = -0.011183    	average train batch reward = 0.510
validation accuracy = 0.047		average validation NDCG = 0.640

epoch 3
average train loss = -0.012166    	average train batch reward = 0.506
validation accuracy = 0.051		average validation NDCG = 0.640

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010031    	average train batch reward = 0.526
validation accuracy = 0.042		average validation NDCG = 0.662

epoch 2
average train loss = -0.008267    	average train batch reward = 0.533
validation accuracy = 0.033		average validation NDCG = 0.674

epoch 3
average train loss = -0.023465    	average train batch reward = 0.528
validation accuracy = 0.028		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001895    	average train batch reward = 0.528
validation accuracy = 0.059		average validation NDCG = 0.657

epoch 2
average train loss = -0.008645    	average train batch reward = 0.517
validation accuracy = 0.037		average validation NDCG = 0.652

epoch 3
average train loss = -0.011387    	average train batch reward = 0.516
validation accuracy = 0.033		average validation NDCG = 0.647

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014358    	average train batch reward = 0.509
validation accuracy = 0.022		average validation NDCG = 0.650

epoch 2
average train loss = -0.023335    	average train batch reward = 0.505
validation accuracy = 0.020		average validation NDCG = 0.650

epoch 3
average train loss = -0.016501    	average train batch reward = 0.511
validation accuracy = 0.025		average validation NDCG = 0.650

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.025005    	average train batch reward = 0.521
validation accuracy = 0.064		average validation NDCG = 0.643

epoch 2
average train loss = -0.039856    	average train batch reward = 0.505
validation accuracy = 0.064		average validation NDCG = 0.644

epoch 3
average train loss = -0.035142    	average train batch reward = 0.505
validation accuracy = 0.043		average validation NDCG = 0.637

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.039062    	average train batch reward = 0.516
validation accuracy = 0.061		average validation NDCG = 0.644

epoch 2
average train loss = -0.019880    	average train batch reward = 0.503
validation accuracy = 0.039		average validation NDCG = 0.633

epoch 3
average train loss = -0.035118    	average train batch reward = 0.501
validation accuracy = 0.037		average validation NDCG = 0.628

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.014082    	average train batch reward = 0.541
validation accuracy = 0.102		average validation NDCG = 0.668

epoch 2
average train loss = -0.021666    	average train batch reward = 0.536
validation accuracy = 0.078		average validation NDCG = 0.664

epoch 3
average train loss = -0.006917    	average train batch reward = 0.528
validation accuracy = 0.045		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000386    	average train batch reward = 0.531
validation accuracy = 0.056		average validation NDCG = 0.657

epoch 2
average train loss = -0.001216    	average train batch reward = 0.529
validation accuracy = 0.056		average validation NDCG = 0.660

epoch 3
average train loss = -0.018521    	average train batch reward = 0.528
validation accuracy = 0.049		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015950    	average train batch reward = 0.511
validation accuracy = 0.106		average validation NDCG = 0.642

epoch 2
average train loss = -0.023323    	average train batch reward = 0.508
validation accuracy = 0.040		average validation NDCG = 0.641

epoch 3
average train loss = -0.031505    	average train batch reward = 0.504
validation accuracy = 0.036		average validation NDCG = 0.635

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.051559    	average train batch reward = 0.534
validation accuracy = 0.043		average validation NDCG = 0.661

epoch 2
average train loss = -0.212625    	average train batch reward = 0.529
validation accuracy = 0.041		average validation NDCG = 0.659

epoch 3
average train loss = -0.050286    	average train batch reward = 0.531
validation accuracy = 0.061		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.071363    	average train batch reward = 0.531
validation accuracy = 0.089		average validation NDCG = 0.655

epoch 2
average train loss = -0.169133    	average train batch reward = 0.528
validation accuracy = 0.094		average validation NDCG = 0.649

epoch 3
average train loss = -0.148254    	average train batch reward = 0.527
validation accuracy = 0.093		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.142358    	average train batch reward = 0.534
validation accuracy = 0.074		average validation NDCG = 0.654

epoch 2
average train loss = -0.105329    	average train batch reward = 0.528
validation accuracy = 0.080		average validation NDCG = 0.653

epoch 3
average train loss = -0.286711    	average train batch reward = 0.523
validation accuracy = 0.073		average validation NDCG = 0.647

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.028028    	average train batch reward = 0.539
validation accuracy = 0.093		average validation NDCG = 0.660

epoch 2
average train loss = -0.217294    	average train batch reward = 0.530
validation accuracy = 0.081		average validation NDCG = 0.651

epoch 3
average train loss = -0.158516    	average train batch reward = 0.527
validation accuracy = 0.075		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.313744    	average train batch reward = 0.524
validation accuracy = 0.046		average validation NDCG = 0.646

epoch 2
average train loss = -0.232820    	average train batch reward = 0.519
validation accuracy = 0.033		average validation NDCG = 0.640

epoch 3
average train loss = -0.419219    	average train batch reward = 0.514
validation accuracy = 0.019		average validation NDCG = 0.630

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.833741    	average train batch reward = 0.538
validation accuracy = 0.070		average validation NDCG = 0.670

epoch 2
average train loss = -2.261516    	average train batch reward = 0.542
validation accuracy = 0.069		average validation NDCG = 0.681

epoch 3
average train loss = 4.131318    	average train batch reward = 0.544
validation accuracy = 0.074		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.018970    	average train batch reward = 0.539
validation accuracy = 0.066		average validation NDCG = 0.661

epoch 2
average train loss = 1.414231    	average train batch reward = 0.537
validation accuracy = 0.078		average validation NDCG = 0.670

epoch 3
average train loss = -1.053069    	average train batch reward = 0.539
validation accuracy = 0.059		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.897860    	average train batch reward = 0.544
validation accuracy = 0.121		average validation NDCG = 0.672

epoch 2
average train loss = -2.264738    	average train batch reward = 0.542
validation accuracy = 0.109		average validation NDCG = 0.670

epoch 3
average train loss = 1.884757    	average train batch reward = 0.542
validation accuracy = 0.123		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6.298079    	average train batch reward = 0.542
validation accuracy = 0.091		average validation NDCG = 0.677

epoch 2
average train loss = 0.308521    	average train batch reward = 0.542
validation accuracy = 0.113		average validation NDCG = 0.679

epoch 3
average train loss = 2.133111    	average train batch reward = 0.542
validation accuracy = 0.114		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 7.030582    	average train batch reward = 0.542
validation accuracy = 0.084		average validation NDCG = 0.671

epoch 2
average train loss = -3.821709    	average train batch reward = 0.538
validation accuracy = 0.075		average validation NDCG = 0.659

epoch 3
average train loss = 1.571985    	average train batch reward = 0.537
validation accuracy = 0.083		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010343    	average train batch reward = 0.522
validation accuracy = 0.064		average validation NDCG = 0.650

epoch 2
average train loss = -0.030963    	average train batch reward = 0.515
validation accuracy = 0.013		average validation NDCG = 0.645

epoch 3
average train loss = -0.006733    	average train batch reward = 0.516
validation accuracy = 0.008		average validation NDCG = 0.644

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011590    	average train batch reward = 0.497
validation accuracy = 0.016		average validation NDCG = 0.637

epoch 2
average train loss = -0.004983    	average train batch reward = 0.500
validation accuracy = 0.026		average validation NDCG = 0.629

epoch 3
average train loss = -0.008711    	average train batch reward = 0.504
validation accuracy = 0.019		average validation NDCG = 0.647

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.013058    	average train batch reward = 0.520
validation accuracy = 0.046		average validation NDCG = 0.649

epoch 2
average train loss = -0.017086    	average train batch reward = 0.511
validation accuracy = 0.109		average validation NDCG = 0.640

epoch 3
average train loss = -0.000786    	average train batch reward = 0.511
validation accuracy = 0.084		average validation NDCG = 0.645

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009620    	average train batch reward = 0.500
validation accuracy = 0.023		average validation NDCG = 0.628

epoch 2
average train loss = -0.034017    	average train batch reward = 0.491
validation accuracy = 0.009		average validation NDCG = 0.625

epoch 3
average train loss = -0.012081    	average train batch reward = 0.490
validation accuracy = 0.061		average validation NDCG = 0.622

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014418    	average train batch reward = 0.524
validation accuracy = 0.076		average validation NDCG = 0.646

epoch 2
average train loss = 0.000477    	average train batch reward = 0.511
validation accuracy = 0.033		average validation NDCG = 0.636

epoch 3
average train loss = -0.023870    	average train batch reward = 0.503
validation accuracy = 0.018		average validation NDCG = 0.634

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.027590    	average train batch reward = 0.524
validation accuracy = 0.161		average validation NDCG = 0.670

epoch 2
average train loss = 0.043532    	average train batch reward = 0.529
validation accuracy = 0.107		average validation NDCG = 0.644

epoch 3
average train loss = -0.057682    	average train batch reward = 0.516
validation accuracy = 0.047		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001835    	average train batch reward = 0.540
validation accuracy = 0.018		average validation NDCG = 0.660

epoch 2
average train loss = -0.029042    	average train batch reward = 0.530
validation accuracy = 0.010		average validation NDCG = 0.673

epoch 3
average train loss = 0.026143    	average train batch reward = 0.536
validation accuracy = 0.022		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.041139    	average train batch reward = 0.526
validation accuracy = 0.049		average validation NDCG = 0.650

epoch 2
average train loss = -0.042868    	average train batch reward = 0.526
validation accuracy = 0.061		average validation NDCG = 0.649

epoch 3
average train loss = -0.047305    	average train batch reward = 0.520
validation accuracy = 0.053		average validation NDCG = 0.646

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013206    	average train batch reward = 0.538
validation accuracy = 0.054		average validation NDCG = 0.655

epoch 2
average train loss = -0.011117    	average train batch reward = 0.530
validation accuracy = 0.010		average validation NDCG = 0.660

epoch 3
average train loss = -0.004818    	average train batch reward = 0.524
validation accuracy = 0.022		average validation NDCG = 0.650

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.008222    	average train batch reward = 0.526
validation accuracy = 0.045		average validation NDCG = 0.646

epoch 2
average train loss = -0.094635    	average train batch reward = 0.516
validation accuracy = 0.050		average validation NDCG = 0.632

epoch 3
average train loss = -0.042175    	average train batch reward = 0.512
validation accuracy = 0.021		average validation NDCG = 0.635

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.128952    	average train batch reward = 0.528
validation accuracy = 0.011		average validation NDCG = 0.646

epoch 2
average train loss = -0.297083    	average train batch reward = 0.529
validation accuracy = 0.060		average validation NDCG = 0.650

epoch 3
average train loss = -0.521025    	average train batch reward = 0.527
validation accuracy = 0.013		average validation NDCG = 0.638

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.330501    	average train batch reward = 0.541
validation accuracy = 0.109		average validation NDCG = 0.686

epoch 2
average train loss = -0.110754    	average train batch reward = 0.547
validation accuracy = 0.134		average validation NDCG = 0.681

epoch 3
average train loss = -0.157439    	average train batch reward = 0.542
validation accuracy = 0.106		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.049540    	average train batch reward = 0.542
validation accuracy = 0.085		average validation NDCG = 0.664

epoch 2
average train loss = -0.339104    	average train batch reward = 0.534
validation accuracy = 0.072		average validation NDCG = 0.649

epoch 3
average train loss = -0.182975    	average train batch reward = 0.525
validation accuracy = 0.086		average validation NDCG = 0.648

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002107    	average train batch reward = 0.533
validation accuracy = 0.045		average validation NDCG = 0.651

epoch 2
average train loss = -0.153327    	average train batch reward = 0.531
validation accuracy = 0.025		average validation NDCG = 0.651

epoch 3
average train loss = -0.358512    	average train batch reward = 0.531
validation accuracy = 0.038		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.143198    	average train batch reward = 0.533
validation accuracy = 0.058		average validation NDCG = 0.665

epoch 2
average train loss = 0.080923    	average train batch reward = 0.539
validation accuracy = 0.123		average validation NDCG = 0.667

epoch 3
average train loss = -0.148700    	average train batch reward = 0.544
validation accuracy = 0.160		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.811086    	average train batch reward = 0.535
validation accuracy = 0.038		average validation NDCG = 0.653

epoch 2
average train loss = -11.558991    	average train batch reward = 0.534
validation accuracy = 0.025		average validation NDCG = 0.639

epoch 3
average train loss = -9.289768    	average train batch reward = 0.534
validation accuracy = 0.093		average validation NDCG = 0.641

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 4.745820    	average train batch reward = 0.541
validation accuracy = 0.067		average validation NDCG = 0.680

epoch 2
average train loss = 6.206093    	average train batch reward = 0.538
validation accuracy = 0.099		average validation NDCG = 0.665

epoch 3
average train loss = 0.950479    	average train batch reward = 0.538
validation accuracy = 0.098		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7.342525    	average train batch reward = 0.535
validation accuracy = 0.076		average validation NDCG = 0.651

epoch 2
average train loss = -12.342317    	average train batch reward = 0.533
validation accuracy = 0.060		average validation NDCG = 0.644

epoch 3
average train loss = 2.855491    	average train batch reward = 0.533
validation accuracy = 0.032		average validation NDCG = 0.639

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7.080131    	average train batch reward = 0.532
validation accuracy = 0.022		average validation NDCG = 0.644

epoch 2
average train loss = -1.615651    	average train batch reward = 0.534
validation accuracy = 0.051		average validation NDCG = 0.641

epoch 3
average train loss = -18.305996    	average train batch reward = 0.534
validation accuracy = 0.090		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 5.245744    	average train batch reward = 0.538
validation accuracy = 0.130		average validation NDCG = 0.673

epoch 2
average train loss = -9.901511    	average train batch reward = 0.538
validation accuracy = 0.097		average validation NDCG = 0.665

epoch 3
average train loss = 2.988329    	average train batch reward = 0.536
validation accuracy = 0.085		average validation NDCG = 0.654

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.073429    	average train batch reward = 0.539
validation accuracy = 0.092		average validation NDCG = 0.684

epoch 2
average train loss = -0.060304    	average train batch reward = 0.545
validation accuracy = 0.162		average validation NDCG = 0.669

epoch 3
average train loss = 0.005365    	average train batch reward = 0.530
validation accuracy = 0.142		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.25, 1.0), (1.0000000000000001e-05, 0.5, 1.0)], which got scores of [0.70593634593854593, 0.69249781970903013, 0.69227093570020315]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.033112    	average train batch reward = 0.533
validation accuracy = 0.070		average validation NDCG = 0.671

epoch 2
average train loss = 0.007798    	average train batch reward = 0.548
validation accuracy = 0.096		average validation NDCG = 0.687

epoch 3
average train loss = -0.040958    	average train batch reward = 0.553
validation accuracy = 0.096		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 0.2), (9.9999999999999995e-07, 0.25, 1.0)], which got scores of [0.70593634593854593, 0.69258674144670318, 0.69249781970903013]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001408    	average train batch reward = 0.511
validation accuracy = 0.093		average validation NDCG = 0.643

epoch 2
average train loss = -0.063934    	average train batch reward = 0.513
validation accuracy = 0.136		average validation NDCG = 0.651

epoch 3
average train loss = -0.000064    	average train batch reward = 0.515
validation accuracy = 0.075		average validation NDCG = 0.653

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 0.2), (9.9999999999999995e-07, 0.25, 1.0)], which got scores of [0.70593634593854593, 0.69258674144670318, 0.69249781970903013]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.008719    	average train batch reward = 0.542
validation accuracy = 0.073		average validation NDCG = 0.693

epoch 2
average train loss = -0.018786    	average train batch reward = 0.539
validation accuracy = 0.086		average validation NDCG = 0.666

epoch 3
average train loss = 0.032842    	average train batch reward = 0.531
validation accuracy = 0.023		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014525    	average train batch reward = 0.530
validation accuracy = 0.071		average validation NDCG = 0.658

epoch 2
average train loss = 0.008286    	average train batch reward = 0.535
validation accuracy = 0.066		average validation NDCG = 0.668

epoch 3
average train loss = 0.066257    	average train batch reward = 0.533
validation accuracy = 0.046		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.064654    	average train batch reward = 0.527
validation accuracy = 0.118		average validation NDCG = 0.658

epoch 2
average train loss = -0.013044    	average train batch reward = 0.528
validation accuracy = 0.056		average validation NDCG = 0.646

epoch 3
average train loss = -0.090778    	average train batch reward = 0.523
validation accuracy = 0.064		average validation NDCG = 0.652

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.051096    	average train batch reward = 0.541
validation accuracy = 0.099		average validation NDCG = 0.685

epoch 2
average train loss = 0.137909    	average train batch reward = 0.545
validation accuracy = 0.103		average validation NDCG = 0.667

epoch 3
average train loss = -0.005773    	average train batch reward = 0.537
validation accuracy = 0.114		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017757    	average train batch reward = 0.532
validation accuracy = 0.119		average validation NDCG = 0.657

epoch 2
average train loss = -0.054858    	average train batch reward = 0.527
validation accuracy = 0.083		average validation NDCG = 0.651

epoch 3
average train loss = -0.021225    	average train batch reward = 0.522
validation accuracy = 0.076		average validation NDCG = 0.650

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.019852    	average train batch reward = 0.530
validation accuracy = 0.088		average validation NDCG = 0.658

epoch 2
average train loss = 0.075484    	average train batch reward = 0.528
validation accuracy = 0.043		average validation NDCG = 0.652

epoch 3
average train loss = 0.019147    	average train batch reward = 0.521
validation accuracy = 0.079		average validation NDCG = 0.653

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.064846    	average train batch reward = 0.528
validation accuracy = 0.098		average validation NDCG = 0.661

epoch 2
average train loss = -0.067502    	average train batch reward = 0.533
validation accuracy = 0.113		average validation NDCG = 0.664

epoch 3
average train loss = 0.157803    	average train batch reward = 0.540
validation accuracy = 0.109		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.693799    	average train batch reward = 0.534
validation accuracy = 0.113		average validation NDCG = 0.664

epoch 2
average train loss = -0.092804    	average train batch reward = 0.536
validation accuracy = 0.083		average validation NDCG = 0.665

epoch 3
average train loss = -1.208109    	average train batch reward = 0.536
validation accuracy = 0.105		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.477085    	average train batch reward = 0.533
validation accuracy = 0.083		average validation NDCG = 0.651

epoch 2
average train loss = -0.019545    	average train batch reward = 0.533
validation accuracy = 0.086		average validation NDCG = 0.657

epoch 3
average train loss = -0.111991    	average train batch reward = 0.540
validation accuracy = 0.073		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.814136    	average train batch reward = 0.537
validation accuracy = 0.057		average validation NDCG = 0.673

epoch 2
average train loss = 1.736963    	average train batch reward = 0.534
validation accuracy = 0.025		average validation NDCG = 0.663

epoch 3
average train loss = 1.538817    	average train batch reward = 0.538
validation accuracy = 0.092		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.281930    	average train batch reward = 0.533
validation accuracy = 0.100		average validation NDCG = 0.652

epoch 2
average train loss = -0.363550    	average train batch reward = 0.528
validation accuracy = 0.107		average validation NDCG = 0.650

epoch 3
average train loss = -4.034621    	average train batch reward = 0.528
validation accuracy = 0.056		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.313781    	average train batch reward = 0.544
validation accuracy = 0.107		average validation NDCG = 0.680

epoch 2
average train loss = -0.131121    	average train batch reward = 0.542
validation accuracy = 0.095		average validation NDCG = 0.677

epoch 3
average train loss = 0.207133    	average train batch reward = 0.538
validation accuracy = 0.098		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 24.826834    	average train batch reward = 0.539
validation accuracy = 0.112		average validation NDCG = 0.669

epoch 2
average train loss = 54.868847    	average train batch reward = 0.539
validation accuracy = 0.083		average validation NDCG = 0.691

epoch 3
average train loss = 20.895281    	average train batch reward = 0.542
validation accuracy = 0.157		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6.009713    	average train batch reward = 0.539
validation accuracy = 0.109		average validation NDCG = 0.670

epoch 2
average train loss = 21.997990    	average train batch reward = 0.539
validation accuracy = 0.107		average validation NDCG = 0.671

epoch 3
average train loss = 11.667003    	average train batch reward = 0.540
validation accuracy = 0.096		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 32.678406    	average train batch reward = 0.541
validation accuracy = 0.086		average validation NDCG = 0.668

epoch 2
average train loss = -4.490551    	average train batch reward = 0.542
validation accuracy = 0.105		average validation NDCG = 0.684

epoch 3
average train loss = 61.427811    	average train batch reward = 0.544
validation accuracy = 0.087		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 20.466581    	average train batch reward = 0.540
validation accuracy = 0.069		average validation NDCG = 0.669

epoch 2
average train loss = 13.952278    	average train batch reward = 0.541
validation accuracy = 0.093		average validation NDCG = 0.681

epoch 3
average train loss = 3.620019    	average train batch reward = 0.541
validation accuracy = 0.092		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 22.241096    	average train batch reward = 0.537
validation accuracy = 0.056		average validation NDCG = 0.657

epoch 2
average train loss = -6.879028    	average train batch reward = 0.537
validation accuracy = 0.081		average validation NDCG = 0.657

epoch 3
average train loss = -10.299352    	average train batch reward = 0.537
validation accuracy = 0.106		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.038442    	average train batch reward = 0.539
validation accuracy = 0.092		average validation NDCG = 0.675

epoch 2
average train loss = 0.000000    	average train batch reward = 0.543
validation accuracy = 0.092		average validation NDCG = 0.675

epoch 3
average train loss = 0.000000    	average train batch reward = 0.545
validation accuracy = 0.092		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000519    	average train batch reward = 0.529
validation accuracy = 0.113		average validation NDCG = 0.663

epoch 2
average train loss = 0.000005    	average train batch reward = 0.538
validation accuracy = 0.086		average validation NDCG = 0.674

epoch 3
average train loss = -0.000000    	average train batch reward = 0.545
validation accuracy = 0.086		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011893    	average train batch reward = 0.528
validation accuracy = 0.118		average validation NDCG = 0.655

epoch 2
average train loss = -0.222877    	average train batch reward = 0.529
validation accuracy = 0.099		average validation NDCG = 0.658

epoch 3
average train loss = -0.000000    	average train batch reward = 0.528
validation accuracy = 0.099		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009795    	average train batch reward = 0.533
validation accuracy = 0.176		average validation NDCG = 0.672

epoch 2
average train loss = 0.000000    	average train batch reward = 0.535
validation accuracy = 0.161		average validation NDCG = 0.671

epoch 3
average train loss = 0.221212    	average train batch reward = 0.535
validation accuracy = 0.188		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.018982    	average train batch reward = 0.538
validation accuracy = 0.084		average validation NDCG = 0.667

epoch 2
average train loss = -0.120027    	average train batch reward = 0.535
validation accuracy = 0.138		average validation NDCG = 0.667

epoch 3
average train loss = 3.844790    	average train batch reward = 0.534
validation accuracy = 0.107		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.142871    	average train batch reward = 0.540
validation accuracy = 0.108		average validation NDCG = 0.683

epoch 2
average train loss = 0.225482    	average train batch reward = 0.542
validation accuracy = 0.129		average validation NDCG = 0.673

epoch 3
average train loss = 0.000000    	average train batch reward = 0.542
validation accuracy = 0.129		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.033618    	average train batch reward = 0.550
validation accuracy = 0.183		average validation NDCG = 0.690

epoch 2
average train loss = -0.000001    	average train batch reward = 0.554
validation accuracy = 0.183		average validation NDCG = 0.689

epoch 3
average train loss = 0.000005    	average train batch reward = 0.553
validation accuracy = 0.183		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.263382    	average train batch reward = 0.544
validation accuracy = 0.109		average validation NDCG = 0.670

epoch 2
average train loss = 0.003703    	average train batch reward = 0.536
validation accuracy = 0.110		average validation NDCG = 0.659

epoch 3
average train loss = -0.000000    	average train batch reward = 0.531
validation accuracy = 0.110		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.01, 0.1, 1.0), (0.01, 0.1, 0.2)], which got scores of [0.70593634593854593, 0.69261287704039676, 0.69258674144670318]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.978975    	average train batch reward = 0.556
validation accuracy = 0.097		average validation NDCG = 0.696

epoch 2
average train loss = -0.081024    	average train batch reward = 0.557
validation accuracy = 0.093		average validation NDCG = 0.693

epoch 3
average train loss = -0.000000    	average train batch reward = 0.555
validation accuracy = 0.095		average validation NDCG = 0.691

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.032706    	average train batch reward = 0.555
validation accuracy = 0.012		average validation NDCG = 0.691

epoch 2
average train loss = 0.000005    	average train batch reward = 0.552
validation accuracy = 0.017		average validation NDCG = 0.688

epoch 3
average train loss = 0.024962    	average train batch reward = 0.547
validation accuracy = 0.017		average validation NDCG = 0.654

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 5.629326    	average train batch reward = 0.530
validation accuracy = 0.083		average validation NDCG = 0.656

epoch 2
average train loss = -0.521321    	average train batch reward = 0.533
validation accuracy = 0.087		average validation NDCG = 0.663

epoch 3
average train loss = 0.000000    	average train batch reward = 0.542
validation accuracy = 0.143		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001743    	average train batch reward = 0.537
validation accuracy = 0.098		average validation NDCG = 0.670

epoch 2
average train loss = 0.000000    	average train batch reward = 0.538
validation accuracy = 0.100		average validation NDCG = 0.670

epoch 3
average train loss = -0.022805    	average train batch reward = 0.537
validation accuracy = 0.098		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.778502    	average train batch reward = 0.531
validation accuracy = 0.106		average validation NDCG = 0.649

epoch 2
average train loss = -0.000003    	average train batch reward = 0.530
validation accuracy = 0.107		average validation NDCG = 0.649

epoch 3
average train loss = -0.000000    	average train batch reward = 0.528
validation accuracy = 0.107		average validation NDCG = 0.649

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.914965    	average train batch reward = 0.530
validation accuracy = 0.107		average validation NDCG = 0.664

epoch 2
average train loss = -0.000000    	average train batch reward = 0.536
validation accuracy = 0.115		average validation NDCG = 0.663

epoch 3
average train loss = 0.000000    	average train batch reward = 0.534
validation accuracy = 0.115		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.137411    	average train batch reward = 0.540
validation accuracy = 0.100		average validation NDCG = 0.674

epoch 2
average train loss = -0.000000    	average train batch reward = 0.540
validation accuracy = 0.100		average validation NDCG = 0.671

epoch 3
average train loss = -0.000000    	average train batch reward = 0.540
validation accuracy = 0.100		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 71.932632    	average train batch reward = 0.538
validation accuracy = 0.113		average validation NDCG = 0.659

epoch 2
average train loss = -0.000000    	average train batch reward = 0.538
validation accuracy = 0.113		average validation NDCG = 0.660

epoch 3
average train loss = 22.389013    	average train batch reward = 0.538
validation accuracy = 0.113		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.307007    	average train batch reward = 0.537
validation accuracy = 0.113		average validation NDCG = 0.664

epoch 2
average train loss = 838.264465    	average train batch reward = 0.538
validation accuracy = 0.110		average validation NDCG = 0.667

epoch 3
average train loss = -0.000001    	average train batch reward = 0.537
validation accuracy = 0.110		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 3.094443    	average train batch reward = 0.541
validation accuracy = 0.096		average validation NDCG = 0.681

epoch 2
average train loss = -134.367920    	average train batch reward = 0.542
validation accuracy = 0.110		average validation NDCG = 0.683

epoch 3
average train loss = -14.831750    	average train batch reward = 0.540
validation accuracy = 0.138		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 2.001223    	average train batch reward = 0.537
validation accuracy = 0.094		average validation NDCG = 0.666

epoch 2
average train loss = -0.000000    	average train batch reward = 0.540
validation accuracy = 0.092		average validation NDCG = 0.666

epoch 3
average train loss = -51.031994    	average train batch reward = 0.537
validation accuracy = 0.071		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
Hyperparameters:
k = 10
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b2e04531320>
Reward function = <function ndcg_full at 0x2b2e04531398>
Greedy action = <function sample at 0x2b2dfd3329b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.061475    	average train batch reward = 0.540
validation accuracy = 0.092		average validation NDCG = 0.671

epoch 2
average train loss = -59.592690    	average train batch reward = 0.539
validation accuracy = 0.107		average validation NDCG = 0.662

epoch 3
average train loss = -0.104441    	average train batch reward = 0.537
validation accuracy = 0.107		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.75, 1.5), (0.10000000000000001, 0.25, 1.0), (0.01, 0.1, 1.0)], which got scores of [0.70593634593854593, 0.69616597914676059, 0.69261287704039676]
========
2017-07-03 12:22:33
