2017-07-03 06:33:18
Finding best parameters for k = 2
=========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000998    	average train batch reward = 0.816
validation accuracy = 0.098		average validation NDCG = 0.656

epoch 2
average train loss = -0.001167    	average train batch reward = 0.822
validation accuracy = 0.099		average validation NDCG = 0.659

epoch 3
average train loss = -0.000689    	average train batch reward = 0.825
validation accuracy = 0.099		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.6625503962196766, -1, -1]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000424    	average train batch reward = 0.815
validation accuracy = 0.067		average validation NDCG = 0.657

epoch 2
average train loss = -0.000733    	average train batch reward = 0.819
validation accuracy = 0.072		average validation NDCG = 0.661

epoch 3
average train loss = -0.000826    	average train batch reward = 0.821
validation accuracy = 0.079		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), ()], which got scores of [0.6639104030030154, 0.6625503962196766, -1]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000072    	average train batch reward = 0.828
validation accuracy = 0.092		average validation NDCG = 0.660

epoch 2
average train loss = -0.000049    	average train batch reward = 0.830
validation accuracy = 0.097		average validation NDCG = 0.664

epoch 3
average train loss = 0.000170    	average train batch reward = 0.834
validation accuracy = 0.101		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 0.2), ()], which got scores of [0.66760018343219019, 0.6639104030030154, -1]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000757    	average train batch reward = 0.855
validation accuracy = 0.154		average validation NDCG = 0.697

epoch 2
average train loss = 0.000603    	average train batch reward = 0.860
validation accuracy = 0.160		average validation NDCG = 0.703

epoch 3
average train loss = 0.000575    	average train batch reward = 0.862
validation accuracy = 0.165		average validation NDCG = 0.709

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.5), ()], which got scores of [0.70940921766839948, 0.66760018343219019, -1]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000009    	average train batch reward = 0.832
validation accuracy = 0.126		average validation NDCG = 0.673

epoch 2
average train loss = 0.000148    	average train batch reward = 0.836
validation accuracy = 0.129		average validation NDCG = 0.677

epoch 3
average train loss = -0.000067    	average train batch reward = 0.838
validation accuracy = 0.136		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.70940921766839948, 0.6816627332049906, 0.66760018343219019]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000081    	average train batch reward = 0.837
validation accuracy = 0.110		average validation NDCG = 0.684

epoch 2
average train loss = 0.000005    	average train batch reward = 0.840
validation accuracy = 0.118		average validation NDCG = 0.688

epoch 3
average train loss = -0.000001    	average train batch reward = 0.843
validation accuracy = 0.129		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.6816627332049906]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000198    	average train batch reward = 0.836
validation accuracy = 0.099		average validation NDCG = 0.671

epoch 2
average train loss = 0.000370    	average train batch reward = 0.837
validation accuracy = 0.100		average validation NDCG = 0.675

epoch 3
average train loss = 0.000349    	average train batch reward = 0.842
validation accuracy = 0.101		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.6816627332049906]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000251    	average train batch reward = 0.825
validation accuracy = 0.063		average validation NDCG = 0.657

epoch 2
average train loss = -0.000116    	average train batch reward = 0.827
validation accuracy = 0.068		average validation NDCG = 0.660

epoch 3
average train loss = -0.000217    	average train batch reward = 0.829
validation accuracy = 0.072		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.6816627332049906]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000243    	average train batch reward = 0.842
validation accuracy = 0.126		average validation NDCG = 0.675

epoch 2
average train loss = 0.000254    	average train batch reward = 0.843
validation accuracy = 0.130		average validation NDCG = 0.679

epoch 3
average train loss = 0.000325    	average train batch reward = 0.845
validation accuracy = 0.136		average validation NDCG = 0.683

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.25, 1.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.68317715519584721]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000130    	average train batch reward = 0.832
validation accuracy = 0.076		average validation NDCG = 0.658

epoch 2
average train loss = 0.000138    	average train batch reward = 0.833
validation accuracy = 0.081		average validation NDCG = 0.661

epoch 3
average train loss = -0.000031    	average train batch reward = 0.836
validation accuracy = 0.086		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.25, 1.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.68317715519584721]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000164    	average train batch reward = 0.832
validation accuracy = 0.077		average validation NDCG = 0.676

epoch 2
average train loss = 0.000334    	average train batch reward = 0.834
validation accuracy = 0.082		average validation NDCG = 0.680

epoch 3
average train loss = 0.000122    	average train batch reward = 0.835
validation accuracy = 0.088		average validation NDCG = 0.685

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.68491117110849986]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000123    	average train batch reward = 0.836
validation accuracy = 0.152		average validation NDCG = 0.667

epoch 2
average train loss = -0.000261    	average train batch reward = 0.839
validation accuracy = 0.157		average validation NDCG = 0.670

epoch 3
average train loss = -0.000020    	average train batch reward = 0.841
validation accuracy = 0.163		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.68491117110849986]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000393    	average train batch reward = 0.838
validation accuracy = 0.102		average validation NDCG = 0.669

epoch 2
average train loss = -0.000237    	average train batch reward = 0.837
validation accuracy = 0.105		average validation NDCG = 0.672

epoch 3
average train loss = -0.000206    	average train batch reward = 0.841
validation accuracy = 0.109		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.68491117110849986]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000539    	average train batch reward = 0.836
validation accuracy = 0.077		average validation NDCG = 0.683

epoch 2
average train loss = -0.000455    	average train batch reward = 0.838
validation accuracy = 0.080		average validation NDCG = 0.686

epoch 3
average train loss = -0.000467    	average train batch reward = 0.837
validation accuracy = 0.083		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 1.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.69004565578511223]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000211    	average train batch reward = 0.833
validation accuracy = 0.119		average validation NDCG = 0.677

epoch 2
average train loss = 0.000015    	average train batch reward = 0.835
validation accuracy = 0.124		average validation NDCG = 0.682

epoch 3
average train loss = 0.000145    	average train batch reward = 0.838
validation accuracy = 0.128		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 1.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.69004565578511223]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000085    	average train batch reward = 0.832
validation accuracy = 0.075		average validation NDCG = 0.678

epoch 2
average train loss = 0.000052    	average train batch reward = 0.833
validation accuracy = 0.081		average validation NDCG = 0.683

epoch 3
average train loss = -0.000076    	average train batch reward = 0.833
validation accuracy = 0.086		average validation NDCG = 0.687

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.5, 1.0)], which got scores of [0.70940921766839948, 0.69280694013546718, 0.69004565578511223]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000239    	average train batch reward = 0.838
validation accuracy = 0.125		average validation NDCG = 0.693

epoch 2
average train loss = -0.000359    	average train batch reward = 0.838
validation accuracy = 0.132		average validation NDCG = 0.698

epoch 3
average train loss = -0.000346    	average train batch reward = 0.838
validation accuracy = 0.137		average validation NDCG = 0.703

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.75, 0.2), (9.9999999999999995e-07, 0.25, 0.0)], which got scores of [0.70940921766839948, 0.70298640107735788, 0.69280694013546718]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000163    	average train batch reward = 0.833
validation accuracy = 0.101		average validation NDCG = 0.680

epoch 2
average train loss = 0.000176    	average train batch reward = 0.836
validation accuracy = 0.105		average validation NDCG = 0.684

epoch 3
average train loss = -0.000026    	average train batch reward = 0.837
validation accuracy = 0.109		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.75, 0.2), (9.9999999999999995e-07, 0.25, 0.0)], which got scores of [0.70940921766839948, 0.70298640107735788, 0.69280694013546718]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000007    	average train batch reward = 0.834
validation accuracy = 0.107		average validation NDCG = 0.671

epoch 2
average train loss = 0.000009    	average train batch reward = 0.837
validation accuracy = 0.110		average validation NDCG = 0.674

epoch 3
average train loss = -0.000167    	average train batch reward = 0.836
validation accuracy = 0.115		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.75, 0.2), (9.9999999999999995e-07, 0.25, 0.0)], which got scores of [0.70940921766839948, 0.70298640107735788, 0.69280694013546718]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000023    	average train batch reward = 0.837
validation accuracy = 0.121		average validation NDCG = 0.695

epoch 2
average train loss = 0.000026    	average train batch reward = 0.838
validation accuracy = 0.125		average validation NDCG = 0.699

epoch 3
average train loss = -0.000099    	average train batch reward = 0.840
validation accuracy = 0.132		average validation NDCG = 0.703

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.75, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70940921766839948, 0.70301030326069092, 0.70298640107735788]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000119    	average train batch reward = 0.835
validation accuracy = 0.099		average validation NDCG = 0.692

epoch 2
average train loss = -0.000126    	average train batch reward = 0.857
validation accuracy = 0.147		average validation NDCG = 0.729

epoch 3
average train loss = -0.000466    	average train batch reward = 0.877
validation accuracy = 0.206		average validation NDCG = 0.760

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.75965664140448286, 0.70940921766839948, 0.70298640107735788]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000517    	average train batch reward = 0.834
validation accuracy = 0.148		average validation NDCG = 0.704

epoch 2
average train loss = -0.000864    	average train batch reward = 0.868
validation accuracy = 0.211		average validation NDCG = 0.753

epoch 3
average train loss = -0.000181    	average train batch reward = 0.896
validation accuracy = 0.271		average validation NDCG = 0.810

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.2), (1.0000000000000001e-05, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.80953544390482701, 0.75965664140448286, 0.70298640107735788]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000580    	average train batch reward = 0.861
validation accuracy = 0.140		average validation NDCG = 0.723

epoch 2
average train loss = 0.000596    	average train batch reward = 0.892
validation accuracy = 0.201		average validation NDCG = 0.770

epoch 3
average train loss = 0.000640    	average train batch reward = 0.911
validation accuracy = 0.263		average validation NDCG = 0.808

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.2), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 0.0)], which got scores of [0.80953544390482701, 0.80824643527103357, 0.75965664140448286]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000450    	average train batch reward = 0.844
validation accuracy = 0.186		average validation NDCG = 0.713

epoch 2
average train loss = 0.000117    	average train batch reward = 0.879
validation accuracy = 0.258		average validation NDCG = 0.771

epoch 3
average train loss = 0.000116    	average train batch reward = 0.904
validation accuracy = 0.339		average validation NDCG = 0.821

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.2), (1.0000000000000001e-05, 0.1, 0.0)], which got scores of [0.82087039514255467, 0.80953544390482701, 0.75965664140448286]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000709    	average train batch reward = 0.839
validation accuracy = 0.208		average validation NDCG = 0.697

epoch 2
average train loss = -0.001181    	average train batch reward = 0.869
validation accuracy = 0.281		average validation NDCG = 0.746

epoch 3
average train loss = -0.000885    	average train batch reward = 0.895
validation accuracy = 0.357		average validation NDCG = 0.805

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.2), (1.0000000000000001e-05, 0.1, 1.5)], which got scores of [0.82087039514255467, 0.80953544390482701, 0.80526990144063448]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000568    	average train batch reward = 0.848
validation accuracy = 0.231		average validation NDCG = 0.722

epoch 2
average train loss = -0.000513    	average train batch reward = 0.874
validation accuracy = 0.350		average validation NDCG = 0.768

epoch 3
average train loss = -0.000197    	average train batch reward = 0.888
validation accuracy = 0.420		average validation NDCG = 0.801

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.2), (1.0000000000000001e-05, 0.1, 1.5)], which got scores of [0.82087039514255467, 0.80953544390482701, 0.80526990144063448]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000348    	average train batch reward = 0.849
validation accuracy = 0.172		average validation NDCG = 0.721

epoch 2
average train loss = -0.000315    	average train batch reward = 0.874
validation accuracy = 0.265		average validation NDCG = 0.776

epoch 3
average train loss = -0.000263    	average train batch reward = 0.892
validation accuracy = 0.335		average validation NDCG = 0.817

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 0.2), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.82087039514255467, 0.81660180650409941, 0.80953544390482701]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000490    	average train batch reward = 0.839
validation accuracy = 0.163		average validation NDCG = 0.703

epoch 2
average train loss = -0.000463    	average train batch reward = 0.862
validation accuracy = 0.242		average validation NDCG = 0.748

epoch 3
average train loss = -0.000316    	average train batch reward = 0.878
validation accuracy = 0.316		average validation NDCG = 0.785

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 0.2), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.82087039514255467, 0.81660180650409941, 0.80953544390482701]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000056    	average train batch reward = 0.855
validation accuracy = 0.183		average validation NDCG = 0.734

epoch 2
average train loss = -0.000235    	average train batch reward = 0.874
validation accuracy = 0.240		average validation NDCG = 0.777

epoch 3
average train loss = -0.000290    	average train batch reward = 0.887
validation accuracy = 0.278		average validation NDCG = 0.812

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.82087039514255467, 0.81660180650409941, 0.81193303400060124]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000777    	average train batch reward = 0.852
validation accuracy = 0.160		average validation NDCG = 0.743

epoch 2
average train loss = -0.000382    	average train batch reward = 0.880
validation accuracy = 0.272		average validation NDCG = 0.793

epoch 3
average train loss = -0.000184    	average train batch reward = 0.894
validation accuracy = 0.362		average validation NDCG = 0.827

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.82707087602053964, 0.82087039514255467, 0.81193303400060124]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000007    	average train batch reward = 0.839
validation accuracy = 0.158		average validation NDCG = 0.730

epoch 2
average train loss = -0.000047    	average train batch reward = 0.852
validation accuracy = 0.243		average validation NDCG = 0.766

epoch 3
average train loss = -0.000325    	average train batch reward = 0.862
validation accuracy = 0.306		average validation NDCG = 0.789

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.82707087602053964, 0.82087039514255467, 0.81193303400060124]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000238    	average train batch reward = 0.843
validation accuracy = 0.183		average validation NDCG = 0.724

epoch 2
average train loss = -0.000126    	average train batch reward = 0.856
validation accuracy = 0.226		average validation NDCG = 0.762

epoch 3
average train loss = -0.000258    	average train batch reward = 0.865
validation accuracy = 0.261		average validation NDCG = 0.795

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.82707087602053964, 0.82087039514255467, 0.81193303400060124]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000241    	average train batch reward = 0.847
validation accuracy = 0.184		average validation NDCG = 0.728

epoch 2
average train loss = -0.000099    	average train batch reward = 0.860
validation accuracy = 0.262		average validation NDCG = 0.776

epoch 3
average train loss = -0.000252    	average train batch reward = 0.870
validation accuracy = 0.335		average validation NDCG = 0.821

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 0.5), (1.0000000000000001e-05, 0.1, 1.0)], which got scores of [0.82707087602053964, 0.82110420600074663, 0.82087039514255467]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000160    	average train batch reward = 0.836
validation accuracy = 0.157		average validation NDCG = 0.691

epoch 2
average train loss = -0.000467    	average train batch reward = 0.855
validation accuracy = 0.255		average validation NDCG = 0.738

epoch 3
average train loss = -0.000524    	average train batch reward = 0.869
validation accuracy = 0.337		average validation NDCG = 0.783

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 0.5), (1.0000000000000001e-05, 0.1, 1.0)], which got scores of [0.82707087602053964, 0.82110420600074663, 0.82087039514255467]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000263    	average train batch reward = 0.839
validation accuracy = 0.148		average validation NDCG = 0.725

epoch 2
average train loss = -0.000511    	average train batch reward = 0.857
validation accuracy = 0.231		average validation NDCG = 0.779

epoch 3
average train loss = -0.000440    	average train batch reward = 0.869
validation accuracy = 0.312		average validation NDCG = 0.822

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000055    	average train batch reward = 0.837
validation accuracy = 0.142		average validation NDCG = 0.704

epoch 2
average train loss = -0.000386    	average train batch reward = 0.843
validation accuracy = 0.188		average validation NDCG = 0.751

epoch 3
average train loss = -0.000761    	average train batch reward = 0.850
validation accuracy = 0.254		average validation NDCG = 0.804

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000465    	average train batch reward = 0.838
validation accuracy = 0.135		average validation NDCG = 0.717

epoch 2
average train loss = -0.000641    	average train batch reward = 0.846
validation accuracy = 0.180		average validation NDCG = 0.761

epoch 3
average train loss = -0.000527    	average train batch reward = 0.851
validation accuracy = 0.228		average validation NDCG = 0.802

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000178    	average train batch reward = 0.837
validation accuracy = 0.151		average validation NDCG = 0.718

epoch 2
average train loss = -0.000486    	average train batch reward = 0.846
validation accuracy = 0.218		average validation NDCG = 0.761

epoch 3
average train loss = -0.000663    	average train batch reward = 0.852
validation accuracy = 0.281		average validation NDCG = 0.800

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000030    	average train batch reward = 0.837
validation accuracy = 0.143		average validation NDCG = 0.700

epoch 2
average train loss = -0.000142    	average train batch reward = 0.844
validation accuracy = 0.195		average validation NDCG = 0.735

epoch 3
average train loss = -0.000297    	average train batch reward = 0.849
validation accuracy = 0.250		average validation NDCG = 0.768

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000318    	average train batch reward = 0.841
validation accuracy = 0.161		average validation NDCG = 0.734

epoch 2
average train loss = -0.000303    	average train batch reward = 0.850
validation accuracy = 0.242		average validation NDCG = 0.782

epoch 3
average train loss = -0.000305    	average train batch reward = 0.857
validation accuracy = 0.320		average validation NDCG = 0.818

========
Currently the best setups are [(1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.82707087602053964, 0.82225819093836949, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000139    	average train batch reward = 0.911
validation accuracy = 0.598		average validation NDCG = 0.891

epoch 2
average train loss = 0.000146    	average train batch reward = 0.941
validation accuracy = 0.660		average validation NDCG = 0.924

epoch 3
average train loss = -0.000011    	average train batch reward = 0.955
validation accuracy = 0.753		average validation NDCG = 0.944

========
Currently the best setups are [(0.0001, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 1.5), (1.0000000000000001e-05, 0.5, 0.5)], which got scores of [0.94439144289605381, 0.82707087602053964, 0.82110420600074663]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000153    	average train batch reward = 0.902
validation accuracy = 0.512		average validation NDCG = 0.896

epoch 2
average train loss = 0.000213    	average train batch reward = 0.950
validation accuracy = 0.605		average validation NDCG = 0.931

epoch 3
average train loss = 0.000137    	average train batch reward = 0.956
validation accuracy = 0.637		average validation NDCG = 0.940

========
Currently the best setups are [(0.0001, 0.1, 0.0), (0.0001, 0.1, 0.2), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.94439144289605381, 0.94016083883598611, 0.82707087602053964]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000510    	average train batch reward = 0.928
validation accuracy = 0.577		average validation NDCG = 0.936

epoch 2
average train loss = 0.000534    	average train batch reward = 0.965
validation accuracy = 0.711		average validation NDCG = 0.961

epoch 3
average train loss = 0.000455    	average train batch reward = 0.970
validation accuracy = 0.782		average validation NDCG = 0.971

========
Currently the best setups are [(0.0001, 0.1, 0.5), (0.0001, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.9705301177579061, 0.94439144289605381, 0.82707087602053964]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000344    	average train batch reward = 0.904
validation accuracy = 0.477		average validation NDCG = 0.914

epoch 2
average train loss = 0.000149    	average train batch reward = 0.955
validation accuracy = 0.615		average validation NDCG = 0.960

epoch 3
average train loss = 0.000189    	average train batch reward = 0.969
validation accuracy = 0.733		average validation NDCG = 0.975

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.82707087602053964]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000108    	average train batch reward = 0.913
validation accuracy = 0.600		average validation NDCG = 0.901

epoch 2
average train loss = 0.000086    	average train batch reward = 0.950
validation accuracy = 0.689		average validation NDCG = 0.931

epoch 3
average train loss = 0.000257    	average train batch reward = 0.957
validation accuracy = 0.760		average validation NDCG = 0.941

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.1, 1.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.94083906144021157]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000146    	average train batch reward = 0.896
validation accuracy = 0.530		average validation NDCG = 0.893

epoch 2
average train loss = -0.000086    	average train batch reward = 0.924
validation accuracy = 0.632		average validation NDCG = 0.923

epoch 3
average train loss = -0.000168    	average train batch reward = 0.931
validation accuracy = 0.699		average validation NDCG = 0.939

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.1, 1.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.94083906144021157]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000142    	average train batch reward = 0.888
validation accuracy = 0.506		average validation NDCG = 0.887

epoch 2
average train loss = -0.000030    	average train batch reward = 0.928
validation accuracy = 0.644		average validation NDCG = 0.933

epoch 3
average train loss = -0.000003    	average train batch reward = 0.936
validation accuracy = 0.692		average validation NDCG = 0.943

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.2)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.94293933023248966]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000334    	average train batch reward = 0.890
validation accuracy = 0.552		average validation NDCG = 0.923

epoch 2
average train loss = -0.000252    	average train batch reward = 0.941
validation accuracy = 0.729		average validation NDCG = 0.959

epoch 3
average train loss = -0.000079    	average train batch reward = 0.947
validation accuracy = 0.780		average validation NDCG = 0.970

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.96992549976535081]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000248    	average train batch reward = 0.894
validation accuracy = 0.553		average validation NDCG = 0.886

epoch 2
average train loss = -0.000123    	average train batch reward = 0.936
validation accuracy = 0.745		average validation NDCG = 0.952

epoch 3
average train loss = 0.000004    	average train batch reward = 0.947
validation accuracy = 0.785		average validation NDCG = 0.967

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.96992549976535081]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000509    	average train batch reward = 0.892
validation accuracy = 0.614		average validation NDCG = 0.904

epoch 2
average train loss = -0.000114    	average train batch reward = 0.931
validation accuracy = 0.672		average validation NDCG = 0.932

epoch 3
average train loss = -0.000046    	average train batch reward = 0.937
validation accuracy = 0.723		average validation NDCG = 0.941

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.5)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.96992549976535081]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000198    	average train batch reward = 0.881
validation accuracy = 0.636		average validation NDCG = 0.935

epoch 2
average train loss = -0.000277    	average train batch reward = 0.908
validation accuracy = 0.717		average validation NDCG = 0.963

epoch 3
average train loss = -0.000168    	average train batch reward = 0.909
validation accuracy = 0.730		average validation NDCG = 0.970

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000229    	average train batch reward = 0.870
validation accuracy = 0.557		average validation NDCG = 0.885

epoch 2
average train loss = -0.000241    	average train batch reward = 0.892
validation accuracy = 0.651		average validation NDCG = 0.907

epoch 3
average train loss = -0.000185    	average train batch reward = 0.897
validation accuracy = 0.674		average validation NDCG = 0.914

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000296    	average train batch reward = 0.878
validation accuracy = 0.513		average validation NDCG = 0.906

epoch 2
average train loss = -0.000143    	average train batch reward = 0.899
validation accuracy = 0.647		average validation NDCG = 0.936

epoch 3
average train loss = -0.000189    	average train batch reward = 0.903
validation accuracy = 0.710		average validation NDCG = 0.942

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000133    	average train batch reward = 0.873
validation accuracy = 0.547		average validation NDCG = 0.892

epoch 2
average train loss = -0.000136    	average train batch reward = 0.898
validation accuracy = 0.644		average validation NDCG = 0.926

epoch 3
average train loss = -0.000099    	average train batch reward = 0.903
validation accuracy = 0.695		average validation NDCG = 0.940

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000238    	average train batch reward = 0.886
validation accuracy = 0.579		average validation NDCG = 0.925

epoch 2
average train loss = -0.000039    	average train batch reward = 0.905
validation accuracy = 0.679		average validation NDCG = 0.956

epoch 3
average train loss = -0.000192    	average train batch reward = 0.909
validation accuracy = 0.716		average validation NDCG = 0.968

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000069    	average train batch reward = 0.850
validation accuracy = 0.485		average validation NDCG = 0.871

epoch 2
average train loss = -0.000232    	average train batch reward = 0.865
validation accuracy = 0.643		average validation NDCG = 0.930

epoch 3
average train loss = -0.000138    	average train batch reward = 0.871
validation accuracy = 0.722		average validation NDCG = 0.967

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000362    	average train batch reward = 0.858
validation accuracy = 0.577		average validation NDCG = 0.910

epoch 2
average train loss = -0.000214    	average train batch reward = 0.867
validation accuracy = 0.696		average validation NDCG = 0.933

epoch 3
average train loss = -0.000190    	average train batch reward = 0.868
validation accuracy = 0.726		average validation NDCG = 0.940

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000213    	average train batch reward = 0.847
validation accuracy = 0.371		average validation NDCG = 0.853

epoch 2
average train loss = -0.000304    	average train batch reward = 0.862
validation accuracy = 0.559		average validation NDCG = 0.903

epoch 3
average train loss = -0.000206    	average train batch reward = 0.865
validation accuracy = 0.609		average validation NDCG = 0.911

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000286    	average train batch reward = 0.852
validation accuracy = 0.544		average validation NDCG = 0.883

epoch 2
average train loss = -0.000234    	average train batch reward = 0.867
validation accuracy = 0.722		average validation NDCG = 0.931

epoch 3
average train loss = -0.000232    	average train batch reward = 0.871
validation accuracy = 0.789		average validation NDCG = 0.965

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000291    	average train batch reward = 0.859
validation accuracy = 0.645		average validation NDCG = 0.929

epoch 2
average train loss = -0.000203    	average train batch reward = 0.871
validation accuracy = 0.743		average validation NDCG = 0.957

epoch 3
average train loss = -0.000093    	average train batch reward = 0.873
validation accuracy = 0.752		average validation NDCG = 0.968

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000182    	average train batch reward = 0.946
validation accuracy = 0.658		average validation NDCG = 0.938

epoch 2
average train loss = 0.000084    	average train batch reward = 0.958
validation accuracy = 0.702		average validation NDCG = 0.943

epoch 3
average train loss = 0.000165    	average train batch reward = 0.958
validation accuracy = 0.645		average validation NDCG = 0.947

========
Currently the best setups are [(0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.9745286615766251, 0.9705301177579061, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000123    	average train batch reward = 0.945
validation accuracy = 0.550		average validation NDCG = 0.942

epoch 2
average train loss = 0.000211    	average train batch reward = 0.964
validation accuracy = 0.779		average validation NDCG = 0.972

epoch 3
average train loss = 0.000110    	average train batch reward = 0.974
validation accuracy = 0.797		average validation NDCG = 0.980

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.0001, 0.1, 1.0), (0.0001, 0.5, 0.0)], which got scores of [0.97981250826574962, 0.9745286615766251, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000198    	average train batch reward = 0.943
validation accuracy = 0.621		average validation NDCG = 0.930

epoch 2
average train loss = 0.000187    	average train batch reward = 0.957
validation accuracy = 0.688		average validation NDCG = 0.944

epoch 3
average train loss = 0.000099    	average train batch reward = 0.960
validation accuracy = 0.726		average validation NDCG = 0.947

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.0001, 0.1, 1.0), (0.0001, 0.5, 0.0)], which got scores of [0.97981250826574962, 0.9745286615766251, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000010    	average train batch reward = 0.930
validation accuracy = 0.680		average validation NDCG = 0.909

epoch 2
average train loss = 0.000005    	average train batch reward = 0.955
validation accuracy = 0.762		average validation NDCG = 0.942

epoch 3
average train loss = 0.000066    	average train batch reward = 0.961
validation accuracy = 0.746		average validation NDCG = 0.946

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.0001, 0.1, 1.0), (0.0001, 0.5, 0.0)], which got scores of [0.97981250826574962, 0.9745286615766251, 0.9701858686849304]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000346    	average train batch reward = 0.960
validation accuracy = 0.768		average validation NDCG = 0.968

epoch 2
average train loss = 0.000156    	average train batch reward = 0.972
validation accuracy = 0.762		average validation NDCG = 0.967

epoch 3
average train loss = 0.000203    	average train batch reward = 0.972
validation accuracy = 0.719		average validation NDCG = 0.973

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.0001, 0.1, 1.0), (0.001, 0.1, 1.5)], which got scores of [0.97981250826574962, 0.9745286615766251, 0.9734693334610407]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000021    	average train batch reward = 0.933
validation accuracy = 0.734		average validation NDCG = 0.971

epoch 2
average train loss = 0.000057    	average train batch reward = 0.948
validation accuracy = 0.683		average validation NDCG = 0.975

epoch 3
average train loss = 0.000057    	average train batch reward = 0.951
validation accuracy = 0.726		average validation NDCG = 0.976

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000039    	average train batch reward = 0.919
validation accuracy = 0.633		average validation NDCG = 0.930

epoch 2
average train loss = 0.000022    	average train batch reward = 0.938
validation accuracy = 0.660		average validation NDCG = 0.944

epoch 3
average train loss = -0.000014    	average train batch reward = 0.939
validation accuracy = 0.764		average validation NDCG = 0.948

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000064    	average train batch reward = 0.929
validation accuracy = 0.569		average validation NDCG = 0.938

epoch 2
average train loss = 0.000008    	average train batch reward = 0.939
validation accuracy = 0.734		average validation NDCG = 0.941

epoch 3
average train loss = 0.000074    	average train batch reward = 0.938
validation accuracy = 0.734		average validation NDCG = 0.947

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000021    	average train batch reward = 0.926
validation accuracy = 0.639		average validation NDCG = 0.933

epoch 2
average train loss = -0.000011    	average train batch reward = 0.937
validation accuracy = 0.621		average validation NDCG = 0.946

epoch 3
average train loss = -0.000011    	average train batch reward = 0.938
validation accuracy = 0.651		average validation NDCG = 0.952

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000056    	average train batch reward = 0.909
validation accuracy = 0.570		average validation NDCG = 0.883

epoch 2
average train loss = -0.000028    	average train batch reward = 0.917
validation accuracy = 0.528		average validation NDCG = 0.887

epoch 3
average train loss = -0.000078    	average train batch reward = 0.920
validation accuracy = 0.608		average validation NDCG = 0.914

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000094    	average train batch reward = 0.895
validation accuracy = 0.677		average validation NDCG = 0.936

epoch 2
average train loss = -0.000047    	average train batch reward = 0.903
validation accuracy = 0.725		average validation NDCG = 0.937

epoch 3
average train loss = -0.000023    	average train batch reward = 0.906
validation accuracy = 0.753		average validation NDCG = 0.948

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000064    	average train batch reward = 0.895
validation accuracy = 0.750		average validation NDCG = 0.945

epoch 2
average train loss = -0.000032    	average train batch reward = 0.903
validation accuracy = 0.741		average validation NDCG = 0.945

epoch 3
average train loss = -0.000039    	average train batch reward = 0.902
validation accuracy = 0.734		average validation NDCG = 0.943

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000027    	average train batch reward = 0.896
validation accuracy = 0.636		average validation NDCG = 0.936

epoch 2
average train loss = -0.000065    	average train batch reward = 0.904
validation accuracy = 0.720		average validation NDCG = 0.944

epoch 3
average train loss = -0.000024    	average train batch reward = 0.905
validation accuracy = 0.749		average validation NDCG = 0.941

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.0001, 0.1, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9745286615766251]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000057    	average train batch reward = 0.895
validation accuracy = 0.704		average validation NDCG = 0.941

epoch 2
average train loss = -0.000051    	average train batch reward = 0.905
validation accuracy = 0.703		average validation NDCG = 0.959

epoch 3
average train loss = 0.000014    	average train batch reward = 0.912
validation accuracy = 0.814		average validation NDCG = 0.975

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000071    	average train batch reward = 0.893
validation accuracy = 0.667		average validation NDCG = 0.930

epoch 2
average train loss = -0.000047    	average train batch reward = 0.904
validation accuracy = 0.773		average validation NDCG = 0.941

epoch 3
average train loss = -0.000059    	average train batch reward = 0.904
validation accuracy = 0.759		average validation NDCG = 0.942

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000115    	average train batch reward = 0.862
validation accuracy = 0.732		average validation NDCG = 0.934

epoch 2
average train loss = -0.000039    	average train batch reward = 0.869
validation accuracy = 0.710		average validation NDCG = 0.942

epoch 3
average train loss = -0.000074    	average train batch reward = 0.871
validation accuracy = 0.714		average validation NDCG = 0.944

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000090    	average train batch reward = 0.862
validation accuracy = 0.719		average validation NDCG = 0.936

epoch 2
average train loss = -0.000043    	average train batch reward = 0.869
validation accuracy = 0.735		average validation NDCG = 0.944

epoch 3
average train loss = 0.000000    	average train batch reward = 0.870
validation accuracy = 0.772		average validation NDCG = 0.946

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000051    	average train batch reward = 0.866
validation accuracy = 0.761		average validation NDCG = 0.942

epoch 2
average train loss = -0.000051    	average train batch reward = 0.870
validation accuracy = 0.623		average validation NDCG = 0.941

epoch 3
average train loss = -0.000070    	average train batch reward = 0.868
validation accuracy = 0.722		average validation NDCG = 0.948

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000049    	average train batch reward = 0.864
validation accuracy = 0.658		average validation NDCG = 0.938

epoch 2
average train loss = -0.000055    	average train batch reward = 0.868
validation accuracy = 0.703		average validation NDCG = 0.941

epoch 3
average train loss = -0.000056    	average train batch reward = 0.871
validation accuracy = 0.776		average validation NDCG = 0.969

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000143    	average train batch reward = 0.866
validation accuracy = 0.733		average validation NDCG = 0.941

epoch 2
average train loss = -0.000076    	average train batch reward = 0.869
validation accuracy = 0.779		average validation NDCG = 0.945

epoch 3
average train loss = -0.000069    	average train batch reward = 0.870
validation accuracy = 0.768		average validation NDCG = 0.947

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000019    	average train batch reward = 0.929
validation accuracy = 0.409		average validation NDCG = 0.883

epoch 2
average train loss = 0.000018    	average train batch reward = 0.940
validation accuracy = 0.293		average validation NDCG = 0.885

epoch 3
average train loss = 0.000012    	average train batch reward = 0.940
validation accuracy = 0.231		average validation NDCG = 0.889

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000000    	average train batch reward = 0.910
validation accuracy = 0.214		average validation NDCG = 0.813

epoch 2
average train loss = 0.000020    	average train batch reward = 0.915
validation accuracy = 0.413		average validation NDCG = 0.857

epoch 3
average train loss = 0.000014    	average train batch reward = 0.915
validation accuracy = 0.262		average validation NDCG = 0.828

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000030    	average train batch reward = 0.908
validation accuracy = 0.331		average validation NDCG = 0.819

epoch 2
average train loss = 0.000007    	average train batch reward = 0.900
validation accuracy = 0.258		average validation NDCG = 0.805

epoch 3
average train loss = 0.000011    	average train batch reward = 0.902
validation accuracy = 0.343		average validation NDCG = 0.829

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000062    	average train batch reward = 0.930
validation accuracy = 0.379		average validation NDCG = 0.864

epoch 2
average train loss = -0.000007    	average train batch reward = 0.933
validation accuracy = 0.504		average validation NDCG = 0.884

epoch 3
average train loss = 0.000006    	average train batch reward = 0.930
validation accuracy = 0.378		average validation NDCG = 0.864

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000024    	average train batch reward = 0.916
validation accuracy = 0.193		average validation NDCG = 0.863

epoch 2
average train loss = 0.000013    	average train batch reward = 0.929
validation accuracy = 0.244		average validation NDCG = 0.862

epoch 3
average train loss = -0.000004    	average train batch reward = 0.927
validation accuracy = 0.245		average validation NDCG = 0.855

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000029    	average train batch reward = 0.912
validation accuracy = 0.490		average validation NDCG = 0.867

epoch 2
average train loss = 0.000004    	average train batch reward = 0.919
validation accuracy = 0.407		average validation NDCG = 0.872

epoch 3
average train loss = -0.000010    	average train batch reward = 0.921
validation accuracy = 0.354		average validation NDCG = 0.881

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000013    	average train batch reward = 0.906
validation accuracy = 0.446		average validation NDCG = 0.859

epoch 2
average train loss = -0.000005    	average train batch reward = 0.909
validation accuracy = 0.456		average validation NDCG = 0.861

epoch 3
average train loss = -0.000019    	average train batch reward = 0.910
validation accuracy = 0.217		average validation NDCG = 0.823

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000022    	average train batch reward = 0.896
validation accuracy = 0.382		average validation NDCG = 0.834

epoch 2
average train loss = 0.000011    	average train batch reward = 0.902
validation accuracy = 0.347		average validation NDCG = 0.831

epoch 3
average train loss = 0.000010    	average train batch reward = 0.895
validation accuracy = 0.333		average validation NDCG = 0.814

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000015    	average train batch reward = 0.894
validation accuracy = 0.156		average validation NDCG = 0.839

epoch 2
average train loss = -0.000001    	average train batch reward = 0.898
validation accuracy = 0.474		average validation NDCG = 0.841

epoch 3
average train loss = -0.000010    	average train batch reward = 0.905
validation accuracy = 0.228		average validation NDCG = 0.830

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000030    	average train batch reward = 0.900
validation accuracy = 0.396		average validation NDCG = 0.846

epoch 2
average train loss = -0.000002    	average train batch reward = 0.912
validation accuracy = 0.528		average validation NDCG = 0.865

epoch 3
average train loss = -0.000005    	average train batch reward = 0.917
validation accuracy = 0.492		average validation NDCG = 0.876

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000002    	average train batch reward = 0.875
validation accuracy = 0.314		average validation NDCG = 0.828

epoch 2
average train loss = -0.000012    	average train batch reward = 0.872
validation accuracy = 0.446		average validation NDCG = 0.808

epoch 3
average train loss = 0.000003    	average train batch reward = 0.872
validation accuracy = 0.185		average validation NDCG = 0.800

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000021    	average train batch reward = 0.875
validation accuracy = 0.419		average validation NDCG = 0.824

epoch 2
average train loss = -0.000017    	average train batch reward = 0.879
validation accuracy = 0.322		average validation NDCG = 0.828

epoch 3
average train loss = 0.000009    	average train batch reward = 0.884
validation accuracy = 0.387		average validation NDCG = 0.846

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000001    	average train batch reward = 0.865
validation accuracy = 0.273		average validation NDCG = 0.816

epoch 2
average train loss = 0.000004    	average train batch reward = 0.870
validation accuracy = 0.258		average validation NDCG = 0.809

epoch 3
average train loss = 0.000005    	average train batch reward = 0.871
validation accuracy = 0.213		average validation NDCG = 0.816

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000005    	average train batch reward = 0.873
validation accuracy = 0.294		average validation NDCG = 0.810

epoch 2
average train loss = -0.000004    	average train batch reward = 0.871
validation accuracy = 0.300		average validation NDCG = 0.811

epoch 3
average train loss = -0.000015    	average train batch reward = 0.871
validation accuracy = 0.362		average validation NDCG = 0.815

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000010    	average train batch reward = 0.883
validation accuracy = 0.269		average validation NDCG = 0.860

epoch 2
average train loss = -0.000001    	average train batch reward = 0.887
validation accuracy = 0.362		average validation NDCG = 0.859

epoch 3
average train loss = 0.000010    	average train batch reward = 0.886
validation accuracy = 0.444		average validation NDCG = 0.858

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000008    	average train batch reward = 0.861
validation accuracy = 0.357		average validation NDCG = 0.881

epoch 2
average train loss = 0.000002    	average train batch reward = 0.861
validation accuracy = 0.434		average validation NDCG = 0.888

epoch 3
average train loss = -0.000004    	average train batch reward = 0.867
validation accuracy = 0.407		average validation NDCG = 0.877

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000015    	average train batch reward = 0.858
validation accuracy = 0.288		average validation NDCG = 0.845

epoch 2
average train loss = -0.000010    	average train batch reward = 0.859
validation accuracy = 0.388		average validation NDCG = 0.845

epoch 3
average train loss = 0.000005    	average train batch reward = 0.857
validation accuracy = 0.389		average validation NDCG = 0.844

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000021    	average train batch reward = 0.853
validation accuracy = 0.301		average validation NDCG = 0.811

epoch 2
average train loss = -0.000002    	average train batch reward = 0.854
validation accuracy = 0.222		average validation NDCG = 0.797

epoch 3
average train loss = -0.000005    	average train batch reward = 0.850
validation accuracy = 0.238		average validation NDCG = 0.798

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000015    	average train batch reward = 0.854
validation accuracy = 0.363		average validation NDCG = 0.830

epoch 2
average train loss = -0.000007    	average train batch reward = 0.857
validation accuracy = 0.438		average validation NDCG = 0.846

epoch 3
average train loss = -0.000001    	average train batch reward = 0.857
validation accuracy = 0.384		average validation NDCG = 0.834

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000005    	average train batch reward = 0.852
validation accuracy = 0.266		average validation NDCG = 0.780

epoch 2
average train loss = -0.000000    	average train batch reward = 0.851
validation accuracy = 0.281		average validation NDCG = 0.800

epoch 3
average train loss = -0.000005    	average train batch reward = 0.853
validation accuracy = 0.341		average validation NDCG = 0.808

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000013    	average train batch reward = 0.866
validation accuracy = 0.105		average validation NDCG = 0.727

epoch 2
average train loss = -0.000001    	average train batch reward = 0.862
validation accuracy = 0.139		average validation NDCG = 0.720

epoch 3
average train loss = -0.000001    	average train batch reward = 0.863
validation accuracy = 0.151		average validation NDCG = 0.726

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000007    	average train batch reward = 0.853
validation accuracy = 0.203		average validation NDCG = 0.725

epoch 2
average train loss = 0.000001    	average train batch reward = 0.864
validation accuracy = 0.089		average validation NDCG = 0.735

epoch 3
average train loss = -0.000004    	average train batch reward = 0.866
validation accuracy = 0.114		average validation NDCG = 0.723

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000005    	average train batch reward = 0.858
validation accuracy = 0.107		average validation NDCG = 0.700

epoch 2
average train loss = -0.000002    	average train batch reward = 0.856
validation accuracy = 0.106		average validation NDCG = 0.719

epoch 3
average train loss = 0.000004    	average train batch reward = 0.859
validation accuracy = 0.107		average validation NDCG = 0.711

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000008    	average train batch reward = 0.858
validation accuracy = 0.117		average validation NDCG = 0.707

epoch 2
average train loss = -0.000000    	average train batch reward = 0.856
validation accuracy = 0.110		average validation NDCG = 0.710

epoch 3
average train loss = 0.000005    	average train batch reward = 0.845
validation accuracy = 0.100		average validation NDCG = 0.675

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000009    	average train batch reward = 0.867
validation accuracy = 0.154		average validation NDCG = 0.725

epoch 2
average train loss = -0.000001    	average train batch reward = 0.859
validation accuracy = 0.189		average validation NDCG = 0.732

epoch 3
average train loss = -0.000003    	average train batch reward = 0.868
validation accuracy = 0.196		average validation NDCG = 0.730

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000009    	average train batch reward = 0.845
validation accuracy = 0.121		average validation NDCG = 0.714

epoch 2
average train loss = -0.000000    	average train batch reward = 0.853
validation accuracy = 0.189		average validation NDCG = 0.733

epoch 3
average train loss = -0.000001    	average train batch reward = 0.852
validation accuracy = 0.188		average validation NDCG = 0.732

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000002    	average train batch reward = 0.866
validation accuracy = 0.088		average validation NDCG = 0.733

epoch 2
average train loss = 0.000000    	average train batch reward = 0.851
validation accuracy = 0.108		average validation NDCG = 0.689

epoch 3
average train loss = -0.000000    	average train batch reward = 0.844
validation accuracy = 0.106		average validation NDCG = 0.686

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000004    	average train batch reward = 0.854
validation accuracy = 0.155		average validation NDCG = 0.751

epoch 2
average train loss = -0.000000    	average train batch reward = 0.862
validation accuracy = 0.073		average validation NDCG = 0.729

epoch 3
average train loss = -0.000000    	average train batch reward = 0.846
validation accuracy = 0.069		average validation NDCG = 0.698

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000002    	average train batch reward = 0.856
validation accuracy = 0.258		average validation NDCG = 0.737

epoch 2
average train loss = -0.000002    	average train batch reward = 0.855
validation accuracy = 0.118		average validation NDCG = 0.708

epoch 3
average train loss = -0.000003    	average train batch reward = 0.851
validation accuracy = 0.100		average validation NDCG = 0.708

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000006    	average train batch reward = 0.869
validation accuracy = 0.092		average validation NDCG = 0.738

epoch 2
average train loss = -0.000003    	average train batch reward = 0.868
validation accuracy = 0.131		average validation NDCG = 0.748

epoch 3
average train loss = -0.000001    	average train batch reward = 0.865
validation accuracy = 0.169		average validation NDCG = 0.763

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000003    	average train batch reward = 0.839
validation accuracy = 0.171		average validation NDCG = 0.709

epoch 2
average train loss = 0.000002    	average train batch reward = 0.844
validation accuracy = 0.198		average validation NDCG = 0.717

epoch 3
average train loss = 0.000002    	average train batch reward = 0.848
validation accuracy = 0.164		average validation NDCG = 0.722

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000006    	average train batch reward = 0.851
validation accuracy = 0.149		average validation NDCG = 0.711

epoch 2
average train loss = -0.000001    	average train batch reward = 0.846
validation accuracy = 0.103		average validation NDCG = 0.706

epoch 3
average train loss = -0.000003    	average train batch reward = 0.853
validation accuracy = 0.140		average validation NDCG = 0.737

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000003    	average train batch reward = 0.842
validation accuracy = 0.099		average validation NDCG = 0.686

epoch 2
average train loss = 0.000003    	average train batch reward = 0.843
validation accuracy = 0.134		average validation NDCG = 0.691

epoch 3
average train loss = -0.000000    	average train batch reward = 0.843
validation accuracy = 0.117		average validation NDCG = 0.690

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000008    	average train batch reward = 0.849
validation accuracy = 0.209		average validation NDCG = 0.745

epoch 2
average train loss = -0.000000    	average train batch reward = 0.860
validation accuracy = 0.201		average validation NDCG = 0.737

epoch 3
average train loss = 0.000000    	average train batch reward = 0.859
validation accuracy = 0.141		average validation NDCG = 0.740

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000008    	average train batch reward = 0.840
validation accuracy = 0.118		average validation NDCG = 0.693

epoch 2
average train loss = -0.000000    	average train batch reward = 0.838
validation accuracy = 0.118		average validation NDCG = 0.698

epoch 3
average train loss = -0.000002    	average train batch reward = 0.833
validation accuracy = 0.094		average validation NDCG = 0.673

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000004    	average train batch reward = 0.842
validation accuracy = 0.111		average validation NDCG = 0.707

epoch 2
average train loss = 0.000003    	average train batch reward = 0.843
validation accuracy = 0.115		average validation NDCG = 0.718

epoch 3
average train loss = -0.000000    	average train batch reward = 0.844
validation accuracy = 0.138		average validation NDCG = 0.724

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000005    	average train batch reward = 0.835
validation accuracy = 0.114		average validation NDCG = 0.688

epoch 2
average train loss = 0.000001    	average train batch reward = 0.839
validation accuracy = 0.153		average validation NDCG = 0.707

epoch 3
average train loss = -0.000002    	average train batch reward = 0.837
validation accuracy = 0.117		average validation NDCG = 0.695

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000002    	average train batch reward = 0.840
validation accuracy = 0.107		average validation NDCG = 0.703

epoch 2
average train loss = -0.000000    	average train batch reward = 0.839
validation accuracy = 0.103		average validation NDCG = 0.705

epoch 3
average train loss = 0.000000    	average train batch reward = 0.839
validation accuracy = 0.100		average validation NDCG = 0.686

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000013    	average train batch reward = 0.838
validation accuracy = 0.195		average validation NDCG = 0.745

epoch 2
average train loss = 0.000000    	average train batch reward = 0.850
validation accuracy = 0.122		average validation NDCG = 0.776

epoch 3
average train loss = 0.000000    	average train batch reward = 0.850
validation accuracy = 0.155		average validation NDCG = 0.765

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
Hyperparameters:
k = 2
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ab56af10320>
Reward function = <function ndcg_full at 0x2ab56af10398>
Greedy action = <function sample at 0x2ab563d139b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000003    	average train batch reward = 0.844
validation accuracy = 0.179		average validation NDCG = 0.747

epoch 2
average train loss = 0.000003    	average train batch reward = 0.845
validation accuracy = 0.113		average validation NDCG = 0.717

epoch 3
average train loss = -0.000002    	average train batch reward = 0.840
validation accuracy = 0.113		average validation NDCG = 0.697

========
Currently the best setups are [(0.001, 0.1, 0.2), (0.001, 0.25, 0.0), (0.001, 0.5, 1.0)], which got scores of [0.97981250826574962, 0.97625748835402282, 0.9754570878944]
========
2017-07-03 09:04:06
