2017-07-03 06:38:57
Finding best parameters for k = 4
=========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002622    	average train batch reward = 0.682
validation accuracy = 0.105		average validation NDCG = 0.679

epoch 2
average train loss = -0.000353    	average train batch reward = 0.683
validation accuracy = 0.107		average validation NDCG = 0.681

epoch 3
average train loss = 0.003899    	average train batch reward = 0.685
validation accuracy = 0.107		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.68169216696900803, -1, -1]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000498    	average train batch reward = 0.691
validation accuracy = 0.092		average validation NDCG = 0.684

epoch 2
average train loss = -0.006480    	average train batch reward = 0.694
validation accuracy = 0.093		average validation NDCG = 0.685

epoch 3
average train loss = -0.006828    	average train batch reward = 0.695
validation accuracy = 0.094		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), ()], which got scores of [0.68645268611944754, 0.68169216696900803, -1]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002774    	average train batch reward = 0.664
validation accuracy = 0.063		average validation NDCG = 0.650

epoch 2
average train loss = -0.001317    	average train batch reward = 0.665
validation accuracy = 0.064		average validation NDCG = 0.651

epoch 3
average train loss = -0.004815    	average train batch reward = 0.665
validation accuracy = 0.064		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.68645268611944754, 0.68169216696900803, 0.65142414959234751]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001241    	average train batch reward = 0.679
validation accuracy = 0.088		average validation NDCG = 0.670

epoch 2
average train loss = -0.006052    	average train batch reward = 0.682
validation accuracy = 0.090		average validation NDCG = 0.671

epoch 3
average train loss = -0.004240    	average train batch reward = 0.682
validation accuracy = 0.092		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.68645268611944754, 0.68169216696900803, 0.67189183352941007]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000212    	average train batch reward = 0.648
validation accuracy = 0.069		average validation NDCG = 0.643

epoch 2
average train loss = -0.002378    	average train batch reward = 0.650
validation accuracy = 0.069		average validation NDCG = 0.644

epoch 3
average train loss = -0.000772    	average train batch reward = 0.652
validation accuracy = 0.070		average validation NDCG = 0.644

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.68645268611944754, 0.68169216696900803, 0.67189183352941007]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000541    	average train batch reward = 0.682
validation accuracy = 0.061		average validation NDCG = 0.671

epoch 2
average train loss = -0.001548    	average train batch reward = 0.683
validation accuracy = 0.061		average validation NDCG = 0.672

epoch 3
average train loss = -0.000502    	average train batch reward = 0.684
validation accuracy = 0.061		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.25, 0.0)], which got scores of [0.68645268611944754, 0.68169216696900803, 0.67222043890648731]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004057    	average train batch reward = 0.680
validation accuracy = 0.104		average validation NDCG = 0.673

epoch 2
average train loss = 0.003115    	average train batch reward = 0.681
validation accuracy = 0.105		average validation NDCG = 0.674

epoch 3
average train loss = 0.001688    	average train batch reward = 0.681
validation accuracy = 0.106		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.25, 0.2)], which got scores of [0.68645268611944754, 0.68169216696900803, 0.67489866383735342]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000367    	average train batch reward = 0.690
validation accuracy = 0.136		average validation NDCG = 0.682

epoch 2
average train loss = -0.004487    	average train batch reward = 0.690
validation accuracy = 0.137		average validation NDCG = 0.683

epoch 3
average train loss = 0.006912    	average train batch reward = 0.693
validation accuracy = 0.137		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.25, 0.5), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.68645268611944754, 0.68399483910952719, 0.68169216696900803]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009954    	average train batch reward = 0.702
validation accuracy = 0.171		average validation NDCG = 0.695

epoch 2
average train loss = 0.007461    	average train batch reward = 0.703
validation accuracy = 0.173		average validation NDCG = 0.697

epoch 3
average train loss = 0.013481    	average train batch reward = 0.703
validation accuracy = 0.173		average validation NDCG = 0.697

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.69745249165390111, 0.68645268611944754, 0.68169216696900803]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007689    	average train batch reward = 0.711
validation accuracy = 0.137		average validation NDCG = 0.695

epoch 2
average train loss = 0.004614    	average train batch reward = 0.712
validation accuracy = 0.138		average validation NDCG = 0.696

epoch 3
average train loss = 0.004121    	average train batch reward = 0.715
validation accuracy = 0.139		average validation NDCG = 0.697

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002606    	average train batch reward = 0.683
validation accuracy = 0.108		average validation NDCG = 0.672

epoch 2
average train loss = 0.008714    	average train batch reward = 0.685
validation accuracy = 0.108		average validation NDCG = 0.672

epoch 3
average train loss = -0.003930    	average train batch reward = 0.686
validation accuracy = 0.110		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001040    	average train batch reward = 0.678
validation accuracy = 0.108		average validation NDCG = 0.664

epoch 2
average train loss = 0.000678    	average train batch reward = 0.680
validation accuracy = 0.107		average validation NDCG = 0.665

epoch 3
average train loss = -0.002339    	average train batch reward = 0.680
validation accuracy = 0.108		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001198    	average train batch reward = 0.667
validation accuracy = 0.066		average validation NDCG = 0.643

epoch 2
average train loss = -0.006881    	average train batch reward = 0.668
validation accuracy = 0.067		average validation NDCG = 0.643

epoch 3
average train loss = 0.007438    	average train batch reward = 0.671
validation accuracy = 0.067		average validation NDCG = 0.644

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003207    	average train batch reward = 0.675
validation accuracy = 0.063		average validation NDCG = 0.661

epoch 2
average train loss = -0.001797    	average train batch reward = 0.675
validation accuracy = 0.062		average validation NDCG = 0.662

epoch 3
average train loss = -0.004278    	average train batch reward = 0.674
validation accuracy = 0.062		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005294    	average train batch reward = 0.680
validation accuracy = 0.101		average validation NDCG = 0.663

epoch 2
average train loss = -0.000103    	average train batch reward = 0.681
validation accuracy = 0.101		average validation NDCG = 0.663

epoch 3
average train loss = 0.002024    	average train batch reward = 0.680
validation accuracy = 0.102		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000317    	average train batch reward = 0.682
validation accuracy = 0.109		average validation NDCG = 0.677

epoch 2
average train loss = -0.001283    	average train batch reward = 0.684
validation accuracy = 0.110		average validation NDCG = 0.678

epoch 3
average train loss = -0.013062    	average train batch reward = 0.681
validation accuracy = 0.111		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007828    	average train batch reward = 0.675
validation accuracy = 0.083		average validation NDCG = 0.646

epoch 2
average train loss = -0.006418    	average train batch reward = 0.676
validation accuracy = 0.083		average validation NDCG = 0.647

epoch 3
average train loss = 0.003430    	average train batch reward = 0.675
validation accuracy = 0.083		average validation NDCG = 0.647

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010104    	average train batch reward = 0.685
validation accuracy = 0.152		average validation NDCG = 0.681

epoch 2
average train loss = 0.003574    	average train batch reward = 0.686
validation accuracy = 0.154		average validation NDCG = 0.681

epoch 3
average train loss = 0.006278    	average train batch reward = 0.685
validation accuracy = 0.153		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.012275    	average train batch reward = 0.681
validation accuracy = 0.080		average validation NDCG = 0.661

epoch 2
average train loss = 0.002927    	average train batch reward = 0.680
validation accuracy = 0.081		average validation NDCG = 0.662

epoch 3
average train loss = -0.001057    	average train batch reward = 0.680
validation accuracy = 0.082		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68645268611944754]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004190    	average train batch reward = 0.686
validation accuracy = 0.070		average validation NDCG = 0.688

epoch 2
average train loss = 0.013751    	average train batch reward = 0.687
validation accuracy = 0.070		average validation NDCG = 0.688

epoch 3
average train loss = 0.003828    	average train batch reward = 0.687
validation accuracy = 0.070		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.69745249165390111, 0.6973613857893356, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002556    	average train batch reward = 0.679
validation accuracy = 0.100		average validation NDCG = 0.677

epoch 2
average train loss = 0.002302    	average train batch reward = 0.693
validation accuracy = 0.111		average validation NDCG = 0.690

epoch 3
average train loss = 0.006156    	average train batch reward = 0.704
validation accuracy = 0.117		average validation NDCG = 0.698

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.0), (9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.69831900015882098, 0.69745249165390111, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015285    	average train batch reward = 0.661
validation accuracy = 0.059		average validation NDCG = 0.665

epoch 2
average train loss = -0.005808    	average train batch reward = 0.675
validation accuracy = 0.064		average validation NDCG = 0.675

epoch 3
average train loss = -0.003992    	average train batch reward = 0.687
validation accuracy = 0.070		average validation NDCG = 0.686

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.0), (9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.69831900015882098, 0.69745249165390111, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000738    	average train batch reward = 0.682
validation accuracy = 0.073		average validation NDCG = 0.680

epoch 2
average train loss = -0.002398    	average train batch reward = 0.693
validation accuracy = 0.077		average validation NDCG = 0.696

epoch 3
average train loss = 0.000306    	average train batch reward = 0.706
validation accuracy = 0.085		average validation NDCG = 0.711

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.71068510833339649, 0.69831900015882098, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007390    	average train batch reward = 0.711
validation accuracy = 0.147		average validation NDCG = 0.696

epoch 2
average train loss = 0.000573    	average train batch reward = 0.720
validation accuracy = 0.152		average validation NDCG = 0.706

epoch 3
average train loss = 0.003357    	average train batch reward = 0.732
validation accuracy = 0.162		average validation NDCG = 0.720

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001981    	average train batch reward = 0.668
validation accuracy = 0.075		average validation NDCG = 0.662

epoch 2
average train loss = 0.001742    	average train batch reward = 0.683
validation accuracy = 0.082		average validation NDCG = 0.672

epoch 3
average train loss = 0.004310    	average train batch reward = 0.695
validation accuracy = 0.091		average validation NDCG = 0.684

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.5)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.68927073905037373]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001511    	average train batch reward = 0.683
validation accuracy = 0.124		average validation NDCG = 0.670

epoch 2
average train loss = 0.003594    	average train batch reward = 0.690
validation accuracy = 0.135		average validation NDCG = 0.680

epoch 3
average train loss = 0.007810    	average train batch reward = 0.700
validation accuracy = 0.144		average validation NDCG = 0.691

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 0.0)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.69064579282803451]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002183    	average train batch reward = 0.679
validation accuracy = 0.085		average validation NDCG = 0.677

epoch 2
average train loss = -0.000516    	average train batch reward = 0.689
validation accuracy = 0.092		average validation NDCG = 0.686

epoch 3
average train loss = 0.002303    	average train batch reward = 0.699
validation accuracy = 0.102		average validation NDCG = 0.701

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 0.2)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.7006831083429228]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001975    	average train batch reward = 0.680
validation accuracy = 0.099		average validation NDCG = 0.676

epoch 2
average train loss = -0.001757    	average train batch reward = 0.688
validation accuracy = 0.100		average validation NDCG = 0.685

epoch 3
average train loss = 0.001001    	average train batch reward = 0.699
validation accuracy = 0.106		average validation NDCG = 0.692

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 0.2)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.7006831083429228]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001599    	average train batch reward = 0.686
validation accuracy = 0.117		average validation NDCG = 0.676

epoch 2
average train loss = 0.009657    	average train batch reward = 0.695
validation accuracy = 0.125		average validation NDCG = 0.684

epoch 3
average train loss = 0.009631    	average train batch reward = 0.703
validation accuracy = 0.137		average validation NDCG = 0.691

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 0.2)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.7006831083429228]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002997    	average train batch reward = 0.699
validation accuracy = 0.115		average validation NDCG = 0.690

epoch 2
average train loss = 0.002349    	average train batch reward = 0.707
validation accuracy = 0.119		average validation NDCG = 0.696

epoch 3
average train loss = 0.007878    	average train batch reward = 0.711
validation accuracy = 0.129		average validation NDCG = 0.706

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.1, 0.5), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72039911352908459, 0.71068510833339649, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003805    	average train batch reward = 0.700
validation accuracy = 0.127		average validation NDCG = 0.709

epoch 2
average train loss = -0.003015    	average train batch reward = 0.705
validation accuracy = 0.138		average validation NDCG = 0.719

epoch 3
average train loss = 0.002049    	average train batch reward = 0.710
validation accuracy = 0.145		average validation NDCG = 0.727

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000321    	average train batch reward = 0.676
validation accuracy = 0.057		average validation NDCG = 0.671

epoch 2
average train loss = 0.007487    	average train batch reward = 0.683
validation accuracy = 0.061		average validation NDCG = 0.679

epoch 3
average train loss = 0.007646    	average train batch reward = 0.688
validation accuracy = 0.067		average validation NDCG = 0.693

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003208    	average train batch reward = 0.676
validation accuracy = 0.076		average validation NDCG = 0.672

epoch 2
average train loss = -0.006858    	average train batch reward = 0.683
validation accuracy = 0.079		average validation NDCG = 0.683

epoch 3
average train loss = -0.012143    	average train batch reward = 0.690
validation accuracy = 0.086		average validation NDCG = 0.694

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005397    	average train batch reward = 0.679
validation accuracy = 0.122		average validation NDCG = 0.668

epoch 2
average train loss = 0.001412    	average train batch reward = 0.684
validation accuracy = 0.130		average validation NDCG = 0.674

epoch 3
average train loss = 0.004953    	average train batch reward = 0.688
validation accuracy = 0.141		average validation NDCG = 0.684

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004913    	average train batch reward = 0.689
validation accuracy = 0.117		average validation NDCG = 0.684

epoch 2
average train loss = 0.002484    	average train batch reward = 0.695
validation accuracy = 0.117		average validation NDCG = 0.694

epoch 3
average train loss = 0.001263    	average train batch reward = 0.700
validation accuracy = 0.131		average validation NDCG = 0.704

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005901    	average train batch reward = 0.677
validation accuracy = 0.103		average validation NDCG = 0.653

epoch 2
average train loss = -0.004732    	average train batch reward = 0.680
validation accuracy = 0.106		average validation NDCG = 0.656

epoch 3
average train loss = 0.006036    	average train batch reward = 0.681
validation accuracy = 0.111		average validation NDCG = 0.661

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000839    	average train batch reward = 0.681
validation accuracy = 0.083		average validation NDCG = 0.665

epoch 2
average train loss = 0.003311    	average train batch reward = 0.682
validation accuracy = 0.091		average validation NDCG = 0.671

epoch 3
average train loss = 0.003021    	average train batch reward = 0.684
validation accuracy = 0.098		average validation NDCG = 0.679

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005653    	average train batch reward = 0.678
validation accuracy = 0.096		average validation NDCG = 0.676

epoch 2
average train loss = 0.011562    	average train batch reward = 0.682
validation accuracy = 0.100		average validation NDCG = 0.681

epoch 3
average train loss = -0.000278    	average train batch reward = 0.684
validation accuracy = 0.102		average validation NDCG = 0.691

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003911    	average train batch reward = 0.683
validation accuracy = 0.103		average validation NDCG = 0.685

epoch 2
average train loss = -0.007030    	average train batch reward = 0.686
validation accuracy = 0.114		average validation NDCG = 0.695

epoch 3
average train loss = 0.021430    	average train batch reward = 0.688
validation accuracy = 0.122		average validation NDCG = 0.703

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000262    	average train batch reward = 0.679
validation accuracy = 0.119		average validation NDCG = 0.672

epoch 2
average train loss = -0.002625    	average train batch reward = 0.680
validation accuracy = 0.122		average validation NDCG = 0.679

epoch 3
average train loss = -0.003820    	average train batch reward = 0.683
validation accuracy = 0.127		average validation NDCG = 0.683

========
Currently the best setups are [(1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.1, 1.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.72710069848784409, 0.72039911352908459, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006671    	average train batch reward = 0.694
validation accuracy = 0.041		average validation NDCG = 0.744

epoch 2
average train loss = -0.015182    	average train batch reward = 0.767
validation accuracy = 0.028		average validation NDCG = 0.801

epoch 3
average train loss = -0.012607    	average train batch reward = 0.794
validation accuracy = 0.026		average validation NDCG = 0.836

========
Currently the best setups are [(0.0001, 0.1, 0.0), (1.0000000000000001e-05, 0.5, 0.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.83593151508336061, 0.72710069848784409, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005250    	average train batch reward = 0.722
validation accuracy = 0.169		average validation NDCG = 0.778

epoch 2
average train loss = 0.013918    	average train batch reward = 0.816
validation accuracy = 0.307		average validation NDCG = 0.868

epoch 3
average train loss = 0.017575    	average train batch reward = 0.860
validation accuracy = 0.340		average validation NDCG = 0.898

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 1.5)], which got scores of [0.89783915056239982, 0.83593151508336061, 0.70591516278502275]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005264    	average train batch reward = 0.716
validation accuracy = 0.161		average validation NDCG = 0.770

epoch 2
average train loss = 0.014565    	average train batch reward = 0.792
validation accuracy = 0.272		average validation NDCG = 0.829

epoch 3
average train loss = 0.008783    	average train batch reward = 0.835
validation accuracy = 0.294		average validation NDCG = 0.881

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.1, 0.0)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.83593151508336061]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011154    	average train batch reward = 0.727
validation accuracy = 0.167		average validation NDCG = 0.773

epoch 2
average train loss = 0.006542    	average train batch reward = 0.786
validation accuracy = 0.183		average validation NDCG = 0.823

epoch 3
average train loss = 0.006083    	average train batch reward = 0.811
validation accuracy = 0.163		average validation NDCG = 0.845

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.1, 1.0)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.84494344413492417]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004141    	average train batch reward = 0.731
validation accuracy = 0.150		average validation NDCG = 0.778

epoch 2
average train loss = 0.005717    	average train batch reward = 0.812
validation accuracy = 0.136		average validation NDCG = 0.844

epoch 3
average train loss = 0.006745    	average train batch reward = 0.834
validation accuracy = 0.123		average validation NDCG = 0.860

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.1, 1.5)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.86045797657900458]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006054    	average train batch reward = 0.719
validation accuracy = 0.190		average validation NDCG = 0.773

epoch 2
average train loss = 0.006154    	average train batch reward = 0.770
validation accuracy = 0.200		average validation NDCG = 0.811

epoch 3
average train loss = 0.004044    	average train batch reward = 0.788
validation accuracy = 0.241		average validation NDCG = 0.838

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.1, 1.5)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.86045797657900458]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006463    	average train batch reward = 0.740
validation accuracy = 0.251		average validation NDCG = 0.774

epoch 2
average train loss = 0.023610    	average train batch reward = 0.797
validation accuracy = 0.401		average validation NDCG = 0.843

epoch 3
average train loss = 0.019395    	average train batch reward = 0.822
validation accuracy = 0.490		average validation NDCG = 0.869

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.2)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.86881760154431897]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003449    	average train batch reward = 0.721
validation accuracy = 0.193		average validation NDCG = 0.780

epoch 2
average train loss = 0.014383    	average train batch reward = 0.771
validation accuracy = 0.338		average validation NDCG = 0.837

epoch 3
average train loss = 0.011835    	average train batch reward = 0.803
validation accuracy = 0.379		average validation NDCG = 0.863

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.25, 0.2)], which got scores of [0.89783915056239982, 0.88086182146487357, 0.86881760154431897]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000440    	average train batch reward = 0.728
validation accuracy = 0.138		average validation NDCG = 0.779

epoch 2
average train loss = 0.011436    	average train batch reward = 0.782
validation accuracy = 0.201		average validation NDCG = 0.846

epoch 3
average train loss = 0.015968    	average train batch reward = 0.811
validation accuracy = 0.262		average validation NDCG = 0.884

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006871    	average train batch reward = 0.717
validation accuracy = 0.261		average validation NDCG = 0.756

epoch 2
average train loss = 0.017971    	average train batch reward = 0.767
validation accuracy = 0.380		average validation NDCG = 0.822

epoch 3
average train loss = 0.012478    	average train batch reward = 0.800
validation accuracy = 0.496		average validation NDCG = 0.857

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013903    	average train batch reward = 0.706
validation accuracy = 0.274		average validation NDCG = 0.757

epoch 2
average train loss = 0.015503    	average train batch reward = 0.745
validation accuracy = 0.357		average validation NDCG = 0.822

epoch 3
average train loss = 0.012903    	average train batch reward = 0.761
validation accuracy = 0.413		average validation NDCG = 0.849

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009122    	average train batch reward = 0.712
validation accuracy = 0.239		average validation NDCG = 0.755

epoch 2
average train loss = 0.008767    	average train batch reward = 0.740
validation accuracy = 0.353		average validation NDCG = 0.806

epoch 3
average train loss = 0.008392    	average train batch reward = 0.755
validation accuracy = 0.396		average validation NDCG = 0.843

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010791    	average train batch reward = 0.712
validation accuracy = 0.133		average validation NDCG = 0.780

epoch 2
average train loss = 0.010280    	average train batch reward = 0.746
validation accuracy = 0.266		average validation NDCG = 0.836

epoch 3
average train loss = 0.020360    	average train batch reward = 0.768
validation accuracy = 0.321		average validation NDCG = 0.876

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011528    	average train batch reward = 0.703
validation accuracy = 0.187		average validation NDCG = 0.736

epoch 2
average train loss = 0.013894    	average train batch reward = 0.722
validation accuracy = 0.213		average validation NDCG = 0.761

epoch 3
average train loss = 0.011847    	average train batch reward = 0.740
validation accuracy = 0.243		average validation NDCG = 0.807

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008919    	average train batch reward = 0.694
validation accuracy = 0.173		average validation NDCG = 0.740

epoch 2
average train loss = 0.017018    	average train batch reward = 0.727
validation accuracy = 0.184		average validation NDCG = 0.786

epoch 3
average train loss = 0.008172    	average train batch reward = 0.744
validation accuracy = 0.228		average validation NDCG = 0.818

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003900    	average train batch reward = 0.690
validation accuracy = 0.149		average validation NDCG = 0.726

epoch 2
average train loss = 0.011078    	average train batch reward = 0.704
validation accuracy = 0.215		average validation NDCG = 0.758

epoch 3
average train loss = 0.012892    	average train batch reward = 0.712
validation accuracy = 0.276		average validation NDCG = 0.802

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009093    	average train batch reward = 0.685
validation accuracy = 0.148		average validation NDCG = 0.725

epoch 2
average train loss = 0.018325    	average train batch reward = 0.705
validation accuracy = 0.212		average validation NDCG = 0.798

epoch 3
average train loss = 0.042066    	average train batch reward = 0.712
validation accuracy = 0.146		average validation NDCG = 0.807

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001787    	average train batch reward = 0.688
validation accuracy = 0.103		average validation NDCG = 0.720

epoch 2
average train loss = 0.020891    	average train batch reward = 0.710
validation accuracy = 0.127		average validation NDCG = 0.793

epoch 3
average train loss = 0.045814    	average train batch reward = 0.720
validation accuracy = 0.164		average validation NDCG = 0.834

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.021128    	average train batch reward = 0.695
validation accuracy = 0.226		average validation NDCG = 0.748

epoch 2
average train loss = 0.018161    	average train batch reward = 0.707
validation accuracy = 0.298		average validation NDCG = 0.792

epoch 3
average train loss = 0.006666    	average train batch reward = 0.716
validation accuracy = 0.335		average validation NDCG = 0.825

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005107    	average train batch reward = 0.692
validation accuracy = 0.130		average validation NDCG = 0.735

epoch 2
average train loss = 0.006977    	average train batch reward = 0.705
validation accuracy = 0.145		average validation NDCG = 0.772

epoch 3
average train loss = 0.007189    	average train batch reward = 0.706
validation accuracy = 0.209		average validation NDCG = 0.783

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.014905    	average train batch reward = 0.739
validation accuracy = 0.245		average validation NDCG = 0.788

epoch 2
average train loss = 0.013166    	average train batch reward = 0.785
validation accuracy = 0.370		average validation NDCG = 0.820

epoch 3
average train loss = 0.012314    	average train batch reward = 0.819
validation accuracy = 0.272		average validation NDCG = 0.864

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005284    	average train batch reward = 0.769
validation accuracy = 0.121		average validation NDCG = 0.797

epoch 2
average train loss = 0.000896    	average train batch reward = 0.778
validation accuracy = 0.059		average validation NDCG = 0.776

epoch 3
average train loss = -0.011887    	average train batch reward = 0.756
validation accuracy = 0.070		average validation NDCG = 0.799

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010641    	average train batch reward = 0.767
validation accuracy = 0.332		average validation NDCG = 0.793

epoch 2
average train loss = 0.006588    	average train batch reward = 0.772
validation accuracy = 0.288		average validation NDCG = 0.790

epoch 3
average train loss = 0.010533    	average train batch reward = 0.777
validation accuracy = 0.157		average validation NDCG = 0.787

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009330    	average train batch reward = 0.757
validation accuracy = 0.285		average validation NDCG = 0.813

epoch 2
average train loss = 0.016258    	average train batch reward = 0.818
validation accuracy = 0.300		average validation NDCG = 0.828

epoch 3
average train loss = 0.013330    	average train batch reward = 0.806
validation accuracy = 0.182		average validation NDCG = 0.801

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013641    	average train batch reward = 0.803
validation accuracy = 0.346		average validation NDCG = 0.852

epoch 2
average train loss = 0.017639    	average train batch reward = 0.824
validation accuracy = 0.447		average validation NDCG = 0.855

epoch 3
average train loss = 0.003014    	average train batch reward = 0.827
validation accuracy = 0.264		average validation NDCG = 0.835

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015324    	average train batch reward = 0.746
validation accuracy = 0.229		average validation NDCG = 0.802

epoch 2
average train loss = 0.011293    	average train batch reward = 0.770
validation accuracy = 0.146		average validation NDCG = 0.800

epoch 3
average train loss = 0.013993    	average train batch reward = 0.747
validation accuracy = 0.194		average validation NDCG = 0.763

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009356    	average train batch reward = 0.717
validation accuracy = 0.002		average validation NDCG = 0.769

epoch 2
average train loss = 0.003652    	average train batch reward = 0.734
validation accuracy = 0.003		average validation NDCG = 0.772

epoch 3
average train loss = -0.001566    	average train batch reward = 0.746
validation accuracy = 0.007		average validation NDCG = 0.785

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011648    	average train batch reward = 0.740
validation accuracy = 0.288		average validation NDCG = 0.783

epoch 2
average train loss = -0.001280    	average train batch reward = 0.771
validation accuracy = 0.390		average validation NDCG = 0.818

epoch 3
average train loss = 0.010292    	average train batch reward = 0.777
validation accuracy = 0.286		average validation NDCG = 0.802

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003442    	average train batch reward = 0.733
validation accuracy = 0.126		average validation NDCG = 0.774

epoch 2
average train loss = 0.002325    	average train batch reward = 0.750
validation accuracy = 0.151		average validation NDCG = 0.794

epoch 3
average train loss = -0.000114    	average train batch reward = 0.740
validation accuracy = 0.091		average validation NDCG = 0.775

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000148    	average train batch reward = 0.732
validation accuracy = 0.178		average validation NDCG = 0.796

epoch 2
average train loss = -0.006602    	average train batch reward = 0.759
validation accuracy = 0.123		average validation NDCG = 0.798

epoch 3
average train loss = 0.008240    	average train batch reward = 0.755
validation accuracy = 0.118		average validation NDCG = 0.764

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.020920    	average train batch reward = 0.709
validation accuracy = 0.201		average validation NDCG = 0.742

epoch 2
average train loss = 0.001862    	average train batch reward = 0.719
validation accuracy = 0.222		average validation NDCG = 0.769

epoch 3
average train loss = 0.012048    	average train batch reward = 0.720
validation accuracy = 0.225		average validation NDCG = 0.748

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009004    	average train batch reward = 0.716
validation accuracy = 0.309		average validation NDCG = 0.788

epoch 2
average train loss = -0.003717    	average train batch reward = 0.741
validation accuracy = 0.436		average validation NDCG = 0.823

epoch 3
average train loss = 0.039714    	average train batch reward = 0.751
validation accuracy = 0.279		average validation NDCG = 0.820

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009483    	average train batch reward = 0.688
validation accuracy = 0.064		average validation NDCG = 0.728

epoch 2
average train loss = -0.029047    	average train batch reward = 0.711
validation accuracy = 0.044		average validation NDCG = 0.739

epoch 3
average train loss = 0.019161    	average train batch reward = 0.714
validation accuracy = 0.044		average validation NDCG = 0.757

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002296    	average train batch reward = 0.727
validation accuracy = 0.312		average validation NDCG = 0.796

epoch 2
average train loss = 0.016819    	average train batch reward = 0.741
validation accuracy = 0.314		average validation NDCG = 0.785

epoch 3
average train loss = 0.001855    	average train batch reward = 0.737
validation accuracy = 0.352		average validation NDCG = 0.775

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001900    	average train batch reward = 0.711
validation accuracy = 0.035		average validation NDCG = 0.757

epoch 2
average train loss = -0.030587    	average train batch reward = 0.719
validation accuracy = 0.098		average validation NDCG = 0.758

epoch 3
average train loss = -0.002185    	average train batch reward = 0.725
validation accuracy = 0.058		average validation NDCG = 0.774

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010380    	average train batch reward = 0.682
validation accuracy = 0.114		average validation NDCG = 0.675

epoch 2
average train loss = -0.012079    	average train batch reward = 0.682
validation accuracy = 0.109		average validation NDCG = 0.681

epoch 3
average train loss = -0.001483    	average train batch reward = 0.688
validation accuracy = 0.103		average validation NDCG = 0.699

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000031    	average train batch reward = 0.684
validation accuracy = 0.142		average validation NDCG = 0.688

epoch 2
average train loss = -0.001988    	average train batch reward = 0.686
validation accuracy = 0.096		average validation NDCG = 0.690

epoch 3
average train loss = -0.006870    	average train batch reward = 0.682
validation accuracy = 0.023		average validation NDCG = 0.686

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012690    	average train batch reward = 0.693
validation accuracy = 0.247		average validation NDCG = 0.743

epoch 2
average train loss = 0.051220    	average train batch reward = 0.703
validation accuracy = 0.208		average validation NDCG = 0.755

epoch 3
average train loss = 0.014382    	average train batch reward = 0.699
validation accuracy = 0.186		average validation NDCG = 0.752

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003407    	average train batch reward = 0.702
validation accuracy = 0.291		average validation NDCG = 0.803

epoch 2
average train loss = 0.030367    	average train batch reward = 0.719
validation accuracy = 0.346		average validation NDCG = 0.837

epoch 3
average train loss = -0.045704    	average train batch reward = 0.722
validation accuracy = 0.431		average validation NDCG = 0.822

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.034944    	average train batch reward = 0.699
validation accuracy = 0.236		average validation NDCG = 0.749

epoch 2
average train loss = 0.000447    	average train batch reward = 0.704
validation accuracy = 0.255		average validation NDCG = 0.738

epoch 3
average train loss = -0.007649    	average train batch reward = 0.700
validation accuracy = 0.209		average validation NDCG = 0.742

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001464    	average train batch reward = 0.696
validation accuracy = 0.099		average validation NDCG = 0.684

epoch 2
average train loss = 0.039305    	average train batch reward = 0.689
validation accuracy = 0.084		average validation NDCG = 0.669

epoch 3
average train loss = 0.004338    	average train batch reward = 0.692
validation accuracy = 0.130		average validation NDCG = 0.677

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.016703    	average train batch reward = 0.692
validation accuracy = 0.084		average validation NDCG = 0.665

epoch 2
average train loss = -0.002445    	average train batch reward = 0.683
validation accuracy = 0.107		average validation NDCG = 0.680

epoch 3
average train loss = -0.011714    	average train batch reward = 0.686
validation accuracy = 0.085		average validation NDCG = 0.670

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.021844    	average train batch reward = 0.716
validation accuracy = 0.142		average validation NDCG = 0.700

epoch 2
average train loss = 0.006433    	average train batch reward = 0.699
validation accuracy = 0.137		average validation NDCG = 0.676

epoch 3
average train loss = 0.018344    	average train batch reward = 0.687
validation accuracy = 0.083		average validation NDCG = 0.684

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009287    	average train batch reward = 0.713
validation accuracy = 0.160		average validation NDCG = 0.720

epoch 2
average train loss = 0.001362    	average train batch reward = 0.700
validation accuracy = 0.101		average validation NDCG = 0.697

epoch 3
average train loss = -0.001999    	average train batch reward = 0.695
validation accuracy = 0.117		average validation NDCG = 0.693

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014990    	average train batch reward = 0.686
validation accuracy = 0.113		average validation NDCG = 0.660

epoch 2
average train loss = 0.010399    	average train batch reward = 0.664
validation accuracy = 0.092		average validation NDCG = 0.663

epoch 3
average train loss = -0.053478    	average train batch reward = 0.669
validation accuracy = 0.057		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.018918    	average train batch reward = 0.713
validation accuracy = 0.182		average validation NDCG = 0.707

epoch 2
average train loss = 0.019799    	average train batch reward = 0.705
validation accuracy = 0.174		average validation NDCG = 0.700

epoch 3
average train loss = 0.001323    	average train batch reward = 0.708
validation accuracy = 0.185		average validation NDCG = 0.703

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004024    	average train batch reward = 0.704
validation accuracy = 0.130		average validation NDCG = 0.687

epoch 2
average train loss = -0.066096    	average train batch reward = 0.688
validation accuracy = 0.067		average validation NDCG = 0.680

epoch 3
average train loss = 0.183827    	average train batch reward = 0.683
validation accuracy = 0.091		average validation NDCG = 0.679

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.039733    	average train batch reward = 0.704
validation accuracy = 0.119		average validation NDCG = 0.689

epoch 2
average train loss = 0.022187    	average train batch reward = 0.700
validation accuracy = 0.099		average validation NDCG = 0.710

epoch 3
average train loss = -0.020995    	average train batch reward = 0.692
validation accuracy = 0.111		average validation NDCG = 0.681

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.062529    	average train batch reward = 0.697
validation accuracy = 0.126		average validation NDCG = 0.672

epoch 2
average train loss = 0.029382    	average train batch reward = 0.694
validation accuracy = 0.094		average validation NDCG = 0.674

epoch 3
average train loss = 0.072422    	average train batch reward = 0.688
validation accuracy = 0.094		average validation NDCG = 0.674

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007655    	average train batch reward = 0.696
validation accuracy = 0.060		average validation NDCG = 0.675

epoch 2
average train loss = -0.006799    	average train batch reward = 0.679
validation accuracy = 0.098		average validation NDCG = 0.684

epoch 3
average train loss = -0.022363    	average train batch reward = 0.683
validation accuracy = 0.066		average validation NDCG = 0.690

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.031690    	average train batch reward = 0.701
validation accuracy = 0.059		average validation NDCG = 0.704

epoch 2
average train loss = -0.060056    	average train batch reward = 0.685
validation accuracy = 0.144		average validation NDCG = 0.668

epoch 3
average train loss = -0.010576    	average train batch reward = 0.679
validation accuracy = 0.111		average validation NDCG = 0.667

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.020811    	average train batch reward = 0.694
validation accuracy = 0.065		average validation NDCG = 0.695

epoch 2
average train loss = 0.030672    	average train batch reward = 0.680
validation accuracy = 0.049		average validation NDCG = 0.672

epoch 3
average train loss = -0.021535    	average train batch reward = 0.685
validation accuracy = 0.108		average validation NDCG = 0.680

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.088258    	average train batch reward = 0.669
validation accuracy = 0.049		average validation NDCG = 0.654

epoch 2
average train loss = 0.001889    	average train batch reward = 0.672
validation accuracy = 0.045		average validation NDCG = 0.655

epoch 3
average train loss = -0.058636    	average train batch reward = 0.677
validation accuracy = 0.081		average validation NDCG = 0.659

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005779    	average train batch reward = 0.686
validation accuracy = 0.075		average validation NDCG = 0.675

epoch 2
average train loss = -0.022124    	average train batch reward = 0.683
validation accuracy = 0.085		average validation NDCG = 0.666

epoch 3
average train loss = -0.178963    	average train batch reward = 0.678
validation accuracy = 0.128		average validation NDCG = 0.680

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.058427    	average train batch reward = 0.681
validation accuracy = 0.023		average validation NDCG = 0.666

epoch 2
average train loss = -0.002257    	average train batch reward = 0.688
validation accuracy = 0.082		average validation NDCG = 0.688

epoch 3
average train loss = -0.001646    	average train batch reward = 0.691
validation accuracy = 0.090		average validation NDCG = 0.690

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.072264    	average train batch reward = 0.697
validation accuracy = 0.207		average validation NDCG = 0.753

epoch 2
average train loss = -0.041276    	average train batch reward = 0.695
validation accuracy = 0.126		average validation NDCG = 0.719

epoch 3
average train loss = 0.162806    	average train batch reward = 0.691
validation accuracy = 0.123		average validation NDCG = 0.700

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.117891    	average train batch reward = 0.689
validation accuracy = 0.120		average validation NDCG = 0.696

epoch 2
average train loss = 0.018640    	average train batch reward = 0.687
validation accuracy = 0.106		average validation NDCG = 0.690

epoch 3
average train loss = -0.032653    	average train batch reward = 0.684
validation accuracy = 0.044		average validation NDCG = 0.685

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.054480    	average train batch reward = 0.683
validation accuracy = 0.095		average validation NDCG = 0.665

epoch 2
average train loss = -0.000963    	average train batch reward = 0.680
validation accuracy = 0.083		average validation NDCG = 0.674

epoch 3
average train loss = 0.058423    	average train batch reward = 0.684
validation accuracy = 0.044		average validation NDCG = 0.675

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009544    	average train batch reward = 0.686
validation accuracy = 0.094		average validation NDCG = 0.696

epoch 2
average train loss = -0.012533    	average train batch reward = 0.687
validation accuracy = 0.103		average validation NDCG = 0.679

epoch 3
average train loss = -0.056950    	average train batch reward = 0.689
validation accuracy = 0.148		average validation NDCG = 0.701

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000338    	average train batch reward = 0.682
validation accuracy = 0.099		average validation NDCG = 0.669

epoch 2
average train loss = 0.060577    	average train batch reward = 0.680
validation accuracy = 0.099		average validation NDCG = 0.656

epoch 3
average train loss = -0.057389    	average train batch reward = 0.676
validation accuracy = 0.099		average validation NDCG = 0.647

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.034487    	average train batch reward = 0.676
validation accuracy = 0.094		average validation NDCG = 0.663

epoch 2
average train loss = -0.318569    	average train batch reward = 0.677
validation accuracy = 0.110		average validation NDCG = 0.675

epoch 3
average train loss = -0.248696    	average train batch reward = 0.692
validation accuracy = 0.126		average validation NDCG = 0.667

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.154443    	average train batch reward = 0.688
validation accuracy = 0.099		average validation NDCG = 0.682

epoch 2
average train loss = 0.108566    	average train batch reward = 0.684
validation accuracy = 0.099		average validation NDCG = 0.671

epoch 3
average train loss = 0.000001    	average train batch reward = 0.680
validation accuracy = 0.099		average validation NDCG = 0.671

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.193882    	average train batch reward = 0.699
validation accuracy = 0.099		average validation NDCG = 0.675

epoch 2
average train loss = 0.101539    	average train batch reward = 0.694
validation accuracy = 0.096		average validation NDCG = 0.692

epoch 3
average train loss = 0.000000    	average train batch reward = 0.699
validation accuracy = 0.096		average validation NDCG = 0.690

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.049726    	average train batch reward = 0.699
validation accuracy = 0.162		average validation NDCG = 0.672

epoch 2
average train loss = 0.700674    	average train batch reward = 0.686
validation accuracy = 0.109		average validation NDCG = 0.676

epoch 3
average train loss = 0.000000    	average train batch reward = 0.692
validation accuracy = 0.104		average validation NDCG = 0.676

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.063498    	average train batch reward = 0.680
validation accuracy = 0.092		average validation NDCG = 0.677

epoch 2
average train loss = 0.000002    	average train batch reward = 0.677
validation accuracy = 0.092		average validation NDCG = 0.676

epoch 3
average train loss = 0.000000    	average train batch reward = 0.688
validation accuracy = 0.093		average validation NDCG = 0.680

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.033115    	average train batch reward = 0.679
validation accuracy = 0.111		average validation NDCG = 0.677

epoch 2
average train loss = 0.000016    	average train batch reward = 0.678
validation accuracy = 0.110		average validation NDCG = 0.678

epoch 3
average train loss = -0.000000    	average train batch reward = 0.679
validation accuracy = 0.110		average validation NDCG = 0.678

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.346394    	average train batch reward = 0.681
validation accuracy = 0.105		average validation NDCG = 0.674

epoch 2
average train loss = -0.937900    	average train batch reward = 0.680
validation accuracy = 0.070		average validation NDCG = 0.677

epoch 3
average train loss = -0.000000    	average train batch reward = 0.684
validation accuracy = 0.071		average validation NDCG = 0.677

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012120    	average train batch reward = 0.676
validation accuracy = 0.128		average validation NDCG = 0.669

epoch 2
average train loss = -0.454878    	average train batch reward = 0.680
validation accuracy = 0.101		average validation NDCG = 0.671

epoch 3
average train loss = 0.000036    	average train batch reward = 0.681
validation accuracy = 0.101		average validation NDCG = 0.670

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.055244    	average train batch reward = 0.688
validation accuracy = 0.098		average validation NDCG = 0.701

epoch 2
average train loss = 0.377165    	average train batch reward = 0.690
validation accuracy = 0.099		average validation NDCG = 0.678

epoch 3
average train loss = 0.980748    	average train batch reward = 0.689
validation accuracy = 0.055		average validation NDCG = 0.686

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004395    	average train batch reward = 0.688
validation accuracy = 0.131		average validation NDCG = 0.678

epoch 2
average train loss = 0.000000    	average train batch reward = 0.688
validation accuracy = 0.131		average validation NDCG = 0.678

epoch 3
average train loss = 1.381388    	average train batch reward = 0.688
validation accuracy = 0.100		average validation NDCG = 0.675

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.119452    	average train batch reward = 0.693
validation accuracy = 0.090		average validation NDCG = 0.697

epoch 2
average train loss = -0.052731    	average train batch reward = 0.694
validation accuracy = 0.104		average validation NDCG = 0.687

epoch 3
average train loss = -0.066006    	average train batch reward = 0.689
validation accuracy = 0.106		average validation NDCG = 0.681

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.162713    	average train batch reward = 0.692
validation accuracy = 0.109		average validation NDCG = 0.684

epoch 2
average train loss = -0.294605    	average train batch reward = 0.683
validation accuracy = 0.107		average validation NDCG = 0.677

epoch 3
average train loss = 0.000004    	average train batch reward = 0.683
validation accuracy = 0.107		average validation NDCG = 0.670

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.326341    	average train batch reward = 0.682
validation accuracy = 0.083		average validation NDCG = 0.676

epoch 2
average train loss = -0.179642    	average train batch reward = 0.684
validation accuracy = 0.143		average validation NDCG = 0.682

epoch 3
average train loss = 0.000000    	average train batch reward = 0.684
validation accuracy = 0.142		average validation NDCG = 0.682

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001017    	average train batch reward = 0.677
validation accuracy = 0.170		average validation NDCG = 0.660

epoch 2
average train loss = -0.000098    	average train batch reward = 0.682
validation accuracy = 0.159		average validation NDCG = 0.681

epoch 3
average train loss = -0.002087    	average train batch reward = 0.681
validation accuracy = 0.095		average validation NDCG = 0.677

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001718    	average train batch reward = 0.683
validation accuracy = 0.112		average validation NDCG = 0.680

epoch 2
average train loss = -0.813395    	average train batch reward = 0.686
validation accuracy = 0.113		average validation NDCG = 0.686

epoch 3
average train loss = -0.000000    	average train batch reward = 0.686
validation accuracy = 0.113		average validation NDCG = 0.686

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.060190    	average train batch reward = 0.689
validation accuracy = 0.092		average validation NDCG = 0.701

epoch 2
average train loss = -0.140693    	average train batch reward = 0.687
validation accuracy = 0.099		average validation NDCG = 0.683

epoch 3
average train loss = 0.000000    	average train batch reward = 0.687
validation accuracy = 0.099		average validation NDCG = 0.683

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.321160    	average train batch reward = 0.678
validation accuracy = 0.059		average validation NDCG = 0.663

epoch 2
average train loss = 0.000060    	average train batch reward = 0.680
validation accuracy = 0.069		average validation NDCG = 0.662

epoch 3
average train loss = 0.782764    	average train batch reward = 0.677
validation accuracy = 0.099		average validation NDCG = 0.661

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.026562    	average train batch reward = 0.688
validation accuracy = 0.156		average validation NDCG = 0.699

epoch 2
average train loss = 0.445508    	average train batch reward = 0.687
validation accuracy = 0.092		average validation NDCG = 0.688

epoch 3
average train loss = 0.187298    	average train batch reward = 0.684
validation accuracy = 0.113		average validation NDCG = 0.682

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.142618    	average train batch reward = 0.686
validation accuracy = 0.099		average validation NDCG = 0.681

epoch 2
average train loss = -0.209486    	average train batch reward = 0.686
validation accuracy = 0.096		average validation NDCG = 0.674

epoch 3
average train loss = 0.000000    	average train batch reward = 0.683
validation accuracy = 0.096		average validation NDCG = 0.674

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
Hyperparameters:
k = 4
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2af9962db320>
Reward function = <function ndcg_full at 0x2af9962db398>
Greedy action = <function sample at 0x2af98f0de9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003136    	average train batch reward = 0.677
validation accuracy = 0.095		average validation NDCG = 0.657

epoch 2
average train loss = -0.634133    	average train batch reward = 0.681
validation accuracy = 0.155		average validation NDCG = 0.670

epoch 3
average train loss = -0.000000    	average train batch reward = 0.683
validation accuracy = 0.144		average validation NDCG = 0.670

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.89783915056239982, 0.88398814567834483, 0.88086182146487357]
========
2017-07-03 09:56:23
