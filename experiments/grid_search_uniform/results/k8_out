2017-07-03 06:40:30
Finding best parameters for k = 8
=========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005435    	average train batch reward = 0.581
validation accuracy = 0.099		average validation NDCG = 0.677

epoch 2
average train loss = -0.002204    	average train batch reward = 0.582
validation accuracy = 0.098		average validation NDCG = 0.677

epoch 3
average train loss = -0.000958    	average train batch reward = 0.582
validation accuracy = 0.099		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.67681568397627623, -1, -1]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003372    	average train batch reward = 0.561
validation accuracy = 0.087		average validation NDCG = 0.661

epoch 2
average train loss = -0.005635    	average train batch reward = 0.561
validation accuracy = 0.086		average validation NDCG = 0.661

epoch 3
average train loss = 0.001143    	average train batch reward = 0.561
validation accuracy = 0.086		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), ()], which got scores of [0.67681568397627623, 0.66101895676413935, -1]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002511    	average train batch reward = 0.567
validation accuracy = 0.097		average validation NDCG = 0.662

epoch 2
average train loss = 0.006383    	average train batch reward = 0.567
validation accuracy = 0.095		average validation NDCG = 0.662

epoch 3
average train loss = 0.001012    	average train batch reward = 0.568
validation accuracy = 0.095		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.67681568397627623, 0.66215291615724481, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000644    	average train batch reward = 0.572
validation accuracy = 0.098		average validation NDCG = 0.677

epoch 2
average train loss = -0.000042    	average train batch reward = 0.572
validation accuracy = 0.097		average validation NDCG = 0.677

epoch 3
average train loss = -0.005282    	average train batch reward = 0.573
validation accuracy = 0.096		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.67718959499521436, 0.67681568397627623, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001503    	average train batch reward = 0.602
validation accuracy = 0.110		average validation NDCG = 0.707

epoch 2
average train loss = -0.006405    	average train batch reward = 0.601
validation accuracy = 0.110		average validation NDCG = 0.707

epoch 3
average train loss = 0.001765    	average train batch reward = 0.602
validation accuracy = 0.109		average validation NDCG = 0.706

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000691    	average train batch reward = 0.556
validation accuracy = 0.055		average validation NDCG = 0.657

epoch 2
average train loss = -0.000399    	average train batch reward = 0.555
validation accuracy = 0.054		average validation NDCG = 0.657

epoch 3
average train loss = -0.004531    	average train batch reward = 0.555
validation accuracy = 0.054		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015117    	average train batch reward = 0.533
validation accuracy = 0.049		average validation NDCG = 0.643

epoch 2
average train loss = -0.004863    	average train batch reward = 0.533
validation accuracy = 0.049		average validation NDCG = 0.642

epoch 3
average train loss = -0.001880    	average train batch reward = 0.534
validation accuracy = 0.049		average validation NDCG = 0.642

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005995    	average train batch reward = 0.550
validation accuracy = 0.115		average validation NDCG = 0.656

epoch 2
average train loss = -0.000799    	average train batch reward = 0.550
validation accuracy = 0.114		average validation NDCG = 0.656

epoch 3
average train loss = 0.012187    	average train batch reward = 0.551
validation accuracy = 0.114		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014406    	average train batch reward = 0.536
validation accuracy = 0.060		average validation NDCG = 0.642

epoch 2
average train loss = -0.022927    	average train batch reward = 0.537
validation accuracy = 0.060		average validation NDCG = 0.642

epoch 3
average train loss = -0.011409    	average train batch reward = 0.537
validation accuracy = 0.060		average validation NDCG = 0.643

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007009    	average train batch reward = 0.554
validation accuracy = 0.100		average validation NDCG = 0.659

epoch 2
average train loss = 0.007614    	average train batch reward = 0.555
validation accuracy = 0.100		average validation NDCG = 0.659

epoch 3
average train loss = 0.002971    	average train batch reward = 0.555
validation accuracy = 0.100		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66101895676413935]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005718    	average train batch reward = 0.560
validation accuracy = 0.092		average validation NDCG = 0.664

epoch 2
average train loss = 0.036425    	average train batch reward = 0.560
validation accuracy = 0.091		average validation NDCG = 0.663

epoch 3
average train loss = -0.010236    	average train batch reward = 0.561
validation accuracy = 0.091		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66376368622133075]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022615    	average train batch reward = 0.568
validation accuracy = 0.064		average validation NDCG = 0.667

epoch 2
average train loss = 0.022022    	average train batch reward = 0.570
validation accuracy = 0.063		average validation NDCG = 0.667

epoch 3
average train loss = 0.000729    	average train batch reward = 0.569
validation accuracy = 0.062		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.5, 0.2)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66678941352873711]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000541    	average train batch reward = 0.567
validation accuracy = 0.097		average validation NDCG = 0.669

epoch 2
average train loss = -0.015578    	average train batch reward = 0.569
validation accuracy = 0.096		average validation NDCG = 0.669

epoch 3
average train loss = -0.001135    	average train batch reward = 0.567
validation accuracy = 0.096		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.5, 0.5)], which got scores of [0.70699115540116542, 0.67718959499521436, 0.66902929690990443]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.052507    	average train batch reward = 0.569
validation accuracy = 0.117		average validation NDCG = 0.681

epoch 2
average train loss = 0.013059    	average train batch reward = 0.569
validation accuracy = 0.116		average validation NDCG = 0.681

epoch 3
average train loss = 0.052361    	average train batch reward = 0.570
validation accuracy = 0.115		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.70699115540116542, 0.68105780408648764, 0.67718959499521436]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010813    	average train batch reward = 0.563
validation accuracy = 0.079		average validation NDCG = 0.661

epoch 2
average train loss = -0.068163    	average train batch reward = 0.562
validation accuracy = 0.079		average validation NDCG = 0.661

epoch 3
average train loss = -0.009842    	average train batch reward = 0.563
validation accuracy = 0.078		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.70699115540116542, 0.68105780408648764, 0.67718959499521436]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.232366    	average train batch reward = 0.567
validation accuracy = 0.149		average validation NDCG = 0.670

epoch 2
average train loss = 0.524892    	average train batch reward = 0.567
validation accuracy = 0.148		average validation NDCG = 0.670

epoch 3
average train loss = -0.492792    	average train batch reward = 0.566
validation accuracy = 0.148		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.70699115540116542, 0.68105780408648764, 0.67718959499521436]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.530758    	average train batch reward = 0.561
validation accuracy = 0.046		average validation NDCG = 0.662

epoch 2
average train loss = -0.174720    	average train batch reward = 0.561
validation accuracy = 0.046		average validation NDCG = 0.662

epoch 3
average train loss = -0.124456    	average train batch reward = 0.562
validation accuracy = 0.045		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.70699115540116542, 0.68105780408648764, 0.67718959499521436]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.119589    	average train batch reward = 0.565
validation accuracy = 0.074		average validation NDCG = 0.665

epoch 2
average train loss = 0.259028    	average train batch reward = 0.567
validation accuracy = 0.075		average validation NDCG = 0.665

epoch 3
average train loss = -0.343955    	average train batch reward = 0.567
validation accuracy = 0.075		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.70699115540116542, 0.68105780408648764, 0.67718959499521436]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.378394    	average train batch reward = 0.573
validation accuracy = 0.127		average validation NDCG = 0.698

epoch 2
average train loss = -0.108860    	average train batch reward = 0.575
validation accuracy = 0.126		average validation NDCG = 0.698

epoch 3
average train loss = 0.043343    	average train batch reward = 0.576
validation accuracy = 0.126		average validation NDCG = 0.698

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.75, 1.0), (9.9999999999999995e-07, 0.5, 1.0)], which got scores of [0.70699115540116542, 0.69774586618507617, 0.68105780408648764]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.384272    	average train batch reward = 0.571
validation accuracy = 0.136		average validation NDCG = 0.671

epoch 2
average train loss = 0.070246    	average train batch reward = 0.572
validation accuracy = 0.134		average validation NDCG = 0.671

epoch 3
average train loss = -0.098271    	average train batch reward = 0.571
validation accuracy = 0.133		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.75, 1.0), (9.9999999999999995e-07, 0.5, 1.0)], which got scores of [0.70699115540116542, 0.69774586618507617, 0.68105780408648764]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007723    	average train batch reward = 0.586
validation accuracy = 0.133		average validation NDCG = 0.681

epoch 2
average train loss = -0.000863    	average train batch reward = 0.585
validation accuracy = 0.117		average validation NDCG = 0.681

epoch 3
average train loss = 0.003413    	average train batch reward = 0.584
validation accuracy = 0.116		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.75, 1.0), (1.0000000000000001e-05, 0.1, 0.0)], which got scores of [0.70699115540116542, 0.69774586618507617, 0.68178864722341925]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010068    	average train batch reward = 0.543
validation accuracy = 0.085		average validation NDCG = 0.653

epoch 2
average train loss = -0.005207    	average train batch reward = 0.542
validation accuracy = 0.081		average validation NDCG = 0.652

epoch 3
average train loss = -0.006093    	average train batch reward = 0.540
validation accuracy = 0.077		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (9.9999999999999995e-07, 0.75, 1.0), (1.0000000000000001e-05, 0.1, 0.0)], which got scores of [0.70699115540116542, 0.69774586618507617, 0.68178864722341925]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000893    	average train batch reward = 0.588
validation accuracy = 0.100		average validation NDCG = 0.703

epoch 2
average train loss = -0.003695    	average train batch reward = 0.589
validation accuracy = 0.090		average validation NDCG = 0.705

epoch 3
average train loss = -0.010495    	average train batch reward = 0.590
validation accuracy = 0.083		average validation NDCG = 0.704

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001088    	average train batch reward = 0.539
validation accuracy = 0.072		average validation NDCG = 0.651

epoch 2
average train loss = -0.008202    	average train batch reward = 0.540
validation accuracy = 0.066		average validation NDCG = 0.650

epoch 3
average train loss = -0.001496    	average train batch reward = 0.537
validation accuracy = 0.065		average validation NDCG = 0.648

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004498    	average train batch reward = 0.579
validation accuracy = 0.102		average validation NDCG = 0.685

epoch 2
average train loss = 0.005198    	average train batch reward = 0.580
validation accuracy = 0.096		average validation NDCG = 0.685

epoch 3
average train loss = 0.004393    	average train batch reward = 0.579
validation accuracy = 0.093		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005262    	average train batch reward = 0.576
validation accuracy = 0.115		average validation NDCG = 0.687

epoch 2
average train loss = -0.004963    	average train batch reward = 0.572
validation accuracy = 0.111		average validation NDCG = 0.686

epoch 3
average train loss = -0.009862    	average train batch reward = 0.573
validation accuracy = 0.106		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000710    	average train batch reward = 0.547
validation accuracy = 0.084		average validation NDCG = 0.652

epoch 2
average train loss = -0.012025    	average train batch reward = 0.547
validation accuracy = 0.079		average validation NDCG = 0.650

epoch 3
average train loss = -0.007582    	average train batch reward = 0.543
validation accuracy = 0.075		average validation NDCG = 0.647

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007782    	average train batch reward = 0.579
validation accuracy = 0.116		average validation NDCG = 0.677

epoch 2
average train loss = -0.002397    	average train batch reward = 0.579
validation accuracy = 0.110		average validation NDCG = 0.676

epoch 3
average train loss = -0.007872    	average train batch reward = 0.579
validation accuracy = 0.111		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015216    	average train batch reward = 0.561
validation accuracy = 0.083		average validation NDCG = 0.668

epoch 2
average train loss = -0.013613    	average train batch reward = 0.561
validation accuracy = 0.079		average validation NDCG = 0.668

epoch 3
average train loss = -0.017286    	average train batch reward = 0.559
validation accuracy = 0.076		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005519    	average train batch reward = 0.557
validation accuracy = 0.049		average validation NDCG = 0.657

epoch 2
average train loss = -0.019653    	average train batch reward = 0.555
validation accuracy = 0.049		average validation NDCG = 0.657

epoch 3
average train loss = -0.011623    	average train batch reward = 0.556
validation accuracy = 0.051		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.020168    	average train batch reward = 0.580
validation accuracy = 0.101		average validation NDCG = 0.694

epoch 2
average train loss = -0.035988    	average train batch reward = 0.580
validation accuracy = 0.094		average validation NDCG = 0.691

epoch 3
average train loss = 0.059272    	average train batch reward = 0.578
validation accuracy = 0.088		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.031253    	average train batch reward = 0.560
validation accuracy = 0.065		average validation NDCG = 0.663

epoch 2
average train loss = -0.060183    	average train batch reward = 0.560
validation accuracy = 0.063		average validation NDCG = 0.661

epoch 3
average train loss = -0.066235    	average train batch reward = 0.559
validation accuracy = 0.060		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.040799    	average train batch reward = 0.565
validation accuracy = 0.075		average validation NDCG = 0.663

epoch 2
average train loss = -0.017751    	average train batch reward = 0.564
validation accuracy = 0.073		average validation NDCG = 0.663

epoch 3
average train loss = -0.060134    	average train batch reward = 0.564
validation accuracy = 0.072		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.051487    	average train batch reward = 0.573
validation accuracy = 0.101		average validation NDCG = 0.683

epoch 2
average train loss = -0.019247    	average train batch reward = 0.571
validation accuracy = 0.102		average validation NDCG = 0.684

epoch 3
average train loss = 0.002584    	average train batch reward = 0.572
validation accuracy = 0.100		average validation NDCG = 0.683

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.024798    	average train batch reward = 0.579
validation accuracy = 0.093		average validation NDCG = 0.695

epoch 2
average train loss = 0.092299    	average train batch reward = 0.580
validation accuracy = 0.091		average validation NDCG = 0.694

epoch 3
average train loss = 0.017370    	average train batch reward = 0.580
validation accuracy = 0.089		average validation NDCG = 0.692

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.226502    	average train batch reward = 0.560
validation accuracy = 0.061		average validation NDCG = 0.651

epoch 2
average train loss = -0.173640    	average train batch reward = 0.560
validation accuracy = 0.060		average validation NDCG = 0.651

epoch 3
average train loss = 0.053469    	average train batch reward = 0.559
validation accuracy = 0.061		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.071573    	average train batch reward = 0.558
validation accuracy = 0.110		average validation NDCG = 0.646

epoch 2
average train loss = -0.278331    	average train batch reward = 0.557
validation accuracy = 0.110		average validation NDCG = 0.645

epoch 3
average train loss = -0.339433    	average train batch reward = 0.558
validation accuracy = 0.111		average validation NDCG = 0.645

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.401134    	average train batch reward = 0.565
validation accuracy = 0.090		average validation NDCG = 0.671

epoch 2
average train loss = -0.094934    	average train batch reward = 0.565
validation accuracy = 0.088		average validation NDCG = 0.670

epoch 3
average train loss = -0.169269    	average train batch reward = 0.565
validation accuracy = 0.087		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.453816    	average train batch reward = 0.569
validation accuracy = 0.105		average validation NDCG = 0.676

epoch 2
average train loss = -0.010589    	average train batch reward = 0.569
validation accuracy = 0.105		average validation NDCG = 0.675

epoch 3
average train loss = 0.311750    	average train batch reward = 0.570
validation accuracy = 0.104		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.262920    	average train batch reward = 0.564
validation accuracy = 0.062		average validation NDCG = 0.664

epoch 2
average train loss = 0.738244    	average train batch reward = 0.563
validation accuracy = 0.061		average validation NDCG = 0.663

epoch 3
average train loss = -0.434565    	average train batch reward = 0.565
validation accuracy = 0.064		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006579    	average train batch reward = 0.534
validation accuracy = 0.040		average validation NDCG = 0.641

epoch 2
average train loss = -0.017169    	average train batch reward = 0.527
validation accuracy = 0.014		average validation NDCG = 0.636

epoch 3
average train loss = -0.021121    	average train batch reward = 0.524
validation accuracy = 0.008		average validation NDCG = 0.634

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017770    	average train batch reward = 0.564
validation accuracy = 0.038		average validation NDCG = 0.654

epoch 2
average train loss = -0.026500    	average train batch reward = 0.545
validation accuracy = 0.033		average validation NDCG = 0.645

epoch 3
average train loss = -0.016037    	average train batch reward = 0.535
validation accuracy = 0.020		average validation NDCG = 0.649

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004331    	average train batch reward = 0.564
validation accuracy = 0.081		average validation NDCG = 0.663

epoch 2
average train loss = -0.001813    	average train batch reward = 0.571
validation accuracy = 0.036		average validation NDCG = 0.668

epoch 3
average train loss = -0.010523    	average train batch reward = 0.560
validation accuracy = 0.019		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006834    	average train batch reward = 0.569
validation accuracy = 0.077		average validation NDCG = 0.670

epoch 2
average train loss = -0.011892    	average train batch reward = 0.555
validation accuracy = 0.037		average validation NDCG = 0.664

epoch 3
average train loss = -0.022318    	average train batch reward = 0.547
validation accuracy = 0.026		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000575    	average train batch reward = 0.582
validation accuracy = 0.107		average validation NDCG = 0.690

epoch 2
average train loss = -0.009196    	average train batch reward = 0.589
validation accuracy = 0.062		average validation NDCG = 0.693

epoch 3
average train loss = -0.014527    	average train batch reward = 0.568
validation accuracy = 0.063		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002050    	average train batch reward = 0.541
validation accuracy = 0.085		average validation NDCG = 0.644

epoch 2
average train loss = -0.024210    	average train batch reward = 0.525
validation accuracy = 0.056		average validation NDCG = 0.631

epoch 3
average train loss = -0.048630    	average train batch reward = 0.519
validation accuracy = 0.031		average validation NDCG = 0.628

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000212    	average train batch reward = 0.560
validation accuracy = 0.069		average validation NDCG = 0.670

epoch 2
average train loss = -0.015066    	average train batch reward = 0.561
validation accuracy = 0.032		average validation NDCG = 0.673

epoch 3
average train loss = -0.017851    	average train batch reward = 0.564
validation accuracy = 0.020		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.023658    	average train batch reward = 0.558
validation accuracy = 0.072		average validation NDCG = 0.664

epoch 2
average train loss = -0.010987    	average train batch reward = 0.558
validation accuracy = 0.040		average validation NDCG = 0.666

epoch 3
average train loss = -0.025807    	average train batch reward = 0.563
validation accuracy = 0.022		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.010313    	average train batch reward = 0.557
validation accuracy = 0.068		average validation NDCG = 0.643

epoch 2
average train loss = -0.036303    	average train batch reward = 0.537
validation accuracy = 0.050		average validation NDCG = 0.640

epoch 3
average train loss = -0.028437    	average train batch reward = 0.535
validation accuracy = 0.021		average validation NDCG = 0.637

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.022112    	average train batch reward = 0.558
validation accuracy = 0.109		average validation NDCG = 0.670

epoch 2
average train loss = -0.024272    	average train batch reward = 0.551
validation accuracy = 0.071		average validation NDCG = 0.667

epoch 3
average train loss = -0.032793    	average train batch reward = 0.552
validation accuracy = 0.043		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (9.9999999999999995e-07, 0.75, 1.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69774586618507617]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.072079    	average train batch reward = 0.585
validation accuracy = 0.116		average validation NDCG = 0.700

epoch 2
average train loss = -0.047828    	average train batch reward = 0.581
validation accuracy = 0.104		average validation NDCG = 0.697

epoch 3
average train loss = -0.014274    	average train batch reward = 0.576
validation accuracy = 0.084		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003408    	average train batch reward = 0.565
validation accuracy = 0.084		average validation NDCG = 0.670

epoch 2
average train loss = -0.078853    	average train batch reward = 0.562
validation accuracy = 0.071		average validation NDCG = 0.659

epoch 3
average train loss = -0.086774    	average train batch reward = 0.557
validation accuracy = 0.082		average validation NDCG = 0.649

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.033311    	average train batch reward = 0.569
validation accuracy = 0.106		average validation NDCG = 0.675

epoch 2
average train loss = 0.035216    	average train batch reward = 0.568
validation accuracy = 0.085		average validation NDCG = 0.665

epoch 3
average train loss = -0.052891    	average train batch reward = 0.560
validation accuracy = 0.064		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.025895    	average train batch reward = 0.564
validation accuracy = 0.079		average validation NDCG = 0.662

epoch 2
average train loss = -0.071484    	average train batch reward = 0.550
validation accuracy = 0.063		average validation NDCG = 0.662

epoch 3
average train loss = -0.090587    	average train batch reward = 0.552
validation accuracy = 0.039		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015744    	average train batch reward = 0.566
validation accuracy = 0.070		average validation NDCG = 0.664

epoch 2
average train loss = -0.051727    	average train batch reward = 0.559
validation accuracy = 0.061		average validation NDCG = 0.665

epoch 3
average train loss = -0.020085    	average train batch reward = 0.559
validation accuracy = 0.060		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013210    	average train batch reward = 0.561
validation accuracy = 0.085		average validation NDCG = 0.646

epoch 2
average train loss = -0.243089    	average train batch reward = 0.557
validation accuracy = 0.058		average validation NDCG = 0.637

epoch 3
average train loss = -0.262219    	average train batch reward = 0.560
validation accuracy = 0.049		average validation NDCG = 0.642

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.269048    	average train batch reward = 0.572
validation accuracy = 0.119		average validation NDCG = 0.674

epoch 2
average train loss = 0.059892    	average train batch reward = 0.570
validation accuracy = 0.121		average validation NDCG = 0.676

epoch 3
average train loss = 0.019268    	average train batch reward = 0.568
validation accuracy = 0.090		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.295852    	average train batch reward = 0.572
validation accuracy = 0.120		average validation NDCG = 0.676

epoch 2
average train loss = 0.475862    	average train batch reward = 0.568
validation accuracy = 0.100		average validation NDCG = 0.656

epoch 3
average train loss = 0.057291    	average train batch reward = 0.564
validation accuracy = 0.085		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.154473    	average train batch reward = 0.565
validation accuracy = 0.082		average validation NDCG = 0.676

epoch 2
average train loss = -1.099530    	average train batch reward = 0.569
validation accuracy = 0.067		average validation NDCG = 0.674

epoch 3
average train loss = -0.376832    	average train batch reward = 0.563
validation accuracy = 0.043		average validation NDCG = 0.649

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.5, 0.0)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.69997208575942205]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.228311    	average train batch reward = 0.576
validation accuracy = 0.116		average validation NDCG = 0.705

epoch 2
average train loss = 0.211229    	average train batch reward = 0.574
validation accuracy = 0.101		average validation NDCG = 0.685

epoch 3
average train loss = -0.161000    	average train batch reward = 0.571
validation accuracy = 0.102		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003882    	average train batch reward = 0.552
validation accuracy = 0.026		average validation NDCG = 0.640

epoch 2
average train loss = -0.034503    	average train batch reward = 0.528
validation accuracy = 0.008		average validation NDCG = 0.626

epoch 3
average train loss = -0.029998    	average train batch reward = 0.527
validation accuracy = 0.004		average validation NDCG = 0.623

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000030    	average train batch reward = 0.557
validation accuracy = 0.122		average validation NDCG = 0.653

epoch 2
average train loss = -0.008251    	average train batch reward = 0.543
validation accuracy = 0.115		average validation NDCG = 0.653

epoch 3
average train loss = -0.017470    	average train batch reward = 0.544
validation accuracy = 0.114		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003265    	average train batch reward = 0.580
validation accuracy = 0.065		average validation NDCG = 0.678

epoch 2
average train loss = -0.003653    	average train batch reward = 0.572
validation accuracy = 0.053		average validation NDCG = 0.683

epoch 3
average train loss = 0.002108    	average train batch reward = 0.574
validation accuracy = 0.024		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015751    	average train batch reward = 0.551
validation accuracy = 0.011		average validation NDCG = 0.652

epoch 2
average train loss = -0.024170    	average train batch reward = 0.552
validation accuracy = 0.011		average validation NDCG = 0.668

epoch 3
average train loss = -0.012354    	average train batch reward = 0.550
validation accuracy = 0.019		average validation NDCG = 0.648

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.018617    	average train batch reward = 0.576
validation accuracy = 0.026		average validation NDCG = 0.647

epoch 2
average train loss = -0.012273    	average train batch reward = 0.534
validation accuracy = 0.020		average validation NDCG = 0.629

epoch 3
average train loss = -0.032389    	average train batch reward = 0.511
validation accuracy = 0.036		average validation NDCG = 0.616

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004547    	average train batch reward = 0.565
validation accuracy = 0.031		average validation NDCG = 0.665

epoch 2
average train loss = -0.016042    	average train batch reward = 0.554
validation accuracy = 0.018		average validation NDCG = 0.658

epoch 3
average train loss = -0.017446    	average train batch reward = 0.552
validation accuracy = 0.015		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022369    	average train batch reward = 0.581
validation accuracy = 0.115		average validation NDCG = 0.674

epoch 2
average train loss = -0.013229    	average train batch reward = 0.548
validation accuracy = 0.042		average validation NDCG = 0.642

epoch 3
average train loss = -0.038600    	average train batch reward = 0.542
validation accuracy = 0.022		average validation NDCG = 0.650

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.016740    	average train batch reward = 0.567
validation accuracy = 0.065		average validation NDCG = 0.664

epoch 2
average train loss = -0.000443    	average train batch reward = 0.560
validation accuracy = 0.053		average validation NDCG = 0.665

epoch 3
average train loss = -0.018871    	average train batch reward = 0.557
validation accuracy = 0.051		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005925    	average train batch reward = 0.567
validation accuracy = 0.048		average validation NDCG = 0.664

epoch 2
average train loss = -0.010983    	average train batch reward = 0.561
validation accuracy = 0.033		average validation NDCG = 0.660

epoch 3
average train loss = -0.013320    	average train batch reward = 0.560
validation accuracy = 0.047		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.016704    	average train batch reward = 0.561
validation accuracy = 0.068		average validation NDCG = 0.659

epoch 2
average train loss = -0.070853    	average train batch reward = 0.542
validation accuracy = 0.015		average validation NDCG = 0.639

epoch 3
average train loss = -0.016982    	average train batch reward = 0.538
validation accuracy = 0.022		average validation NDCG = 0.650

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.092098    	average train batch reward = 0.564
validation accuracy = 0.061		average validation NDCG = 0.664

epoch 2
average train loss = -0.062204    	average train batch reward = 0.562
validation accuracy = 0.092		average validation NDCG = 0.653

epoch 3
average train loss = 0.085958    	average train batch reward = 0.557
validation accuracy = 0.091		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011590    	average train batch reward = 0.560
validation accuracy = 0.100		average validation NDCG = 0.651

epoch 2
average train loss = -0.063810    	average train batch reward = 0.550
validation accuracy = 0.037		average validation NDCG = 0.635

epoch 3
average train loss = -0.284355    	average train batch reward = 0.550
validation accuracy = 0.034		average validation NDCG = 0.637

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.031511    	average train batch reward = 0.566
validation accuracy = 0.051		average validation NDCG = 0.688

epoch 2
average train loss = -0.017416    	average train batch reward = 0.569
validation accuracy = 0.060		average validation NDCG = 0.674

epoch 3
average train loss = -0.121062    	average train batch reward = 0.559
validation accuracy = 0.055		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036966    	average train batch reward = 0.564
validation accuracy = 0.068		average validation NDCG = 0.657

epoch 2
average train loss = 0.023508    	average train batch reward = 0.562
validation accuracy = 0.083		average validation NDCG = 0.646

epoch 3
average train loss = -0.110109    	average train batch reward = 0.553
validation accuracy = 0.069		average validation NDCG = 0.645

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.034564    	average train batch reward = 0.564
validation accuracy = 0.047		average validation NDCG = 0.671

epoch 2
average train loss = 0.046385    	average train batch reward = 0.560
validation accuracy = 0.072		average validation NDCG = 0.654

epoch 3
average train loss = -0.212260    	average train batch reward = 0.564
validation accuracy = 0.111		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.505842    	average train batch reward = 0.570
validation accuracy = 0.123		average validation NDCG = 0.672

epoch 2
average train loss = 0.857402    	average train batch reward = 0.566
validation accuracy = 0.095		average validation NDCG = 0.673

epoch 3
average train loss = 0.579271    	average train batch reward = 0.565
validation accuracy = 0.099		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.297711    	average train batch reward = 0.568
validation accuracy = 0.039		average validation NDCG = 0.655

epoch 2
average train loss = 1.107473    	average train batch reward = 0.559
validation accuracy = 0.049		average validation NDCG = 0.639

epoch 3
average train loss = -1.593488    	average train batch reward = 0.557
validation accuracy = 0.040		average validation NDCG = 0.629

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.482502    	average train batch reward = 0.563
validation accuracy = 0.080		average validation NDCG = 0.648

epoch 2
average train loss = -2.098672    	average train batch reward = 0.561
validation accuracy = 0.080		average validation NDCG = 0.650

epoch 3
average train loss = -1.378664    	average train batch reward = 0.562
validation accuracy = 0.052		average validation NDCG = 0.654

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.651185    	average train batch reward = 0.568
validation accuracy = 0.024		average validation NDCG = 0.675

epoch 2
average train loss = -0.167516    	average train batch reward = 0.562
validation accuracy = 0.044		average validation NDCG = 0.660

epoch 3
average train loss = 0.325797    	average train batch reward = 0.564
validation accuracy = 0.100		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012181    	average train batch reward = 0.577
validation accuracy = 0.191		average validation NDCG = 0.695

epoch 2
average train loss = 0.106304    	average train batch reward = 0.575
validation accuracy = 0.148		average validation NDCG = 0.694

epoch 3
average train loss = 0.751566    	average train batch reward = 0.575
validation accuracy = 0.133		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011107    	average train batch reward = 0.551
validation accuracy = 0.117		average validation NDCG = 0.656

epoch 2
average train loss = -0.006140    	average train batch reward = 0.552
validation accuracy = 0.099		average validation NDCG = 0.666

epoch 3
average train loss = -0.003950    	average train batch reward = 0.549
validation accuracy = 0.049		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006174    	average train batch reward = 0.572
validation accuracy = 0.107		average validation NDCG = 0.666

epoch 2
average train loss = -0.049333    	average train batch reward = 0.555
validation accuracy = 0.110		average validation NDCG = 0.655

epoch 3
average train loss = -0.037110    	average train batch reward = 0.549
validation accuracy = 0.086		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 1.5), (1.0000000000000001e-05, 0.1, 0.5), (0.0001, 0.75, 1.5)], which got scores of [0.70699115540116542, 0.70492344496277171, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.070738    	average train batch reward = 0.590
validation accuracy = 0.189		average validation NDCG = 0.709

epoch 2
average train loss = -0.025981    	average train batch reward = 0.597
validation accuracy = 0.199		average validation NDCG = 0.682

epoch 3
average train loss = 0.027469    	average train batch reward = 0.569
validation accuracy = 0.115		average validation NDCG = 0.677

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015476    	average train batch reward = 0.553
validation accuracy = 0.093		average validation NDCG = 0.665

epoch 2
average train loss = 0.009633    	average train batch reward = 0.567
validation accuracy = 0.094		average validation NDCG = 0.673

epoch 3
average train loss = 0.053192    	average train batch reward = 0.558
validation accuracy = 0.117		average validation NDCG = 0.659

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011002    	average train batch reward = 0.558
validation accuracy = 0.034		average validation NDCG = 0.666

epoch 2
average train loss = -0.008548    	average train batch reward = 0.560
validation accuracy = 0.099		average validation NDCG = 0.662

epoch 3
average train loss = 0.020429    	average train batch reward = 0.559
validation accuracy = 0.094		average validation NDCG = 0.657

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.025969    	average train batch reward = 0.559
validation accuracy = 0.073		average validation NDCG = 0.664

epoch 2
average train loss = -0.059024    	average train batch reward = 0.560
validation accuracy = 0.149		average validation NDCG = 0.659

epoch 3
average train loss = 0.196480    	average train batch reward = 0.552
validation accuracy = 0.135		average validation NDCG = 0.650

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.068932    	average train batch reward = 0.557
validation accuracy = 0.075		average validation NDCG = 0.660

epoch 2
average train loss = 0.039191    	average train batch reward = 0.555
validation accuracy = 0.058		average validation NDCG = 0.661

epoch 3
average train loss = -0.217360    	average train batch reward = 0.561
validation accuracy = 0.105		average validation NDCG = 0.668

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017234    	average train batch reward = 0.581
validation accuracy = 0.099		average validation NDCG = 0.697

epoch 2
average train loss = -0.013546    	average train batch reward = 0.574
validation accuracy = 0.107		average validation NDCG = 0.673

epoch 3
average train loss = 0.014262    	average train batch reward = 0.567
validation accuracy = 0.106		average validation NDCG = 0.672

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.038226    	average train batch reward = 0.563
validation accuracy = 0.110		average validation NDCG = 0.660

epoch 2
average train loss = -0.049701    	average train batch reward = 0.558
validation accuracy = 0.087		average validation NDCG = 0.661

epoch 3
average train loss = 0.008683    	average train batch reward = 0.557
validation accuracy = 0.087		average validation NDCG = 0.660

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.019950    	average train batch reward = 0.558
validation accuracy = 0.136		average validation NDCG = 0.663

epoch 2
average train loss = -0.023228    	average train batch reward = 0.554
validation accuracy = 0.107		average validation NDCG = 0.656

epoch 3
average train loss = -0.006265    	average train batch reward = 0.556
validation accuracy = 0.105		average validation NDCG = 0.656

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.151777    	average train batch reward = 0.565
validation accuracy = 0.071		average validation NDCG = 0.657

epoch 2
average train loss = 0.235383    	average train batch reward = 0.562
validation accuracy = 0.097		average validation NDCG = 0.675

epoch 3
average train loss = 0.214644    	average train batch reward = 0.566
validation accuracy = 0.105		average validation NDCG = 0.664

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.044720    	average train batch reward = 0.572
validation accuracy = 0.105		average validation NDCG = 0.676

epoch 2
average train loss = 0.427663    	average train batch reward = 0.562
validation accuracy = 0.131		average validation NDCG = 0.670

epoch 3
average train loss = -0.027962    	average train batch reward = 0.563
validation accuracy = 0.092		average validation NDCG = 0.659

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.111917    	average train batch reward = 0.568
validation accuracy = 0.096		average validation NDCG = 0.675

epoch 2
average train loss = 0.008744    	average train batch reward = 0.572
validation accuracy = 0.096		average validation NDCG = 0.677

epoch 3
average train loss = -0.233862    	average train batch reward = 0.566
validation accuracy = 0.096		average validation NDCG = 0.671

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.156480    	average train batch reward = 0.557
validation accuracy = 0.092		average validation NDCG = 0.654

epoch 2
average train loss = -0.032627    	average train batch reward = 0.564
validation accuracy = 0.019		average validation NDCG = 0.661

epoch 3
average train loss = -0.305051    	average train batch reward = 0.562
validation accuracy = 0.047		average validation NDCG = 0.661

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.110231    	average train batch reward = 0.573
validation accuracy = 0.149		average validation NDCG = 0.701

epoch 2
average train loss = 0.308903    	average train batch reward = 0.583
validation accuracy = 0.132		average validation NDCG = 0.695

epoch 3
average train loss = -0.783521    	average train batch reward = 0.580
validation accuracy = 0.110		average validation NDCG = 0.701

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.058682    	average train batch reward = 0.565
validation accuracy = 0.095		average validation NDCG = 0.665

epoch 2
average train loss = -15.964349    	average train batch reward = 0.566
validation accuracy = 0.121		average validation NDCG = 0.670

epoch 3
average train loss = 1.678280    	average train batch reward = 0.567
validation accuracy = 0.126		average validation NDCG = 0.667

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.896661    	average train batch reward = 0.573
validation accuracy = 0.107		average validation NDCG = 0.676

epoch 2
average train loss = 2.307211    	average train batch reward = 0.569
validation accuracy = 0.102		average validation NDCG = 0.676

epoch 3
average train loss = 2.103125    	average train batch reward = 0.571
validation accuracy = 0.143		average validation NDCG = 0.677

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 4.109170    	average train batch reward = 0.566
validation accuracy = 0.114		average validation NDCG = 0.668

epoch 2
average train loss = -0.011744    	average train batch reward = 0.567
validation accuracy = 0.116		average validation NDCG = 0.669

epoch 3
average train loss = -3.743999    	average train batch reward = 0.570
validation accuracy = 0.145		average validation NDCG = 0.684

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.652035    	average train batch reward = 0.565
validation accuracy = 0.094		average validation NDCG = 0.671

epoch 2
average train loss = -2.198535    	average train batch reward = 0.568
validation accuracy = 0.087		average validation NDCG = 0.664

epoch 3
average train loss = 11.389462    	average train batch reward = 0.563
validation accuracy = 0.037		average validation NDCG = 0.647

========
Currently the best setups are [(0.01, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 1.5), (0.0001, 0.75, 1.5)], which got scores of [0.70858465698406214, 0.70699115540116542, 0.7048604821602461]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.454987    	average train batch reward = 0.571
validation accuracy = 0.226		average validation NDCG = 0.707

epoch 2
average train loss = 6.165212    	average train batch reward = 0.576
validation accuracy = 0.133		average validation NDCG = 0.697

epoch 3
average train loss = 0.659058    	average train batch reward = 0.574
validation accuracy = 0.183		average validation NDCG = 0.693

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.175899    	average train batch reward = 0.547
validation accuracy = 0.110		average validation NDCG = 0.655

epoch 2
average train loss = -0.000000    	average train batch reward = 0.549
validation accuracy = 0.110		average validation NDCG = 0.654

epoch 3
average train loss = 0.010617    	average train batch reward = 0.551
validation accuracy = 0.110		average validation NDCG = 0.659

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.310498    	average train batch reward = 0.575
validation accuracy = 0.063		average validation NDCG = 0.678

epoch 2
average train loss = 1.659056    	average train batch reward = 0.580
validation accuracy = 0.101		average validation NDCG = 0.684

epoch 3
average train loss = -0.000000    	average train batch reward = 0.580
validation accuracy = 0.096		average validation NDCG = 0.683

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.012036    	average train batch reward = 0.580
validation accuracy = 0.113		average validation NDCG = 0.664

epoch 2
average train loss = 0.004356    	average train batch reward = 0.562
validation accuracy = 0.113		average validation NDCG = 0.665

epoch 3
average train loss = 0.000128    	average train batch reward = 0.564
validation accuracy = 0.113		average validation NDCG = 0.664

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000555    	average train batch reward = 0.573
validation accuracy = 0.062		average validation NDCG = 0.680

epoch 2
average train loss = -0.140526    	average train batch reward = 0.574
validation accuracy = 0.087		average validation NDCG = 0.680

epoch 3
average train loss = -0.014981    	average train batch reward = 0.576
validation accuracy = 0.190		average validation NDCG = 0.685

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.365594    	average train batch reward = 0.569
validation accuracy = 0.097		average validation NDCG = 0.667

epoch 2
average train loss = -0.024505    	average train batch reward = 0.568
validation accuracy = 0.096		average validation NDCG = 0.671

epoch 3
average train loss = 0.000056    	average train batch reward = 0.567
validation accuracy = 0.096		average validation NDCG = 0.663

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.076965    	average train batch reward = 0.554
validation accuracy = 0.105		average validation NDCG = 0.653

epoch 2
average train loss = 0.000012    	average train batch reward = 0.556
validation accuracy = 0.076		average validation NDCG = 0.658

epoch 3
average train loss = 0.013786    	average train batch reward = 0.558
validation accuracy = 0.063		average validation NDCG = 0.656

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.107803    	average train batch reward = 0.567
validation accuracy = 0.107		average validation NDCG = 0.677

epoch 2
average train loss = -0.107208    	average train batch reward = 0.570
validation accuracy = 0.113		average validation NDCG = 0.679

epoch 3
average train loss = 0.021439    	average train batch reward = 0.567
validation accuracy = 0.113		average validation NDCG = 0.670

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003114    	average train batch reward = 0.573
validation accuracy = 0.099		average validation NDCG = 0.682

epoch 2
average train loss = -0.000000    	average train batch reward = 0.575
validation accuracy = 0.099		average validation NDCG = 0.682

epoch 3
average train loss = 1.975086    	average train batch reward = 0.577
validation accuracy = 0.099		average validation NDCG = 0.684

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.522907    	average train batch reward = 0.578
validation accuracy = 0.095		average validation NDCG = 0.674

epoch 2
average train loss = -0.575226    	average train batch reward = 0.579
validation accuracy = 0.111		average validation NDCG = 0.688

epoch 3
average train loss = -0.074158    	average train batch reward = 0.578
validation accuracy = 0.120		average validation NDCG = 0.680

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.067300    	average train batch reward = 0.555
validation accuracy = 0.104		average validation NDCG = 0.658

epoch 2
average train loss = -0.006760    	average train batch reward = 0.566
validation accuracy = 0.092		average validation NDCG = 0.672

epoch 3
average train loss = 0.000000    	average train batch reward = 0.566
validation accuracy = 0.092		average validation NDCG = 0.672

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.632802    	average train batch reward = 0.572
validation accuracy = 0.099		average validation NDCG = 0.677

epoch 2
average train loss = 0.003630    	average train batch reward = 0.572
validation accuracy = 0.099		average validation NDCG = 0.676

epoch 3
average train loss = -2.171076    	average train batch reward = 0.572
validation accuracy = 0.099		average validation NDCG = 0.669

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.594502    	average train batch reward = 0.561
validation accuracy = 0.099		average validation NDCG = 0.664

epoch 2
average train loss = -0.000264    	average train batch reward = 0.566
validation accuracy = 0.107		average validation NDCG = 0.666

epoch 3
average train loss = -0.000001    	average train batch reward = 0.565
validation accuracy = 0.107		average validation NDCG = 0.666

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.178315    	average train batch reward = 0.567
validation accuracy = 0.098		average validation NDCG = 0.673

epoch 2
average train loss = -0.002048    	average train batch reward = 0.567
validation accuracy = 0.098		average validation NDCG = 0.675

epoch 3
average train loss = -0.108419    	average train batch reward = 0.570
validation accuracy = 0.098		average validation NDCG = 0.677

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.119119    	average train batch reward = 0.553
validation accuracy = 0.086		average validation NDCG = 0.644

epoch 2
average train loss = 1.526193    	average train batch reward = 0.559
validation accuracy = 0.111		average validation NDCG = 0.663

epoch 3
average train loss = 0.032754    	average train batch reward = 0.561
validation accuracy = 0.110		average validation NDCG = 0.663

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.072280    	average train batch reward = 0.574
validation accuracy = 0.147		average validation NDCG = 0.678

epoch 2
average train loss = 2.777852    	average train batch reward = 0.571
validation accuracy = 0.052		average validation NDCG = 0.673

epoch 3
average train loss = -0.138206    	average train batch reward = 0.569
validation accuracy = 0.141		average validation NDCG = 0.676

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 96.730675    	average train batch reward = 0.563
validation accuracy = 0.079		average validation NDCG = 0.652

epoch 2
average train loss = 312.870300    	average train batch reward = 0.563
validation accuracy = 0.117		average validation NDCG = 0.652

epoch 3
average train loss = -0.008078    	average train batch reward = 0.565
validation accuracy = 0.106		average validation NDCG = 0.655

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.614922    	average train batch reward = 0.565
validation accuracy = 0.099		average validation NDCG = 0.666

epoch 2
average train loss = -0.000003    	average train batch reward = 0.566
validation accuracy = 0.099		average validation NDCG = 0.672

epoch 3
average train loss = -0.204478    	average train batch reward = 0.569
validation accuracy = 0.062		average validation NDCG = 0.668

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.074062    	average train batch reward = 0.565
validation accuracy = 0.137		average validation NDCG = 0.666

epoch 2
average train loss = 41.151531    	average train batch reward = 0.564
validation accuracy = 0.103		average validation NDCG = 0.655

epoch 3
average train loss = -0.000000    	average train batch reward = 0.563
validation accuracy = 0.103		average validation NDCG = 0.655

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.714032    	average train batch reward = 0.568
validation accuracy = 0.103		average validation NDCG = 0.673

epoch 2
average train loss = 0.000197    	average train batch reward = 0.569
validation accuracy = 0.100		average validation NDCG = 0.678

epoch 3
average train loss = -0.030475    	average train batch reward = 0.570
validation accuracy = 0.099		average validation NDCG = 0.678

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b50f9b55320>
Reward function = <function ndcg_full at 0x2b50f9b55398>
Greedy action = <function sample at 0x2b50f29569b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -28.377666    	average train batch reward = 0.568
validation accuracy = 0.083		average validation NDCG = 0.681

epoch 2
average train loss = 0.555680    	average train batch reward = 0.570
validation accuracy = 0.086		average validation NDCG = 0.682

epoch 3
average train loss = -0.000000    	average train batch reward = 0.570
validation accuracy = 0.086		average validation NDCG = 0.683

========
Currently the best setups are [(0.01, 0.1, 0.5), (0.01, 0.75, 1.5), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.70858465698406214, 0.70736129146243842, 0.70699115540116542]
========
2017-07-03 12:00:44
