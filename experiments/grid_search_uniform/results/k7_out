2017-07-03 06:39:27
Finding best parameters for k = 7
=========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006081    	average train batch reward = 0.598
validation accuracy = 0.105		average validation NDCG = 0.687

epoch 2
average train loss = -0.004667    	average train batch reward = 0.600
validation accuracy = 0.106		average validation NDCG = 0.686

epoch 3
average train loss = 0.003965    	average train batch reward = 0.599
validation accuracy = 0.105		average validation NDCG = 0.687

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.6865781414006713, -1, -1]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002846    	average train batch reward = 0.563
validation accuracy = 0.054		average validation NDCG = 0.657

epoch 2
average train loss = -0.007914    	average train batch reward = 0.561
validation accuracy = 0.054		average validation NDCG = 0.657

epoch 3
average train loss = -0.004061    	average train batch reward = 0.562
validation accuracy = 0.054		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), ()], which got scores of [0.6865781414006713, 0.65734540766986482, -1]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002939    	average train batch reward = 0.588
validation accuracy = 0.098		average validation NDCG = 0.666

epoch 2
average train loss = -0.000100    	average train batch reward = 0.589
validation accuracy = 0.097		average validation NDCG = 0.666

epoch 3
average train loss = 0.001613    	average train batch reward = 0.588
validation accuracy = 0.097		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5), (9.9999999999999995e-07, 0.1, 0.2)], which got scores of [0.6865781414006713, 0.66650389058902437, 0.65734540766986482]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006344    	average train batch reward = 0.603
validation accuracy = 0.092		average validation NDCG = 0.677

epoch 2
average train loss = 0.006257    	average train batch reward = 0.604
validation accuracy = 0.092		average validation NDCG = 0.677

epoch 3
average train loss = 0.009282    	average train batch reward = 0.603
validation accuracy = 0.092		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.6865781414006713, 0.67718267836131185, 0.66650389058902437]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006458    	average train batch reward = 0.568
validation accuracy = 0.076		average validation NDCG = 0.656

epoch 2
average train loss = -0.005366    	average train batch reward = 0.569
validation accuracy = 0.076		average validation NDCG = 0.656

epoch 3
average train loss = 0.002140    	average train batch reward = 0.568
validation accuracy = 0.076		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.6865781414006713, 0.67718267836131185, 0.66650389058902437]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013781    	average train batch reward = 0.611
validation accuracy = 0.142		average validation NDCG = 0.697

epoch 2
average train loss = -0.007638    	average train batch reward = 0.609
validation accuracy = 0.141		average validation NDCG = 0.698

epoch 3
average train loss = 0.000194    	average train batch reward = 0.611
validation accuracy = 0.141		average validation NDCG = 0.698

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.69755134694978804, 0.6865781414006713, 0.66650389058902437]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002848    	average train batch reward = 0.572
validation accuracy = 0.087		average validation NDCG = 0.658

epoch 2
average train loss = -0.001909    	average train batch reward = 0.572
validation accuracy = 0.087		average validation NDCG = 0.658

epoch 3
average train loss = -0.006127    	average train batch reward = 0.572
validation accuracy = 0.086		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.69755134694978804, 0.6865781414006713, 0.66650389058902437]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001824    	average train batch reward = 0.573
validation accuracy = 0.089		average validation NDCG = 0.660

epoch 2
average train loss = -0.000928    	average train batch reward = 0.572
validation accuracy = 0.088		average validation NDCG = 0.659

epoch 3
average train loss = -0.008998    	average train batch reward = 0.572
validation accuracy = 0.088		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.69755134694978804, 0.6865781414006713, 0.66650389058902437]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001891    	average train batch reward = 0.601
validation accuracy = 0.102		average validation NDCG = 0.690

epoch 2
average train loss = -0.000113    	average train batch reward = 0.600
validation accuracy = 0.103		average validation NDCG = 0.690

epoch 3
average train loss = -0.000795    	average train batch reward = 0.600
validation accuracy = 0.101		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.69755134694978804, 0.6903464352787726, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.023748    	average train batch reward = 0.627
validation accuracy = 0.185		average validation NDCG = 0.703

epoch 2
average train loss = 0.013008    	average train batch reward = 0.625
validation accuracy = 0.184		average validation NDCG = 0.703

epoch 3
average train loss = -0.001004    	average train batch reward = 0.627
validation accuracy = 0.184		average validation NDCG = 0.703

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.7032948776770036, 0.69755134694978804, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.029833    	average train batch reward = 0.583
validation accuracy = 0.075		average validation NDCG = 0.661

epoch 2
average train loss = -0.041334    	average train batch reward = 0.585
validation accuracy = 0.076		average validation NDCG = 0.662

epoch 3
average train loss = -0.002842    	average train batch reward = 0.584
validation accuracy = 0.076		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.7032948776770036, 0.69755134694978804, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009755    	average train batch reward = 0.582
validation accuracy = 0.092		average validation NDCG = 0.673

epoch 2
average train loss = -0.001029    	average train batch reward = 0.581
validation accuracy = 0.091		average validation NDCG = 0.673

epoch 3
average train loss = 0.010731    	average train batch reward = 0.581
validation accuracy = 0.090		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.7032948776770036, 0.69755134694978804, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003759    	average train batch reward = 0.577
validation accuracy = 0.066		average validation NDCG = 0.658

epoch 2
average train loss = -0.025656    	average train batch reward = 0.579
validation accuracy = 0.067		average validation NDCG = 0.658

epoch 3
average train loss = -0.021005    	average train batch reward = 0.580
validation accuracy = 0.067		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.25, 0.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.7032948776770036, 0.69755134694978804, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000476    	average train batch reward = 0.603
validation accuracy = 0.135		average validation NDCG = 0.707

epoch 2
average train loss = 0.031677    	average train batch reward = 0.602
validation accuracy = 0.134		average validation NDCG = 0.707

epoch 3
average train loss = 0.009375    	average train batch reward = 0.602
validation accuracy = 0.134		average validation NDCG = 0.707

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017981    	average train batch reward = 0.574
validation accuracy = 0.135		average validation NDCG = 0.659

epoch 2
average train loss = 0.008318    	average train batch reward = 0.576
validation accuracy = 0.135		average validation NDCG = 0.659

epoch 3
average train loss = -0.016480    	average train batch reward = 0.576
validation accuracy = 0.135		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.181450    	average train batch reward = 0.589
validation accuracy = 0.117		average validation NDCG = 0.680

epoch 2
average train loss = 0.015969    	average train batch reward = 0.590
validation accuracy = 0.117		average validation NDCG = 0.680

epoch 3
average train loss = -0.137287    	average train batch reward = 0.591
validation accuracy = 0.118		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.6865781414006713]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.025001    	average train batch reward = 0.591
validation accuracy = 0.142		average validation NDCG = 0.690

epoch 2
average train loss = -0.038034    	average train batch reward = 0.592
validation accuracy = 0.141		average validation NDCG = 0.690

epoch 3
average train loss = 0.093552    	average train batch reward = 0.593
validation accuracy = 0.142		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69023178784851302]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.113088    	average train batch reward = 0.582
validation accuracy = 0.079		average validation NDCG = 0.655

epoch 2
average train loss = -0.096567    	average train batch reward = 0.582
validation accuracy = 0.078		average validation NDCG = 0.656

epoch 3
average train loss = -0.151184    	average train batch reward = 0.581
validation accuracy = 0.079		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69023178784851302]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006783    	average train batch reward = 0.587
validation accuracy = 0.107		average validation NDCG = 0.673

epoch 2
average train loss = 0.307907    	average train batch reward = 0.589
validation accuracy = 0.107		average validation NDCG = 0.673

epoch 3
average train loss = -0.128249    	average train batch reward = 0.588
validation accuracy = 0.107		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69023178784851302]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.103462    	average train batch reward = 0.592
validation accuracy = 0.111		average validation NDCG = 0.680

epoch 2
average train loss = 0.285784    	average train batch reward = 0.589
validation accuracy = 0.111		average validation NDCG = 0.680

epoch 3
average train loss = 0.264796    	average train batch reward = 0.591
validation accuracy = 0.109		average validation NDCG = 0.680

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69023178784851302]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004685    	average train batch reward = 0.604
validation accuracy = 0.089		average validation NDCG = 0.684

epoch 2
average train loss = 0.002169    	average train batch reward = 0.603
validation accuracy = 0.088		average validation NDCG = 0.682

epoch 3
average train loss = 0.003328    	average train batch reward = 0.603
validation accuracy = 0.082		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (9.9999999999999995e-07, 0.75, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69023178784851302]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010239    	average train batch reward = 0.619
validation accuracy = 0.158		average validation NDCG = 0.695

epoch 2
average train loss = 0.003696    	average train batch reward = 0.620
validation accuracy = 0.147		average validation NDCG = 0.696

epoch 3
average train loss = 0.007258    	average train batch reward = 0.619
validation accuracy = 0.141		average validation NDCG = 0.696

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007459    	average train batch reward = 0.564
validation accuracy = 0.074		average validation NDCG = 0.653

epoch 2
average train loss = -0.002368    	average train batch reward = 0.563
validation accuracy = 0.071		average validation NDCG = 0.654

epoch 3
average train loss = -0.009195    	average train batch reward = 0.564
validation accuracy = 0.069		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000481    	average train batch reward = 0.591
validation accuracy = 0.098		average validation NDCG = 0.684

epoch 2
average train loss = -0.000220    	average train batch reward = 0.591
validation accuracy = 0.092		average validation NDCG = 0.688

epoch 3
average train loss = -0.010080    	average train batch reward = 0.594
validation accuracy = 0.090		average validation NDCG = 0.688

========
Currently the best setups are [(9.9999999999999995e-07, 0.5, 1.0), (9.9999999999999995e-07, 0.25, 1.5), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70706392192410783, 0.7032948776770036, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003299    	average train batch reward = 0.630
validation accuracy = 0.118		average validation NDCG = 0.709

epoch 2
average train loss = -0.007022    	average train batch reward = 0.629
validation accuracy = 0.109		average validation NDCG = 0.709

epoch 3
average train loss = 0.001515    	average train batch reward = 0.627
validation accuracy = 0.105		average validation NDCG = 0.709

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.012215    	average train batch reward = 0.599
validation accuracy = 0.121		average validation NDCG = 0.689

epoch 2
average train loss = 0.012114    	average train batch reward = 0.598
validation accuracy = 0.119		average validation NDCG = 0.689

epoch 3
average train loss = 0.006702    	average train batch reward = 0.596
validation accuracy = 0.114		average validation NDCG = 0.687

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005413    	average train batch reward = 0.600
validation accuracy = 0.106		average validation NDCG = 0.676

epoch 2
average train loss = 0.011506    	average train batch reward = 0.599
validation accuracy = 0.091		average validation NDCG = 0.675

epoch 3
average train loss = 0.002753    	average train batch reward = 0.597
validation accuracy = 0.084		average validation NDCG = 0.676

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003769    	average train batch reward = 0.581
validation accuracy = 0.129		average validation NDCG = 0.669

epoch 2
average train loss = 0.005195    	average train batch reward = 0.585
validation accuracy = 0.126		average validation NDCG = 0.671

epoch 3
average train loss = 0.001572    	average train batch reward = 0.584
validation accuracy = 0.120		average validation NDCG = 0.669

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007677    	average train batch reward = 0.569
validation accuracy = 0.107		average validation NDCG = 0.667

epoch 2
average train loss = -0.023376    	average train batch reward = 0.567
validation accuracy = 0.097		average validation NDCG = 0.665

epoch 3
average train loss = -0.003843    	average train batch reward = 0.565
validation accuracy = 0.095		average validation NDCG = 0.663

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012363    	average train batch reward = 0.577
validation accuracy = 0.085		average validation NDCG = 0.667

epoch 2
average train loss = -0.012412    	average train batch reward = 0.578
validation accuracy = 0.081		average validation NDCG = 0.666

epoch 3
average train loss = -0.008370    	average train batch reward = 0.575
validation accuracy = 0.072		average validation NDCG = 0.666

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002954    	average train batch reward = 0.580
validation accuracy = 0.120		average validation NDCG = 0.663

epoch 2
average train loss = -0.024019    	average train batch reward = 0.581
validation accuracy = 0.118		average validation NDCG = 0.662

epoch 3
average train loss = -0.016752    	average train batch reward = 0.582
validation accuracy = 0.114		average validation NDCG = 0.662

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009055    	average train batch reward = 0.580
validation accuracy = 0.080		average validation NDCG = 0.660

epoch 2
average train loss = 0.012803    	average train batch reward = 0.578
validation accuracy = 0.082		average validation NDCG = 0.661

epoch 3
average train loss = -0.004874    	average train batch reward = 0.579
validation accuracy = 0.081		average validation NDCG = 0.660

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.035699    	average train batch reward = 0.593
validation accuracy = 0.169		average validation NDCG = 0.676

epoch 2
average train loss = 0.012158    	average train batch reward = 0.595
validation accuracy = 0.152		average validation NDCG = 0.677

epoch 3
average train loss = 0.028934    	average train batch reward = 0.595
validation accuracy = 0.138		average validation NDCG = 0.676

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000210    	average train batch reward = 0.580
validation accuracy = 0.075		average validation NDCG = 0.662

epoch 2
average train loss = -0.023199    	average train batch reward = 0.580
validation accuracy = 0.071		average validation NDCG = 0.662

epoch 3
average train loss = -0.012482    	average train batch reward = 0.581
validation accuracy = 0.075		average validation NDCG = 0.662

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.017019    	average train batch reward = 0.575
validation accuracy = 0.116		average validation NDCG = 0.659

epoch 2
average train loss = 0.003731    	average train batch reward = 0.576
validation accuracy = 0.119		average validation NDCG = 0.659

epoch 3
average train loss = -0.009505    	average train batch reward = 0.576
validation accuracy = 0.110		average validation NDCG = 0.658

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.080383    	average train batch reward = 0.588
validation accuracy = 0.105		average validation NDCG = 0.680

epoch 2
average train loss = 0.074727    	average train batch reward = 0.589
validation accuracy = 0.106		average validation NDCG = 0.679

epoch 3
average train loss = -0.003986    	average train batch reward = 0.591
validation accuracy = 0.107		average validation NDCG = 0.680

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.091024    	average train batch reward = 0.594
validation accuracy = 0.124		average validation NDCG = 0.692

epoch 2
average train loss = -0.063241    	average train batch reward = 0.596
validation accuracy = 0.124		average validation NDCG = 0.694

epoch 3
average train loss = 0.213074    	average train batch reward = 0.595
validation accuracy = 0.124		average validation NDCG = 0.694

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.096596    	average train batch reward = 0.589
validation accuracy = 0.107		average validation NDCG = 0.691

epoch 2
average train loss = -0.247625    	average train batch reward = 0.589
validation accuracy = 0.106		average validation NDCG = 0.690

epoch 3
average train loss = -0.032997    	average train batch reward = 0.591
validation accuracy = 0.107		average validation NDCG = 0.691

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.060169    	average train batch reward = 0.590
validation accuracy = 0.129		average validation NDCG = 0.687

epoch 2
average train loss = -0.108229    	average train batch reward = 0.589
validation accuracy = 0.126		average validation NDCG = 0.687

epoch 3
average train loss = 0.115214    	average train batch reward = 0.589
validation accuracy = 0.127		average validation NDCG = 0.687

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.130760    	average train batch reward = 0.581
validation accuracy = 0.107		average validation NDCG = 0.661

epoch 2
average train loss = -0.010414    	average train batch reward = 0.581
validation accuracy = 0.106		average validation NDCG = 0.661

epoch 3
average train loss = -0.034225    	average train batch reward = 0.582
validation accuracy = 0.105		average validation NDCG = 0.662

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.69644969303611859]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002636    	average train batch reward = 0.603
validation accuracy = 0.090		average validation NDCG = 0.694

epoch 2
average train loss = -0.013843    	average train batch reward = 0.602
validation accuracy = 0.048		average validation NDCG = 0.702

epoch 3
average train loss = -0.013108    	average train batch reward = 0.608
validation accuracy = 0.027		average validation NDCG = 0.693

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (0.0001, 0.1, 0.0)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.70209609012274465]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000127    	average train batch reward = 0.595
validation accuracy = 0.086		average validation NDCG = 0.671

epoch 2
average train loss = -0.006205    	average train batch reward = 0.588
validation accuracy = 0.038		average validation NDCG = 0.679

epoch 3
average train loss = -0.009829    	average train batch reward = 0.602
validation accuracy = 0.039		average validation NDCG = 0.705

========
Currently the best setups are [(1.0000000000000001e-05, 0.1, 1.5), (9.9999999999999995e-07, 0.5, 1.0), (0.0001, 0.1, 0.2)], which got scores of [0.70949513632337369, 0.70706392192410783, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008382    	average train batch reward = 0.592
validation accuracy = 0.091		average validation NDCG = 0.678

epoch 2
average train loss = -0.001938    	average train batch reward = 0.610
validation accuracy = 0.082		average validation NDCG = 0.703

epoch 3
average train loss = -0.002364    	average train batch reward = 0.615
validation accuracy = 0.053		average validation NDCG = 0.713

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015327    	average train batch reward = 0.538
validation accuracy = 0.033		average validation NDCG = 0.643

epoch 2
average train loss = -0.021974    	average train batch reward = 0.535
validation accuracy = 0.025		average validation NDCG = 0.654

epoch 3
average train loss = -0.013955    	average train batch reward = 0.547
validation accuracy = 0.023		average validation NDCG = 0.660

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005712    	average train batch reward = 0.568
validation accuracy = 0.039		average validation NDCG = 0.665

epoch 2
average train loss = -0.004851    	average train batch reward = 0.572
validation accuracy = 0.018		average validation NDCG = 0.663

epoch 3
average train loss = -0.008943    	average train batch reward = 0.584
validation accuracy = 0.015		average validation NDCG = 0.693

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000671    	average train batch reward = 0.582
validation accuracy = 0.093		average validation NDCG = 0.681

epoch 2
average train loss = -0.014669    	average train batch reward = 0.588
validation accuracy = 0.084		average validation NDCG = 0.673

epoch 3
average train loss = -0.012327    	average train batch reward = 0.583
validation accuracy = 0.060		average validation NDCG = 0.677

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003052    	average train batch reward = 0.571
validation accuracy = 0.093		average validation NDCG = 0.659

epoch 2
average train loss = -0.010114    	average train batch reward = 0.570
validation accuracy = 0.060		average validation NDCG = 0.666

epoch 3
average train loss = -0.011446    	average train batch reward = 0.578
validation accuracy = 0.035		average validation NDCG = 0.663

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007203    	average train batch reward = 0.577
validation accuracy = 0.066		average validation NDCG = 0.668

epoch 2
average train loss = 0.003562    	average train batch reward = 0.573
validation accuracy = 0.055		average validation NDCG = 0.648

epoch 3
average train loss = -0.026747    	average train batch reward = 0.564
validation accuracy = 0.047		average validation NDCG = 0.656

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012999    	average train batch reward = 0.569
validation accuracy = 0.040		average validation NDCG = 0.662

epoch 2
average train loss = -0.014394    	average train batch reward = 0.579
validation accuracy = 0.027		average validation NDCG = 0.680

epoch 3
average train loss = -0.015214    	average train batch reward = 0.583
validation accuracy = 0.019		average validation NDCG = 0.679

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002240    	average train batch reward = 0.587
validation accuracy = 0.086		average validation NDCG = 0.688

epoch 2
average train loss = 0.005068    	average train batch reward = 0.590
validation accuracy = 0.068		average validation NDCG = 0.679

epoch 3
average train loss = -0.012927    	average train batch reward = 0.588
validation accuracy = 0.060		average validation NDCG = 0.678

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036790    	average train batch reward = 0.585
validation accuracy = 0.095		average validation NDCG = 0.682

epoch 2
average train loss = -0.016193    	average train batch reward = 0.594
validation accuracy = 0.076		average validation NDCG = 0.676

epoch 3
average train loss = -0.047352    	average train batch reward = 0.584
validation accuracy = 0.062		average validation NDCG = 0.671

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013848    	average train batch reward = 0.592
validation accuracy = 0.109		average validation NDCG = 0.677

epoch 2
average train loss = -0.014076    	average train batch reward = 0.582
validation accuracy = 0.117		average validation NDCG = 0.685

epoch 3
average train loss = -0.027760    	average train batch reward = 0.578
validation accuracy = 0.068		average validation NDCG = 0.667

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.048004    	average train batch reward = 0.585
validation accuracy = 0.117		average validation NDCG = 0.664

epoch 2
average train loss = -0.009797    	average train batch reward = 0.581
validation accuracy = 0.089		average validation NDCG = 0.658

epoch 3
average train loss = -0.050715    	average train batch reward = 0.577
validation accuracy = 0.082		average validation NDCG = 0.662

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.020526    	average train batch reward = 0.570
validation accuracy = 0.071		average validation NDCG = 0.659

epoch 2
average train loss = 0.008912    	average train batch reward = 0.574
validation accuracy = 0.048		average validation NDCG = 0.660

epoch 3
average train loss = -0.007628    	average train batch reward = 0.577
validation accuracy = 0.044		average validation NDCG = 0.656

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.027304    	average train batch reward = 0.574
validation accuracy = 0.046		average validation NDCG = 0.663

epoch 2
average train loss = -0.001723    	average train batch reward = 0.574
validation accuracy = 0.027		average validation NDCG = 0.655

epoch 3
average train loss = -0.044662    	average train batch reward = 0.568
validation accuracy = 0.022		average validation NDCG = 0.647

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.384188    	average train batch reward = 0.582
validation accuracy = 0.067		average validation NDCG = 0.656

epoch 2
average train loss = -0.122948    	average train batch reward = 0.583
validation accuracy = 0.065		average validation NDCG = 0.664

epoch 3
average train loss = -0.164853    	average train batch reward = 0.586
validation accuracy = 0.083		average validation NDCG = 0.670

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.129302    	average train batch reward = 0.591
validation accuracy = 0.116		average validation NDCG = 0.674

epoch 2
average train loss = -0.197354    	average train batch reward = 0.591
validation accuracy = 0.136		average validation NDCG = 0.679

epoch 3
average train loss = 0.035124    	average train batch reward = 0.593
validation accuracy = 0.100		average validation NDCG = 0.680

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007192    	average train batch reward = 0.585
validation accuracy = 0.068		average validation NDCG = 0.658

epoch 2
average train loss = -0.025938    	average train batch reward = 0.586
validation accuracy = 0.067		average validation NDCG = 0.664

epoch 3
average train loss = 0.180357    	average train batch reward = 0.587
validation accuracy = 0.084		average validation NDCG = 0.671

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.153567    	average train batch reward = 0.583
validation accuracy = 0.086		average validation NDCG = 0.671

epoch 2
average train loss = -0.146321    	average train batch reward = 0.582
validation accuracy = 0.085		average validation NDCG = 0.664

epoch 3
average train loss = -0.186566    	average train batch reward = 0.581
validation accuracy = 0.080		average validation NDCG = 0.661

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.441375    	average train batch reward = 0.576
validation accuracy = 0.089		average validation NDCG = 0.651

epoch 2
average train loss = -0.080549    	average train batch reward = 0.581
validation accuracy = 0.060		average validation NDCG = 0.655

epoch 3
average train loss = 0.244704    	average train batch reward = 0.584
validation accuracy = 0.069		average validation NDCG = 0.655

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011759    	average train batch reward = 0.559
validation accuracy = 0.029		average validation NDCG = 0.657

epoch 2
average train loss = -0.007586    	average train batch reward = 0.553
validation accuracy = 0.012		average validation NDCG = 0.635

epoch 3
average train loss = -0.011839    	average train batch reward = 0.552
validation accuracy = 0.033		average validation NDCG = 0.641

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.013558    	average train batch reward = 0.564
validation accuracy = 0.018		average validation NDCG = 0.652

epoch 2
average train loss = -0.009823    	average train batch reward = 0.563
validation accuracy = 0.036		average validation NDCG = 0.660

epoch 3
average train loss = -0.022494    	average train batch reward = 0.567
validation accuracy = 0.027		average validation NDCG = 0.655

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007185    	average train batch reward = 0.562
validation accuracy = 0.065		average validation NDCG = 0.665

epoch 2
average train loss = -0.008427    	average train batch reward = 0.577
validation accuracy = 0.031		average validation NDCG = 0.656

epoch 3
average train loss = -0.025693    	average train batch reward = 0.572
validation accuracy = 0.058		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003058    	average train batch reward = 0.606
validation accuracy = 0.100		average validation NDCG = 0.672

epoch 2
average train loss = -0.009440    	average train batch reward = 0.566
validation accuracy = 0.038		average validation NDCG = 0.648

epoch 3
average train loss = -0.016795    	average train batch reward = 0.561
validation accuracy = 0.004		average validation NDCG = 0.646

========
Currently the best setups are [(0.0001, 0.1, 0.5), (1.0000000000000001e-05, 0.1, 1.5), (0.0001, 0.1, 0.2)], which got scores of [0.71252732774535721, 0.70949513632337369, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002585    	average train batch reward = 0.616
validation accuracy = 0.079		average validation NDCG = 0.717

epoch 2
average train loss = 0.002239    	average train batch reward = 0.623
validation accuracy = 0.038		average validation NDCG = 0.721

epoch 3
average train loss = -0.004606    	average train batch reward = 0.608
validation accuracy = 0.043		average validation NDCG = 0.682

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.0001, 0.1, 0.2)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.70467256555605184]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003358    	average train batch reward = 0.607
validation accuracy = 0.170		average validation NDCG = 0.712

epoch 2
average train loss = 0.000332    	average train batch reward = 0.611
validation accuracy = 0.070		average validation NDCG = 0.695

epoch 3
average train loss = 0.010644    	average train batch reward = 0.607
validation accuracy = 0.093		average validation NDCG = 0.696

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009926    	average train batch reward = 0.576
validation accuracy = 0.036		average validation NDCG = 0.655

epoch 2
average train loss = -0.013311    	average train batch reward = 0.569
validation accuracy = 0.072		average validation NDCG = 0.650

epoch 3
average train loss = -0.017225    	average train batch reward = 0.569
validation accuracy = 0.039		average validation NDCG = 0.653

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002772    	average train batch reward = 0.576
validation accuracy = 0.073		average validation NDCG = 0.669

epoch 2
average train loss = -0.015035    	average train batch reward = 0.580
validation accuracy = 0.039		average validation NDCG = 0.670

epoch 3
average train loss = -0.014686    	average train batch reward = 0.580
validation accuracy = 0.046		average validation NDCG = 0.663

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015410    	average train batch reward = 0.574
validation accuracy = 0.050		average validation NDCG = 0.646

epoch 2
average train loss = -0.034399    	average train batch reward = 0.552
validation accuracy = 0.016		average validation NDCG = 0.638

epoch 3
average train loss = -0.031439    	average train batch reward = 0.555
validation accuracy = 0.051		average validation NDCG = 0.631

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003843    	average train batch reward = 0.571
validation accuracy = 0.053		average validation NDCG = 0.651

epoch 2
average train loss = -0.005433    	average train batch reward = 0.571
validation accuracy = 0.144		average validation NDCG = 0.660

epoch 3
average train loss = -0.004003    	average train batch reward = 0.573
validation accuracy = 0.022		average validation NDCG = 0.656

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000411    	average train batch reward = 0.596
validation accuracy = 0.130		average validation NDCG = 0.701

epoch 2
average train loss = 0.004062    	average train batch reward = 0.591
validation accuracy = 0.067		average validation NDCG = 0.671

epoch 3
average train loss = 0.024120    	average train batch reward = 0.590
validation accuracy = 0.092		average validation NDCG = 0.682

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.053781    	average train batch reward = 0.587
validation accuracy = 0.073		average validation NDCG = 0.662

epoch 2
average train loss = -0.056711    	average train batch reward = 0.581
validation accuracy = 0.061		average validation NDCG = 0.667

epoch 3
average train loss = -0.023686    	average train batch reward = 0.584
validation accuracy = 0.068		average validation NDCG = 0.666

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.031225    	average train batch reward = 0.584
validation accuracy = 0.117		average validation NDCG = 0.666

epoch 2
average train loss = -0.036053    	average train batch reward = 0.586
validation accuracy = 0.143		average validation NDCG = 0.672

epoch 3
average train loss = -0.032491    	average train batch reward = 0.583
validation accuracy = 0.114		average validation NDCG = 0.666

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003260    	average train batch reward = 0.593
validation accuracy = 0.117		average validation NDCG = 0.688

epoch 2
average train loss = 0.010638    	average train batch reward = 0.589
validation accuracy = 0.121		average validation NDCG = 0.677

epoch 3
average train loss = 0.038517    	average train batch reward = 0.586
validation accuracy = 0.077		average validation NDCG = 0.673

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.139980    	average train batch reward = 0.575
validation accuracy = 0.084		average validation NDCG = 0.646

epoch 2
average train loss = -0.013857    	average train batch reward = 0.571
validation accuracy = 0.050		average validation NDCG = 0.638

epoch 3
average train loss = 0.004874    	average train batch reward = 0.568
validation accuracy = 0.050		average validation NDCG = 0.641

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.361614    	average train batch reward = 0.592
validation accuracy = 0.127		average validation NDCG = 0.701

epoch 2
average train loss = 0.630228    	average train batch reward = 0.591
validation accuracy = 0.084		average validation NDCG = 0.690

epoch 3
average train loss = -0.032733    	average train batch reward = 0.584
validation accuracy = 0.050		average validation NDCG = 0.664

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.152759    	average train batch reward = 0.591
validation accuracy = 0.081		average validation NDCG = 0.667

epoch 2
average train loss = -0.233962    	average train batch reward = 0.587
validation accuracy = 0.130		average validation NDCG = 0.686

epoch 3
average train loss = 0.370445    	average train batch reward = 0.593
validation accuracy = 0.145		average validation NDCG = 0.689

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.064830    	average train batch reward = 0.596
validation accuracy = 0.145		average validation NDCG = 0.707

epoch 2
average train loss = 0.050753    	average train batch reward = 0.591
validation accuracy = 0.115		average validation NDCG = 0.677

epoch 3
average train loss = -0.391910    	average train batch reward = 0.584
validation accuracy = 0.113		average validation NDCG = 0.658

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.208903    	average train batch reward = 0.585
validation accuracy = 0.124		average validation NDCG = 0.670

epoch 2
average train loss = -0.526183    	average train batch reward = 0.583
validation accuracy = 0.085		average validation NDCG = 0.666

epoch 3
average train loss = -0.826401    	average train batch reward = 0.585
validation accuracy = 0.036		average validation NDCG = 0.657

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.394811    	average train batch reward = 0.593
validation accuracy = 0.046		average validation NDCG = 0.667

epoch 2
average train loss = 0.187071    	average train batch reward = 0.584
validation accuracy = 0.055		average validation NDCG = 0.664

epoch 3
average train loss = -0.067693    	average train batch reward = 0.585
validation accuracy = 0.074		average validation NDCG = 0.667

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003048    	average train batch reward = 0.556
validation accuracy = 0.072		average validation NDCG = 0.644

epoch 2
average train loss = -0.028733    	average train batch reward = 0.559
validation accuracy = 0.088		average validation NDCG = 0.642

epoch 3
average train loss = -0.001601    	average train batch reward = 0.563
validation accuracy = 0.043		average validation NDCG = 0.660

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.018817    	average train batch reward = 0.607
validation accuracy = 0.056		average validation NDCG = 0.695

epoch 2
average train loss = 0.019349    	average train batch reward = 0.588
validation accuracy = 0.057		average validation NDCG = 0.668

epoch 3
average train loss = -0.011264    	average train batch reward = 0.577
validation accuracy = 0.087		average validation NDCG = 0.664

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006994    	average train batch reward = 0.600
validation accuracy = 0.129		average validation NDCG = 0.670

epoch 2
average train loss = 0.004661    	average train batch reward = 0.577
validation accuracy = 0.123		average validation NDCG = 0.668

epoch 3
average train loss = 0.029256    	average train batch reward = 0.579
validation accuracy = 0.099		average validation NDCG = 0.660

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.048553    	average train batch reward = 0.559
validation accuracy = 0.166		average validation NDCG = 0.645

epoch 2
average train loss = 0.029518    	average train batch reward = 0.568
validation accuracy = 0.177		average validation NDCG = 0.656

epoch 3
average train loss = -0.040884    	average train batch reward = 0.571
validation accuracy = 0.106		average validation NDCG = 0.663

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001143    	average train batch reward = 0.594
validation accuracy = 0.098		average validation NDCG = 0.680

epoch 2
average train loss = -0.069846    	average train batch reward = 0.583
validation accuracy = 0.113		average validation NDCG = 0.665

epoch 3
average train loss = -0.032800    	average train batch reward = 0.584
validation accuracy = 0.145		average validation NDCG = 0.676

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.051883    	average train batch reward = 0.570
validation accuracy = 0.106		average validation NDCG = 0.653

epoch 2
average train loss = -0.048231    	average train batch reward = 0.566
validation accuracy = 0.110		average validation NDCG = 0.648

epoch 3
average train loss = -0.045941    	average train batch reward = 0.565
validation accuracy = 0.191		average validation NDCG = 0.651

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004101    	average train batch reward = 0.589
validation accuracy = 0.198		average validation NDCG = 0.681

epoch 2
average train loss = -0.075977    	average train batch reward = 0.597
validation accuracy = 0.193		average validation NDCG = 0.683

epoch 3
average train loss = 0.021269    	average train batch reward = 0.595
validation accuracy = 0.124		average validation NDCG = 0.681

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.055175    	average train batch reward = 0.578
validation accuracy = 0.098		average validation NDCG = 0.661

epoch 2
average train loss = 0.000344    	average train batch reward = 0.577
validation accuracy = 0.107		average validation NDCG = 0.665

epoch 3
average train loss = -0.000781    	average train batch reward = 0.584
validation accuracy = 0.107		average validation NDCG = 0.668

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008536    	average train batch reward = 0.590
validation accuracy = 0.128		average validation NDCG = 0.665

epoch 2
average train loss = 0.190688    	average train batch reward = 0.584
validation accuracy = 0.107		average validation NDCG = 0.667

epoch 3
average train loss = 0.073002    	average train batch reward = 0.582
validation accuracy = 0.079		average validation NDCG = 0.660

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.029265    	average train batch reward = 0.585
validation accuracy = 0.089		average validation NDCG = 0.666

epoch 2
average train loss = -0.018031    	average train batch reward = 0.583
validation accuracy = 0.110		average validation NDCG = 0.669

epoch 3
average train loss = -0.045787    	average train batch reward = 0.587
validation accuracy = 0.088		average validation NDCG = 0.669

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.097893    	average train batch reward = 0.583
validation accuracy = 0.069		average validation NDCG = 0.666

epoch 2
average train loss = 0.306022    	average train batch reward = 0.587
validation accuracy = 0.110		average validation NDCG = 0.675

epoch 3
average train loss = -0.090076    	average train batch reward = 0.587
validation accuracy = 0.098		average validation NDCG = 0.670

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.107984    	average train batch reward = 0.575
validation accuracy = 0.123		average validation NDCG = 0.649

epoch 2
average train loss = 0.088354    	average train batch reward = 0.578
validation accuracy = 0.063		average validation NDCG = 0.661

epoch 3
average train loss = -0.099855    	average train batch reward = 0.580
validation accuracy = 0.102		average validation NDCG = 0.659

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.106086    	average train batch reward = 0.584
validation accuracy = 0.057		average validation NDCG = 0.649

epoch 2
average train loss = -0.291817    	average train batch reward = 0.577
validation accuracy = 0.013		average validation NDCG = 0.657

epoch 3
average train loss = -0.017997    	average train batch reward = 0.577
validation accuracy = 0.013		average validation NDCG = 0.656

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.055050    	average train batch reward = 0.582
validation accuracy = 0.117		average validation NDCG = 0.658

epoch 2
average train loss = -0.069163    	average train batch reward = 0.580
validation accuracy = 0.095		average validation NDCG = 0.662

epoch 3
average train loss = -0.000359    	average train batch reward = 0.583
validation accuracy = 0.105		average validation NDCG = 0.667

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.049740    	average train batch reward = 0.581
validation accuracy = 0.070		average validation NDCG = 0.668

epoch 2
average train loss = -0.055251    	average train batch reward = 0.585
validation accuracy = 0.097		average validation NDCG = 0.664

epoch 3
average train loss = 0.002499    	average train batch reward = 0.585
validation accuracy = 0.157		average validation NDCG = 0.665

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.806840    	average train batch reward = 0.587
validation accuracy = 0.073		average validation NDCG = 0.673

epoch 2
average train loss = 1.298060    	average train batch reward = 0.584
validation accuracy = 0.108		average validation NDCG = 0.664

epoch 3
average train loss = -0.002606    	average train batch reward = 0.585
validation accuracy = 0.115		average validation NDCG = 0.670

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.908157    	average train batch reward = 0.588
validation accuracy = 0.111		average validation NDCG = 0.680

epoch 2
average train loss = -0.452569    	average train batch reward = 0.588
validation accuracy = 0.142		average validation NDCG = 0.684

epoch 3
average train loss = -0.343951    	average train batch reward = 0.592
validation accuracy = 0.213		average validation NDCG = 0.687

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.488430    	average train batch reward = 0.587
validation accuracy = 0.098		average validation NDCG = 0.679

epoch 2
average train loss = 0.958749    	average train batch reward = 0.586
validation accuracy = 0.100		average validation NDCG = 0.669

epoch 3
average train loss = -0.245848    	average train batch reward = 0.585
validation accuracy = 0.092		average validation NDCG = 0.669

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.932747    	average train batch reward = 0.590
validation accuracy = 0.051		average validation NDCG = 0.683

epoch 2
average train loss = 3.430922    	average train batch reward = 0.590
validation accuracy = 0.097		average validation NDCG = 0.680

epoch 3
average train loss = 0.443994    	average train batch reward = 0.588
validation accuracy = 0.097		average validation NDCG = 0.681

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.636730    	average train batch reward = 0.591
validation accuracy = 0.096		average validation NDCG = 0.678

epoch 2
average train loss = -2.381897    	average train batch reward = 0.589
validation accuracy = 0.133		average validation NDCG = 0.681

epoch 3
average train loss = 1.211526    	average train batch reward = 0.591
validation accuracy = 0.067		average validation NDCG = 0.688

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.019449    	average train batch reward = 0.587
validation accuracy = 0.070		average validation NDCG = 0.668

epoch 2
average train loss = 0.018145    	average train batch reward = 0.580
validation accuracy = 0.095		average validation NDCG = 0.662

epoch 3
average train loss = -0.241883    	average train batch reward = 0.581
validation accuracy = 0.101		average validation NDCG = 0.665

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.347112    	average train batch reward = 0.581
validation accuracy = 0.117		average validation NDCG = 0.668

epoch 2
average train loss = 0.098914    	average train batch reward = 0.590
validation accuracy = 0.097		average validation NDCG = 0.678

epoch 3
average train loss = 0.035219    	average train batch reward = 0.592
validation accuracy = 0.097		average validation NDCG = 0.673

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000266    	average train batch reward = 0.593
validation accuracy = 0.113		average validation NDCG = 0.686

epoch 2
average train loss = -0.018502    	average train batch reward = 0.591
validation accuracy = 0.107		average validation NDCG = 0.669

epoch 3
average train loss = -0.000000    	average train batch reward = 0.585
validation accuracy = 0.107		average validation NDCG = 0.669

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013195    	average train batch reward = 0.576
validation accuracy = 0.107		average validation NDCG = 0.659

epoch 2
average train loss = 0.000001    	average train batch reward = 0.579
validation accuracy = 0.142		average validation NDCG = 0.671

epoch 3
average train loss = -0.003295    	average train batch reward = 0.587
validation accuracy = 0.188		average validation NDCG = 0.676

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.033637    	average train batch reward = 0.577
validation accuracy = 0.099		average validation NDCG = 0.664

epoch 2
average train loss = 0.002601    	average train batch reward = 0.579
validation accuracy = 0.099		average validation NDCG = 0.673

epoch 3
average train loss = -0.000078    	average train batch reward = 0.586
validation accuracy = 0.099		average validation NDCG = 0.672

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.140850    	average train batch reward = 0.576
validation accuracy = 0.065		average validation NDCG = 0.657

epoch 2
average train loss = 0.435127    	average train batch reward = 0.577
validation accuracy = 0.110		average validation NDCG = 0.667

epoch 3
average train loss = 0.000001    	average train batch reward = 0.581
validation accuracy = 0.099		average validation NDCG = 0.665

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.023211    	average train batch reward = 0.585
validation accuracy = 0.087		average validation NDCG = 0.667

epoch 2
average train loss = -0.000000    	average train batch reward = 0.584
validation accuracy = 0.087		average validation NDCG = 0.667

epoch 3
average train loss = -0.000000    	average train batch reward = 0.583
validation accuracy = 0.087		average validation NDCG = 0.667

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.059577    	average train batch reward = 0.582
validation accuracy = 0.082		average validation NDCG = 0.663

epoch 2
average train loss = 0.813002    	average train batch reward = 0.585
validation accuracy = 0.098		average validation NDCG = 0.676

epoch 3
average train loss = 0.000000    	average train batch reward = 0.591
validation accuracy = 0.098		average validation NDCG = 0.676

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.034747    	average train batch reward = 0.593
validation accuracy = 0.099		average validation NDCG = 0.679

epoch 2
average train loss = 0.071005    	average train batch reward = 0.588
validation accuracy = 0.107		average validation NDCG = 0.672

epoch 3
average train loss = 0.025248    	average train batch reward = 0.586
validation accuracy = 0.109		average validation NDCG = 0.654

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.027079    	average train batch reward = 0.586
validation accuracy = 0.083		average validation NDCG = 0.677

epoch 2
average train loss = 0.203190    	average train batch reward = 0.594
validation accuracy = 0.099		average validation NDCG = 0.687

epoch 3
average train loss = 0.092544    	average train batch reward = 0.597
validation accuracy = 0.099		average validation NDCG = 0.687

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.047819    	average train batch reward = 0.585
validation accuracy = 0.040		average validation NDCG = 0.680

epoch 2
average train loss = -17.622370    	average train batch reward = 0.587
validation accuracy = 0.100		average validation NDCG = 0.671

epoch 3
average train loss = -0.000000    	average train batch reward = 0.584
validation accuracy = 0.100		average validation NDCG = 0.671

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 7.938613    	average train batch reward = 0.595
validation accuracy = 0.137		average validation NDCG = 0.692

epoch 2
average train loss = 0.000000    	average train batch reward = 0.598
validation accuracy = 0.126		average validation NDCG = 0.691

epoch 3
average train loss = -0.100695    	average train batch reward = 0.597
validation accuracy = 0.123		average validation NDCG = 0.691

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.059132    	average train batch reward = 0.597
validation accuracy = 0.068		average validation NDCG = 0.689

epoch 2
average train loss = -0.000000    	average train batch reward = 0.596
validation accuracy = 0.070		average validation NDCG = 0.689

epoch 3
average train loss = 0.213876    	average train batch reward = 0.591
validation accuracy = 0.055		average validation NDCG = 0.677

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -13.104679    	average train batch reward = 0.586
validation accuracy = 0.100		average validation NDCG = 0.681

epoch 2
average train loss = 0.251111    	average train batch reward = 0.588
validation accuracy = 0.100		average validation NDCG = 0.671

epoch 3
average train loss = -0.080702    	average train batch reward = 0.588
validation accuracy = 0.100		average validation NDCG = 0.672

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.056869    	average train batch reward = 0.585
validation accuracy = 0.035		average validation NDCG = 0.672

epoch 2
average train loss = -2.654029    	average train batch reward = 0.585
validation accuracy = 0.092		average validation NDCG = 0.665

epoch 3
average train loss = 1.320680    	average train batch reward = 0.583
validation accuracy = 0.092		average validation NDCG = 0.662

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.060540    	average train batch reward = 0.590
validation accuracy = 0.095		average validation NDCG = 0.688

epoch 2
average train loss = 0.167584    	average train batch reward = 0.590
validation accuracy = 0.096		average validation NDCG = 0.673

epoch 3
average train loss = 3.021255    	average train batch reward = 0.586
validation accuracy = 0.097		average validation NDCG = 0.663

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.938249    	average train batch reward = 0.587
validation accuracy = 0.098		average validation NDCG = 0.673

epoch 2
average train loss = -0.707971    	average train batch reward = 0.589
validation accuracy = 0.104		average validation NDCG = 0.689

epoch 3
average train loss = 0.014744    	average train batch reward = 0.589
validation accuracy = 0.093		average validation NDCG = 0.681

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.513656    	average train batch reward = 0.588
validation accuracy = 0.107		average validation NDCG = 0.674

epoch 2
average train loss = -0.000010    	average train batch reward = 0.588
validation accuracy = 0.107		average validation NDCG = 0.674

epoch 3
average train loss = -4.256654    	average train batch reward = 0.585
validation accuracy = 0.083		average validation NDCG = 0.679

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.118082    	average train batch reward = 0.579
validation accuracy = 0.098		average validation NDCG = 0.647

epoch 2
average train loss = 18.537563    	average train batch reward = 0.586
validation accuracy = 0.107		average validation NDCG = 0.681

epoch 3
average train loss = -0.000565    	average train batch reward = 0.590
validation accuracy = 0.146		average validation NDCG = 0.683

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
Hyperparameters:
k = 7
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ba8c2c79320>
Reward function = <function ndcg_full at 0x2ba8c2c79398>
Greedy action = <function sample at 0x2ba8bba7c9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.118273    	average train batch reward = 0.587
validation accuracy = 0.144		average validation NDCG = 0.683

epoch 2
average train loss = 0.000000    	average train batch reward = 0.589
validation accuracy = 0.145		average validation NDCG = 0.683

epoch 3
average train loss = -2.025232    	average train batch reward = 0.588
validation accuracy = 0.087		average validation NDCG = 0.679

========
Currently the best setups are [(0.001, 0.1, 1.5), (0.0001, 0.1, 0.5), (0.001, 0.25, 0.0)], which got scores of [0.72084011175157392, 0.71252732774535721, 0.71193943610538102]
========
2017-07-03 11:01:59
