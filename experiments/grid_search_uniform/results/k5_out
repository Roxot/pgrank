2017-07-03 06:38:57
Finding best parameters for k = 5
=========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006380    	average train batch reward = 0.673
validation accuracy = 0.093		average validation NDCG = 0.697

epoch 2
average train loss = 0.001515    	average train batch reward = 0.671
validation accuracy = 0.094		average validation NDCG = 0.698

epoch 3
average train loss = 0.001632    	average train batch reward = 0.674
validation accuracy = 0.095		average validation NDCG = 0.698

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (), ()], which got scores of [0.6982159112930566, -1, -1]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002353    	average train batch reward = 0.663
validation accuracy = 0.100		average validation NDCG = 0.690

epoch 2
average train loss = -0.001903    	average train batch reward = 0.665
validation accuracy = 0.099		average validation NDCG = 0.691

epoch 3
average train loss = -0.001476    	average train batch reward = 0.665
validation accuracy = 0.098		average validation NDCG = 0.691

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), ()], which got scores of [0.6982159112930566, 0.69146788842693241, -1]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003666    	average train batch reward = 0.619
validation accuracy = 0.067		average validation NDCG = 0.657

epoch 2
average train loss = -0.003804    	average train batch reward = 0.621
validation accuracy = 0.067		average validation NDCG = 0.658

epoch 3
average train loss = -0.007837    	average train batch reward = 0.622
validation accuracy = 0.067		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 0.5)], which got scores of [0.6982159112930566, 0.69146788842693241, 0.65834022266290637]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003043    	average train batch reward = 0.632
validation accuracy = 0.091		average validation NDCG = 0.665

epoch 2
average train loss = 0.002062    	average train batch reward = 0.631
validation accuracy = 0.091		average validation NDCG = 0.665

epoch 3
average train loss = -0.003439    	average train batch reward = 0.630
validation accuracy = 0.091		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 1.0)], which got scores of [0.6982159112930566, 0.69146788842693241, 0.66549735141995625]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001272    	average train batch reward = 0.654
validation accuracy = 0.092		average validation NDCG = 0.680

epoch 2
average train loss = 0.001947    	average train batch reward = 0.655
validation accuracy = 0.093		average validation NDCG = 0.681

epoch 3
average train loss = 0.002933    	average train batch reward = 0.654
validation accuracy = 0.092		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.6982159112930566, 0.69146788842693241, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004282    	average train batch reward = 0.618
validation accuracy = 0.072		average validation NDCG = 0.645

epoch 2
average train loss = -0.000376    	average train batch reward = 0.618
validation accuracy = 0.072		average validation NDCG = 0.645

epoch 3
average train loss = -0.007715    	average train batch reward = 0.620
validation accuracy = 0.072		average validation NDCG = 0.646

========
Currently the best setups are [(9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 0.2), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.6982159112930566, 0.69146788842693241, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.017166    	average train batch reward = 0.677
validation accuracy = 0.117		average validation NDCG = 0.711

epoch 2
average train loss = 0.000160    	average train batch reward = 0.677
validation accuracy = 0.117		average validation NDCG = 0.712

epoch 3
average train loss = 0.008970    	average train batch reward = 0.678
validation accuracy = 0.117		average validation NDCG = 0.713

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005932    	average train batch reward = 0.647
validation accuracy = 0.086		average validation NDCG = 0.674

epoch 2
average train loss = 0.008105    	average train batch reward = 0.649
validation accuracy = 0.085		average validation NDCG = 0.674

epoch 3
average train loss = -0.007106    	average train batch reward = 0.647
validation accuracy = 0.084		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001652    	average train batch reward = 0.624
validation accuracy = 0.091		average validation NDCG = 0.655

epoch 2
average train loss = 0.006224    	average train batch reward = 0.626
validation accuracy = 0.091		average validation NDCG = 0.656

epoch 3
average train loss = -0.006312    	average train batch reward = 0.626
validation accuracy = 0.091		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005065    	average train batch reward = 0.635
validation accuracy = 0.124		average validation NDCG = 0.661

epoch 2
average train loss = -0.000192    	average train batch reward = 0.637
validation accuracy = 0.125		average validation NDCG = 0.661

epoch 3
average train loss = -0.006267    	average train batch reward = 0.636
validation accuracy = 0.125		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.1, 1.5)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68103926035493567]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002182    	average train batch reward = 0.653
validation accuracy = 0.096		average validation NDCG = 0.688

epoch 2
average train loss = 0.002248    	average train batch reward = 0.653
validation accuracy = 0.096		average validation NDCG = 0.688

epoch 3
average train loss = 0.007800    	average train batch reward = 0.654
validation accuracy = 0.096		average validation NDCG = 0.688

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68849231356928997]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.005146    	average train batch reward = 0.647
validation accuracy = 0.126		average validation NDCG = 0.674

epoch 2
average train loss = 0.018117    	average train batch reward = 0.648
validation accuracy = 0.126		average validation NDCG = 0.675

epoch 3
average train loss = -0.001686    	average train batch reward = 0.649
validation accuracy = 0.127		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68849231356928997]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015249    	average train batch reward = 0.644
validation accuracy = 0.121		average validation NDCG = 0.679

epoch 2
average train loss = 0.008174    	average train batch reward = 0.645
validation accuracy = 0.122		average validation NDCG = 0.679

epoch 3
average train loss = 0.009427    	average train batch reward = 0.645
validation accuracy = 0.122		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68849231356928997]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006945    	average train batch reward = 0.643
validation accuracy = 0.095		average validation NDCG = 0.674

epoch 2
average train loss = 0.010026    	average train batch reward = 0.643
validation accuracy = 0.096		average validation NDCG = 0.674

epoch 3
average train loss = 0.000041    	average train batch reward = 0.643
validation accuracy = 0.097		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68849231356928997]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004954    	average train batch reward = 0.638
validation accuracy = 0.078		average validation NDCG = 0.681

epoch 2
average train loss = -0.012236    	average train batch reward = 0.641
validation accuracy = 0.078		average validation NDCG = 0.681

epoch 3
average train loss = -0.010407    	average train batch reward = 0.640
validation accuracy = 0.078		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.5, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.68849231356928997]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002985    	average train batch reward = 0.643
validation accuracy = 0.061		average validation NDCG = 0.693

epoch 2
average train loss = 0.017759    	average train batch reward = 0.644
validation accuracy = 0.061		average validation NDCG = 0.693

epoch 3
average train loss = 0.004062    	average train batch reward = 0.644
validation accuracy = 0.061		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006238    	average train batch reward = 0.636
validation accuracy = 0.070		average validation NDCG = 0.659

epoch 2
average train loss = 0.016374    	average train batch reward = 0.636
validation accuracy = 0.070		average validation NDCG = 0.659

epoch 3
average train loss = -0.017796    	average train batch reward = 0.636
validation accuracy = 0.071		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002307    	average train batch reward = 0.635
validation accuracy = 0.070		average validation NDCG = 0.664

epoch 2
average train loss = -0.025270    	average train batch reward = 0.637
validation accuracy = 0.070		average validation NDCG = 0.664

epoch 3
average train loss = -0.009567    	average train batch reward = 0.637
validation accuracy = 0.070		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004394    	average train batch reward = 0.641
validation accuracy = 0.057		average validation NDCG = 0.664

epoch 2
average train loss = 0.008394    	average train batch reward = 0.642
validation accuracy = 0.057		average validation NDCG = 0.664

epoch 3
average train loss = 0.001639    	average train batch reward = 0.641
validation accuracy = 0.057		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003634    	average train batch reward = 0.646
validation accuracy = 0.132		average validation NDCG = 0.677

epoch 2
average train loss = 0.055906    	average train batch reward = 0.645
validation accuracy = 0.132		average validation NDCG = 0.677

epoch 3
average train loss = 0.015424    	average train batch reward = 0.646
validation accuracy = 0.133		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008465    	average train batch reward = 0.636
validation accuracy = 0.089		average validation NDCG = 0.667

epoch 2
average train loss = 0.004884    	average train batch reward = 0.642
validation accuracy = 0.091		average validation NDCG = 0.670

epoch 3
average train loss = 0.006901    	average train batch reward = 0.645
validation accuracy = 0.092		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (9.9999999999999995e-07, 0.75, 0.0)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69328388650703943]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001290    	average train batch reward = 0.655
validation accuracy = 0.091		average validation NDCG = 0.685

epoch 2
average train loss = -0.007069    	average train batch reward = 0.657
validation accuracy = 0.092		average validation NDCG = 0.690

epoch 3
average train loss = -0.000532    	average train batch reward = 0.661
validation accuracy = 0.088		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69330971376819528]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003306    	average train batch reward = 0.642
validation accuracy = 0.105		average validation NDCG = 0.678

epoch 2
average train loss = -0.000499    	average train batch reward = 0.644
validation accuracy = 0.105		average validation NDCG = 0.681

epoch 3
average train loss = -0.002940    	average train batch reward = 0.648
validation accuracy = 0.106		average validation NDCG = 0.685

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69330971376819528]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002030    	average train batch reward = 0.649
validation accuracy = 0.120		average validation NDCG = 0.672

epoch 2
average train loss = 0.007810    	average train batch reward = 0.660
validation accuracy = 0.125		average validation NDCG = 0.678

epoch 3
average train loss = 0.006511    	average train batch reward = 0.666
validation accuracy = 0.129		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69330971376819528]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001840    	average train batch reward = 0.643
validation accuracy = 0.100		average validation NDCG = 0.677

epoch 2
average train loss = 0.006164    	average train batch reward = 0.648
validation accuracy = 0.107		average validation NDCG = 0.683

epoch 3
average train loss = 0.004766    	average train batch reward = 0.655
validation accuracy = 0.110		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69330971376819528]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003016    	average train batch reward = 0.644
validation accuracy = 0.118		average validation NDCG = 0.679

epoch 2
average train loss = -0.002516    	average train batch reward = 0.651
validation accuracy = 0.119		average validation NDCG = 0.685

epoch 3
average train loss = 0.004706    	average train batch reward = 0.657
validation accuracy = 0.120		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.1, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69330971376819528]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007338    	average train batch reward = 0.664
validation accuracy = 0.138		average validation NDCG = 0.689

epoch 2
average train loss = 0.007519    	average train batch reward = 0.666
validation accuracy = 0.138		average validation NDCG = 0.693

epoch 3
average train loss = 0.006720    	average train batch reward = 0.672
validation accuracy = 0.131		average validation NDCG = 0.698

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69766352625313321]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000759    	average train batch reward = 0.653
validation accuracy = 0.108		average validation NDCG = 0.689

epoch 2
average train loss = 0.002067    	average train batch reward = 0.660
validation accuracy = 0.105		average validation NDCG = 0.695

epoch 3
average train loss = 0.000433    	average train batch reward = 0.663
validation accuracy = 0.098		average validation NDCG = 0.697

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (9.9999999999999995e-07, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 0.2)], which got scores of [0.712815461926533, 0.6982159112930566, 0.69766352625313321]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000898    	average train batch reward = 0.653
validation accuracy = 0.102		average validation NDCG = 0.698

epoch 2
average train loss = 0.002763    	average train batch reward = 0.659
validation accuracy = 0.102		average validation NDCG = 0.701

epoch 3
average train loss = -0.004422    	average train batch reward = 0.661
validation accuracy = 0.105		average validation NDCG = 0.706

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002558    	average train batch reward = 0.643
validation accuracy = 0.098		average validation NDCG = 0.672

epoch 2
average train loss = 0.004845    	average train batch reward = 0.647
validation accuracy = 0.103		average validation NDCG = 0.675

epoch 3
average train loss = 0.009858    	average train batch reward = 0.653
validation accuracy = 0.092		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004766    	average train batch reward = 0.643
validation accuracy = 0.093		average validation NDCG = 0.677

epoch 2
average train loss = -0.000300    	average train batch reward = 0.645
validation accuracy = 0.097		average validation NDCG = 0.680

epoch 3
average train loss = 0.000724    	average train batch reward = 0.650
validation accuracy = 0.101		average validation NDCG = 0.685

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.023634    	average train batch reward = 0.631
validation accuracy = 0.069		average validation NDCG = 0.660

epoch 2
average train loss = 0.006335    	average train batch reward = 0.633
validation accuracy = 0.074		average validation NDCG = 0.663

epoch 3
average train loss = 0.003623    	average train batch reward = 0.639
validation accuracy = 0.076		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015931    	average train batch reward = 0.631
validation accuracy = 0.064		average validation NDCG = 0.665

epoch 2
average train loss = -0.004926    	average train batch reward = 0.633
validation accuracy = 0.065		average validation NDCG = 0.670

epoch 3
average train loss = -0.012204    	average train batch reward = 0.636
validation accuracy = 0.061		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004252    	average train batch reward = 0.640
validation accuracy = 0.103		average validation NDCG = 0.668

epoch 2
average train loss = 0.001885    	average train batch reward = 0.644
validation accuracy = 0.104		average validation NDCG = 0.671

epoch 3
average train loss = 0.009025    	average train batch reward = 0.648
validation accuracy = 0.109		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001114    	average train batch reward = 0.639
validation accuracy = 0.067		average validation NDCG = 0.668

epoch 2
average train loss = -0.016122    	average train batch reward = 0.643
validation accuracy = 0.065		average validation NDCG = 0.670

epoch 3
average train loss = -0.008993    	average train batch reward = 0.644
validation accuracy = 0.063		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.002983    	average train batch reward = 0.639
validation accuracy = 0.093		average validation NDCG = 0.665

epoch 2
average train loss = -0.002275    	average train batch reward = 0.639
validation accuracy = 0.093		average validation NDCG = 0.666

epoch 3
average train loss = -0.008357    	average train batch reward = 0.641
validation accuracy = 0.090		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0), (9.9999999999999995e-07, 0.1, 0.0)], which got scores of [0.712815461926533, 0.70576083800308476, 0.6982159112930566]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.027993    	average train batch reward = 0.650
validation accuracy = 0.081		average validation NDCG = 0.707

epoch 2
average train loss = 0.005898    	average train batch reward = 0.651
validation accuracy = 0.082		average validation NDCG = 0.708

epoch 3
average train loss = 0.010538    	average train batch reward = 0.651
validation accuracy = 0.082		average validation NDCG = 0.713

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.75, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.712815461926533, 0.71270691539184461, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.017661    	average train batch reward = 0.648
validation accuracy = 0.115		average validation NDCG = 0.693

epoch 2
average train loss = -0.011301    	average train batch reward = 0.647
validation accuracy = 0.117		average validation NDCG = 0.696

epoch 3
average train loss = -0.019483    	average train batch reward = 0.647
validation accuracy = 0.118		average validation NDCG = 0.697

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.75, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.712815461926533, 0.71270691539184461, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.012229    	average train batch reward = 0.644
validation accuracy = 0.137		average validation NDCG = 0.681

epoch 2
average train loss = -0.022459    	average train batch reward = 0.645
validation accuracy = 0.137		average validation NDCG = 0.682

epoch 3
average train loss = 0.006015    	average train batch reward = 0.647
validation accuracy = 0.142		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.75, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.712815461926533, 0.71270691539184461, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.009172    	average train batch reward = 0.641
validation accuracy = 0.107		average validation NDCG = 0.668

epoch 2
average train loss = 0.015770    	average train batch reward = 0.646
validation accuracy = 0.112		average validation NDCG = 0.672

epoch 3
average train loss = 0.015401    	average train batch reward = 0.646
validation accuracy = 0.111		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.75, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.712815461926533, 0.71270691539184461, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000782    	average train batch reward = 0.678
validation accuracy = 0.112		average validation NDCG = 0.729

epoch 2
average train loss = -0.002138    	average train batch reward = 0.702
validation accuracy = 0.083		average validation NDCG = 0.768

epoch 3
average train loss = -0.010329    	average train batch reward = 0.726
validation accuracy = 0.048		average validation NDCG = 0.773

========
Currently the best setups are [(0.0001, 0.1, 0.0), (9.9999999999999995e-07, 0.25, 0.2), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.77329882894059909, 0.712815461926533, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000197    	average train batch reward = 0.720
validation accuracy = 0.172		average validation NDCG = 0.800

epoch 2
average train loss = 0.002078    	average train batch reward = 0.769
validation accuracy = 0.142		average validation NDCG = 0.835

epoch 3
average train loss = -0.002831    	average train batch reward = 0.782
validation accuracy = 0.137		average validation NDCG = 0.854

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.0), (1.0000000000000001e-05, 0.25, 1.0)], which got scores of [0.85350300897460818, 0.77329882894059909, 0.70576083800308476]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004376    	average train batch reward = 0.679
validation accuracy = 0.139		average validation NDCG = 0.723

epoch 2
average train loss = 0.003698    	average train batch reward = 0.727
validation accuracy = 0.138		average validation NDCG = 0.768

epoch 3
average train loss = -0.002517    	average train batch reward = 0.737
validation accuracy = 0.118		average validation NDCG = 0.780

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 0.5), (0.0001, 0.1, 0.0)], which got scores of [0.85350300897460818, 0.78012350072232217, 0.77329882894059909]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008924    	average train batch reward = 0.669
validation accuracy = 0.152		average validation NDCG = 0.727

epoch 2
average train loss = 0.008350    	average train batch reward = 0.708
validation accuracy = 0.120		average validation NDCG = 0.769

epoch 3
average train loss = 0.003962    	average train batch reward = 0.735
validation accuracy = 0.106		average validation NDCG = 0.812

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 1.0), (0.0001, 0.1, 0.5)], which got scores of [0.85350300897460818, 0.81164607522225096, 0.78012350072232217]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006177    	average train batch reward = 0.681
validation accuracy = 0.149		average validation NDCG = 0.741

epoch 2
average train loss = 0.010680    	average train batch reward = 0.736
validation accuracy = 0.234		average validation NDCG = 0.792

epoch 3
average train loss = 0.011143    	average train batch reward = 0.762
validation accuracy = 0.184		average validation NDCG = 0.814

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 1.5), (0.0001, 0.1, 1.0)], which got scores of [0.85350300897460818, 0.81391615281314267, 0.81164607522225096]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006083    	average train batch reward = 0.656
validation accuracy = 0.133		average validation NDCG = 0.714

epoch 2
average train loss = 0.005236    	average train batch reward = 0.691
validation accuracy = 0.132		average validation NDCG = 0.754

epoch 3
average train loss = -0.001431    	average train batch reward = 0.716
validation accuracy = 0.081		average validation NDCG = 0.788

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 1.5), (0.0001, 0.1, 1.0)], which got scores of [0.85350300897460818, 0.81391615281314267, 0.81164607522225096]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008398    	average train batch reward = 0.678
validation accuracy = 0.187		average validation NDCG = 0.739

epoch 2
average train loss = 0.011132    	average train batch reward = 0.713
validation accuracy = 0.167		average validation NDCG = 0.779

epoch 3
average train loss = 0.018061    	average train batch reward = 0.733
validation accuracy = 0.210		average validation NDCG = 0.800

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 1.5), (0.0001, 0.1, 1.0)], which got scores of [0.85350300897460818, 0.81391615281314267, 0.81164607522225096]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000155    	average train batch reward = 0.638
validation accuracy = 0.097		average validation NDCG = 0.685

epoch 2
average train loss = 0.005113    	average train batch reward = 0.665
validation accuracy = 0.095		average validation NDCG = 0.721

epoch 3
average train loss = 0.007480    	average train batch reward = 0.696
validation accuracy = 0.098		average validation NDCG = 0.755

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.1, 1.5), (0.0001, 0.1, 1.0)], which got scores of [0.85350300897460818, 0.81391615281314267, 0.81164607522225096]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015175    	average train batch reward = 0.675
validation accuracy = 0.113		average validation NDCG = 0.738

epoch 2
average train loss = 0.018459    	average train batch reward = 0.714
validation accuracy = 0.139		average validation NDCG = 0.789

epoch 3
average train loss = 0.017587    	average train batch reward = 0.740
validation accuracy = 0.175		average validation NDCG = 0.814

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001857    	average train batch reward = 0.696
validation accuracy = 0.105		average validation NDCG = 0.752

epoch 2
average train loss = 0.008231    	average train batch reward = 0.712
validation accuracy = 0.104		average validation NDCG = 0.765

epoch 3
average train loss = 0.005594    	average train batch reward = 0.722
validation accuracy = 0.106		average validation NDCG = 0.788

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005689    	average train batch reward = 0.633
validation accuracy = 0.117		average validation NDCG = 0.678

epoch 2
average train loss = -0.000308    	average train batch reward = 0.656
validation accuracy = 0.140		average validation NDCG = 0.696

epoch 3
average train loss = 0.019870    	average train batch reward = 0.664
validation accuracy = 0.119		average validation NDCG = 0.710

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010764    	average train batch reward = 0.666
validation accuracy = 0.141		average validation NDCG = 0.751

epoch 2
average train loss = 0.013451    	average train batch reward = 0.687
validation accuracy = 0.149		average validation NDCG = 0.797

epoch 3
average train loss = 0.015708    	average train batch reward = 0.696
validation accuracy = 0.141		average validation NDCG = 0.806

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011176    	average train batch reward = 0.643
validation accuracy = 0.079		average validation NDCG = 0.689

epoch 2
average train loss = 0.001363    	average train batch reward = 0.659
validation accuracy = 0.112		average validation NDCG = 0.724

epoch 3
average train loss = 0.008893    	average train batch reward = 0.670
validation accuracy = 0.105		average validation NDCG = 0.744

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001179    	average train batch reward = 0.649
validation accuracy = 0.153		average validation NDCG = 0.700

epoch 2
average train loss = 0.008425    	average train batch reward = 0.668
validation accuracy = 0.177		average validation NDCG = 0.733

epoch 3
average train loss = 0.009737    	average train batch reward = 0.671
validation accuracy = 0.149		average validation NDCG = 0.733

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004312    	average train batch reward = 0.641
validation accuracy = 0.088		average validation NDCG = 0.680

epoch 2
average train loss = -0.001710    	average train batch reward = 0.648
validation accuracy = 0.090		average validation NDCG = 0.690

epoch 3
average train loss = 0.007093    	average train batch reward = 0.660
validation accuracy = 0.118		average validation NDCG = 0.722

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.007420    	average train batch reward = 0.638
validation accuracy = 0.091		average validation NDCG = 0.666

epoch 2
average train loss = 0.013571    	average train batch reward = 0.644
validation accuracy = 0.077		average validation NDCG = 0.682

epoch 3
average train loss = 0.021538    	average train batch reward = 0.645
validation accuracy = 0.065		average validation NDCG = 0.703

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.028689    	average train batch reward = 0.653
validation accuracy = 0.158		average validation NDCG = 0.714

epoch 2
average train loss = 0.044120    	average train batch reward = 0.658
validation accuracy = 0.123		average validation NDCG = 0.734

epoch 3
average train loss = 0.001786    	average train batch reward = 0.660
validation accuracy = 0.151		average validation NDCG = 0.737

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014881    	average train batch reward = 0.644
validation accuracy = 0.140		average validation NDCG = 0.700

epoch 2
average train loss = 0.040213    	average train batch reward = 0.651
validation accuracy = 0.140		average validation NDCG = 0.715

epoch 3
average train loss = 0.015808    	average train batch reward = 0.657
validation accuracy = 0.169		average validation NDCG = 0.739

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.004939    	average train batch reward = 0.646
validation accuracy = 0.195		average validation NDCG = 0.708

epoch 2
average train loss = 0.066561    	average train batch reward = 0.655
validation accuracy = 0.189		average validation NDCG = 0.739

epoch 3
average train loss = 0.045481    	average train batch reward = 0.663
validation accuracy = 0.224		average validation NDCG = 0.773

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.004216    	average train batch reward = 0.651
validation accuracy = 0.166		average validation NDCG = 0.722

epoch 2
average train loss = 0.037983    	average train batch reward = 0.656
validation accuracy = 0.188		average validation NDCG = 0.740

epoch 3
average train loss = 0.052763    	average train batch reward = 0.660
validation accuracy = 0.175		average validation NDCG = 0.764

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.014953    	average train batch reward = 0.657
validation accuracy = 0.091		average validation NDCG = 0.728

epoch 2
average train loss = 0.006826    	average train batch reward = 0.680
validation accuracy = 0.104		average validation NDCG = 0.717

epoch 3
average train loss = -0.013841    	average train batch reward = 0.652
validation accuracy = 0.035		average validation NDCG = 0.695

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.003470    	average train batch reward = 0.662
validation accuracy = 0.051		average validation NDCG = 0.711

epoch 2
average train loss = -0.017437    	average train batch reward = 0.651
validation accuracy = 0.121		average validation NDCG = 0.674

epoch 3
average train loss = -0.006353    	average train batch reward = 0.639
validation accuracy = 0.065		average validation NDCG = 0.675

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012494    	average train batch reward = 0.666
validation accuracy = 0.026		average validation NDCG = 0.712

epoch 2
average train loss = -0.010839    	average train batch reward = 0.652
validation accuracy = 0.032		average validation NDCG = 0.686

epoch 3
average train loss = -0.013285    	average train batch reward = 0.643
validation accuracy = 0.048		average validation NDCG = 0.683

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009927    	average train batch reward = 0.659
validation accuracy = 0.022		average validation NDCG = 0.689

epoch 2
average train loss = -0.029238    	average train batch reward = 0.629
validation accuracy = 0.039		average validation NDCG = 0.684

epoch 3
average train loss = -0.015466    	average train batch reward = 0.634
validation accuracy = 0.004		average validation NDCG = 0.674

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005641    	average train batch reward = 0.669
validation accuracy = 0.077		average validation NDCG = 0.737

epoch 2
average train loss = -0.002955    	average train batch reward = 0.690
validation accuracy = 0.208		average validation NDCG = 0.731

epoch 3
average train loss = 0.016300    	average train batch reward = 0.675
validation accuracy = 0.114		average validation NDCG = 0.711

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015314    	average train batch reward = 0.670
validation accuracy = 0.106		average validation NDCG = 0.698

epoch 2
average train loss = -0.016013    	average train batch reward = 0.655
validation accuracy = 0.069		average validation NDCG = 0.686

epoch 3
average train loss = -0.023656    	average train batch reward = 0.648
validation accuracy = 0.056		average validation NDCG = 0.701

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001229    	average train batch reward = 0.668
validation accuracy = 0.098		average validation NDCG = 0.710

epoch 2
average train loss = -0.004825    	average train batch reward = 0.664
validation accuracy = 0.049		average validation NDCG = 0.689

epoch 3
average train loss = 0.003324    	average train batch reward = 0.655
validation accuracy = 0.043		average validation NDCG = 0.709

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.001007    	average train batch reward = 0.670
validation accuracy = 0.061		average validation NDCG = 0.732

epoch 2
average train loss = 0.003189    	average train batch reward = 0.673
validation accuracy = 0.029		average validation NDCG = 0.719

epoch 3
average train loss = -0.009737    	average train batch reward = 0.670
validation accuracy = 0.014		average validation NDCG = 0.718

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000064    	average train batch reward = 0.676
validation accuracy = 0.014		average validation NDCG = 0.731

epoch 2
average train loss = -0.007289    	average train batch reward = 0.680
validation accuracy = 0.006		average validation NDCG = 0.720

epoch 3
average train loss = -0.004797    	average train batch reward = 0.665
validation accuracy = 0.038		average validation NDCG = 0.700

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002655    	average train batch reward = 0.649
validation accuracy = 0.048		average validation NDCG = 0.689

epoch 2
average train loss = -0.006317    	average train batch reward = 0.646
validation accuracy = 0.044		average validation NDCG = 0.693

epoch 3
average train loss = -0.008120    	average train batch reward = 0.644
validation accuracy = 0.077		average validation NDCG = 0.684

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013139    	average train batch reward = 0.653
validation accuracy = 0.115		average validation NDCG = 0.697

epoch 2
average train loss = 0.015945    	average train batch reward = 0.647
validation accuracy = 0.096		average validation NDCG = 0.678

epoch 3
average train loss = -0.008137    	average train batch reward = 0.652
validation accuracy = 0.195		average validation NDCG = 0.701

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.030211    	average train batch reward = 0.657
validation accuracy = 0.135		average validation NDCG = 0.703

epoch 2
average train loss = 0.017011    	average train batch reward = 0.659
validation accuracy = 0.116		average validation NDCG = 0.690

epoch 3
average train loss = 0.008361    	average train batch reward = 0.650
validation accuracy = 0.104		average validation NDCG = 0.694

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.033192    	average train batch reward = 0.649
validation accuracy = 0.023		average validation NDCG = 0.704

epoch 2
average train loss = -0.013722    	average train batch reward = 0.654
validation accuracy = 0.036		average validation NDCG = 0.708

epoch 3
average train loss = -0.046101    	average train batch reward = 0.648
validation accuracy = 0.038		average validation NDCG = 0.680

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022904    	average train batch reward = 0.657
validation accuracy = 0.130		average validation NDCG = 0.702

epoch 2
average train loss = 0.021453    	average train batch reward = 0.651
validation accuracy = 0.162		average validation NDCG = 0.694

epoch 3
average train loss = -0.001881    	average train batch reward = 0.648
validation accuracy = 0.098		average validation NDCG = 0.676

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007684    	average train batch reward = 0.645
validation accuracy = 0.073		average validation NDCG = 0.690

epoch 2
average train loss = 0.006175    	average train batch reward = 0.647
validation accuracy = 0.090		average validation NDCG = 0.678

epoch 3
average train loss = 0.006498    	average train batch reward = 0.649
validation accuracy = 0.097		average validation NDCG = 0.691

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036688    	average train batch reward = 0.654
validation accuracy = 0.119		average validation NDCG = 0.739

epoch 2
average train loss = 0.063119    	average train batch reward = 0.653
validation accuracy = 0.080		average validation NDCG = 0.719

epoch 3
average train loss = 0.012882    	average train batch reward = 0.647
validation accuracy = 0.075		average validation NDCG = 0.685

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.033913    	average train batch reward = 0.652
validation accuracy = 0.212		average validation NDCG = 0.727

epoch 2
average train loss = 0.015040    	average train batch reward = 0.652
validation accuracy = 0.183		average validation NDCG = 0.706

epoch 3
average train loss = -0.016329    	average train batch reward = 0.648
validation accuracy = 0.169		average validation NDCG = 0.711

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001256    	average train batch reward = 0.647
validation accuracy = 0.093		average validation NDCG = 0.682

epoch 2
average train loss = 0.069236    	average train batch reward = 0.647
validation accuracy = 0.111		average validation NDCG = 0.707

epoch 3
average train loss = -0.002625    	average train batch reward = 0.647
validation accuracy = 0.104		average validation NDCG = 0.704

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.051793    	average train batch reward = 0.643
validation accuracy = 0.083		average validation NDCG = 0.681

epoch 2
average train loss = -0.012519    	average train batch reward = 0.642
validation accuracy = 0.037		average validation NDCG = 0.674

epoch 3
average train loss = -0.094085    	average train batch reward = 0.642
validation accuracy = 0.025		average validation NDCG = 0.685

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.019717    	average train batch reward = 0.651
validation accuracy = 0.210		average validation NDCG = 0.727

epoch 2
average train loss = 0.007832    	average train batch reward = 0.649
validation accuracy = 0.081		average validation NDCG = 0.715

epoch 3
average train loss = -0.064874    	average train batch reward = 0.644
validation accuracy = 0.098		average validation NDCG = 0.688

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.021908    	average train batch reward = 0.663
validation accuracy = 0.143		average validation NDCG = 0.701

epoch 2
average train loss = 0.064506    	average train batch reward = 0.663
validation accuracy = 0.118		average validation NDCG = 0.698

epoch 3
average train loss = 0.056473    	average train batch reward = 0.655
validation accuracy = 0.112		average validation NDCG = 0.696

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.031878    	average train batch reward = 0.634
validation accuracy = 0.041		average validation NDCG = 0.652

epoch 2
average train loss = 0.032229    	average train batch reward = 0.623
validation accuracy = 0.096		average validation NDCG = 0.663

epoch 3
average train loss = -0.027852    	average train batch reward = 0.618
validation accuracy = 0.120		average validation NDCG = 0.652

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.013905    	average train batch reward = 0.657
validation accuracy = 0.120		average validation NDCG = 0.695

epoch 2
average train loss = -0.064150    	average train batch reward = 0.662
validation accuracy = 0.195		average validation NDCG = 0.699

epoch 3
average train loss = -0.109603    	average train batch reward = 0.673
validation accuracy = 0.113		average validation NDCG = 0.696

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.029135    	average train batch reward = 0.643
validation accuracy = 0.101		average validation NDCG = 0.678

epoch 2
average train loss = -0.013631    	average train batch reward = 0.631
validation accuracy = 0.075		average validation NDCG = 0.675

epoch 3
average train loss = -0.050754    	average train batch reward = 0.635
validation accuracy = 0.049		average validation NDCG = 0.673

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009522    	average train batch reward = 0.642
validation accuracy = 0.103		average validation NDCG = 0.656

epoch 2
average train loss = -0.018907    	average train batch reward = 0.623
validation accuracy = 0.040		average validation NDCG = 0.651

epoch 3
average train loss = -0.027758    	average train batch reward = 0.625
validation accuracy = 0.053		average validation NDCG = 0.664

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022214    	average train batch reward = 0.638
validation accuracy = 0.107		average validation NDCG = 0.653

epoch 2
average train loss = -0.007020    	average train batch reward = 0.627
validation accuracy = 0.105		average validation NDCG = 0.660

epoch 3
average train loss = -0.021997    	average train batch reward = 0.625
validation accuracy = 0.104		average validation NDCG = 0.655

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.029922    	average train batch reward = 0.646
validation accuracy = 0.055		average validation NDCG = 0.668

epoch 2
average train loss = -0.049671    	average train batch reward = 0.635
validation accuracy = 0.066		average validation NDCG = 0.666

epoch 3
average train loss = -0.037029    	average train batch reward = 0.639
validation accuracy = 0.037		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.007297    	average train batch reward = 0.629
validation accuracy = 0.043		average validation NDCG = 0.662

epoch 2
average train loss = -0.000701    	average train batch reward = 0.639
validation accuracy = 0.065		average validation NDCG = 0.666

epoch 3
average train loss = 0.002751    	average train batch reward = 0.633
validation accuracy = 0.113		average validation NDCG = 0.664

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.028826    	average train batch reward = 0.645
validation accuracy = 0.157		average validation NDCG = 0.669

epoch 2
average train loss = 0.010933    	average train batch reward = 0.643
validation accuracy = 0.130		average validation NDCG = 0.674

epoch 3
average train loss = 0.005697    	average train batch reward = 0.643
validation accuracy = 0.128		average validation NDCG = 0.681

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000918    	average train batch reward = 0.628
validation accuracy = 0.088		average validation NDCG = 0.653

epoch 2
average train loss = -0.032365    	average train batch reward = 0.629
validation accuracy = 0.108		average validation NDCG = 0.668

epoch 3
average train loss = 0.022870    	average train batch reward = 0.628
validation accuracy = 0.106		average validation NDCG = 0.650

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.034807    	average train batch reward = 0.646
validation accuracy = 0.064		average validation NDCG = 0.692

epoch 2
average train loss = -0.015143    	average train batch reward = 0.647
validation accuracy = 0.089		average validation NDCG = 0.683

epoch 3
average train loss = 0.003591    	average train batch reward = 0.645
validation accuracy = 0.070		average validation NDCG = 0.685

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005386    	average train batch reward = 0.644
validation accuracy = 0.119		average validation NDCG = 0.692

epoch 2
average train loss = 0.027596    	average train batch reward = 0.639
validation accuracy = 0.092		average validation NDCG = 0.664

epoch 3
average train loss = 0.012281    	average train batch reward = 0.641
validation accuracy = 0.101		average validation NDCG = 0.676

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017784    	average train batch reward = 0.640
validation accuracy = 0.099		average validation NDCG = 0.660

epoch 2
average train loss = -0.095664    	average train batch reward = 0.632
validation accuracy = 0.078		average validation NDCG = 0.656

epoch 3
average train loss = 0.156129    	average train batch reward = 0.630
validation accuracy = 0.079		average validation NDCG = 0.660

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.027560    	average train batch reward = 0.658
validation accuracy = 0.128		average validation NDCG = 0.695

epoch 2
average train loss = 0.033045    	average train batch reward = 0.647
validation accuracy = 0.092		average validation NDCG = 0.676

epoch 3
average train loss = -0.019049    	average train batch reward = 0.643
validation accuracy = 0.086		average validation NDCG = 0.683

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009096    	average train batch reward = 0.644
validation accuracy = 0.109		average validation NDCG = 0.694

epoch 2
average train loss = -0.027457    	average train batch reward = 0.651
validation accuracy = 0.101		average validation NDCG = 0.694

epoch 3
average train loss = 0.106818    	average train batch reward = 0.647
validation accuracy = 0.062		average validation NDCG = 0.688

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.021092    	average train batch reward = 0.649
validation accuracy = 0.116		average validation NDCG = 0.721

epoch 2
average train loss = 0.230077    	average train batch reward = 0.652
validation accuracy = 0.049		average validation NDCG = 0.707

epoch 3
average train loss = 0.081629    	average train batch reward = 0.648
validation accuracy = 0.105		average validation NDCG = 0.698

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.043152    	average train batch reward = 0.643
validation accuracy = 0.099		average validation NDCG = 0.659

epoch 2
average train loss = 0.054168    	average train batch reward = 0.638
validation accuracy = 0.062		average validation NDCG = 0.644

epoch 3
average train loss = -0.018112    	average train batch reward = 0.636
validation accuracy = 0.059		average validation NDCG = 0.653

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.008116    	average train batch reward = 0.644
validation accuracy = 0.070		average validation NDCG = 0.677

epoch 2
average train loss = 0.048440    	average train batch reward = 0.646
validation accuracy = 0.096		average validation NDCG = 0.693

epoch 3
average train loss = 0.311968    	average train batch reward = 0.648
validation accuracy = 0.086		average validation NDCG = 0.694

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.081894    	average train batch reward = 0.646
validation accuracy = 0.138		average validation NDCG = 0.715

epoch 2
average train loss = -0.095454    	average train batch reward = 0.648
validation accuracy = 0.101		average validation NDCG = 0.684

epoch 3
average train loss = -0.382447    	average train batch reward = 0.644
validation accuracy = 0.099		average validation NDCG = 0.682

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015500    	average train batch reward = 0.637
validation accuracy = 0.035		average validation NDCG = 0.671

epoch 2
average train loss = -0.011228    	average train batch reward = 0.642
validation accuracy = 0.035		average validation NDCG = 0.673

epoch 3
average train loss = 0.089618    	average train batch reward = 0.640
validation accuracy = 0.100		average validation NDCG = 0.662

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.030101    	average train batch reward = 0.649
validation accuracy = 0.113		average validation NDCG = 0.682

epoch 2
average train loss = 0.320869    	average train batch reward = 0.653
validation accuracy = 0.113		average validation NDCG = 0.693

epoch 3
average train loss = 0.020506    	average train batch reward = 0.652
validation accuracy = 0.123		average validation NDCG = 0.687

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.060719    	average train batch reward = 0.647
validation accuracy = 0.122		average validation NDCG = 0.674

epoch 2
average train loss = 0.025467    	average train batch reward = 0.648
validation accuracy = 0.127		average validation NDCG = 0.679

epoch 3
average train loss = 0.001088    	average train batch reward = 0.648
validation accuracy = 0.118		average validation NDCG = 0.676

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.245875    	average train batch reward = 0.643
validation accuracy = 0.099		average validation NDCG = 0.685

epoch 2
average train loss = -0.001747    	average train batch reward = 0.654
validation accuracy = 0.099		average validation NDCG = 0.686

epoch 3
average train loss = 0.000156    	average train batch reward = 0.655
validation accuracy = 0.099		average validation NDCG = 0.689

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.083494    	average train batch reward = 0.647
validation accuracy = 0.099		average validation NDCG = 0.684

epoch 2
average train loss = -0.317125    	average train batch reward = 0.655
validation accuracy = 0.095		average validation NDCG = 0.683

epoch 3
average train loss = -0.235561    	average train batch reward = 0.657
validation accuracy = 0.098		average validation NDCG = 0.686

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.100000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.063299    	average train batch reward = 0.634
validation accuracy = 0.082		average validation NDCG = 0.673

epoch 2
average train loss = -0.000162    	average train batch reward = 0.642
validation accuracy = 0.087		average validation NDCG = 0.672

epoch 3
average train loss = 0.000000    	average train batch reward = 0.639
validation accuracy = 0.087		average validation NDCG = 0.672

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.039710    	average train batch reward = 0.641
validation accuracy = 0.099		average validation NDCG = 0.671

epoch 2
average train loss = -0.000007    	average train batch reward = 0.640
validation accuracy = 0.100		average validation NDCG = 0.672

epoch 3
average train loss = -0.159967    	average train batch reward = 0.641
validation accuracy = 0.106		average validation NDCG = 0.667

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.027342    	average train batch reward = 0.644
validation accuracy = 0.100		average validation NDCG = 0.674

epoch 2
average train loss = 0.000001    	average train batch reward = 0.641
validation accuracy = 0.100		average validation NDCG = 0.673

epoch 3
average train loss = 0.000002    	average train batch reward = 0.644
validation accuracy = 0.100		average validation NDCG = 0.673

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.161017    	average train batch reward = 0.654
validation accuracy = 0.108		average validation NDCG = 0.714

epoch 2
average train loss = 0.021762    	average train batch reward = 0.654
validation accuracy = 0.096		average validation NDCG = 0.686

epoch 3
average train loss = -0.001498    	average train batch reward = 0.655
validation accuracy = 0.096		average validation NDCG = 0.682

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.146074    	average train batch reward = 0.656
validation accuracy = 0.120		average validation NDCG = 0.686

epoch 2
average train loss = -9.897995    	average train batch reward = 0.643
validation accuracy = 0.088		average validation NDCG = 0.676

epoch 3
average train loss = -0.000001    	average train batch reward = 0.647
validation accuracy = 0.096		average validation NDCG = 0.678

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.250000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009428    	average train batch reward = 0.660
validation accuracy = 0.094		average validation NDCG = 0.670

epoch 2
average train loss = 0.090138    	average train batch reward = 0.642
validation accuracy = 0.026		average validation NDCG = 0.671

epoch 3
average train loss = -0.000000    	average train batch reward = 0.639
validation accuracy = 0.029		average validation NDCG = 0.671

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.733237    	average train batch reward = 0.656
validation accuracy = 0.087		average validation NDCG = 0.705

epoch 2
average train loss = 0.029621    	average train batch reward = 0.660
validation accuracy = 0.107		average validation NDCG = 0.696

epoch 3
average train loss = 0.030402    	average train batch reward = 0.654
validation accuracy = 0.108		average validation NDCG = 0.699

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.324862    	average train batch reward = 0.632
validation accuracy = 0.150		average validation NDCG = 0.653

epoch 2
average train loss = -0.017911    	average train batch reward = 0.629
validation accuracy = 0.148		average validation NDCG = 0.652

epoch 3
average train loss = -0.000272    	average train batch reward = 0.629
validation accuracy = 0.198		average validation NDCG = 0.654

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.068197    	average train batch reward = 0.644
validation accuracy = 0.099		average validation NDCG = 0.676

epoch 2
average train loss = 0.838006    	average train batch reward = 0.645
validation accuracy = 0.062		average validation NDCG = 0.676

epoch 3
average train loss = 0.286693    	average train batch reward = 0.637
validation accuracy = 0.052		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.529639    	average train batch reward = 0.642
validation accuracy = 0.087		average validation NDCG = 0.675

epoch 2
average train loss = -0.000002    	average train batch reward = 0.641
validation accuracy = 0.087		average validation NDCG = 0.675

epoch 3
average train loss = 0.207529    	average train batch reward = 0.642
validation accuracy = 0.098		average validation NDCG = 0.681

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.500000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.044322    	average train batch reward = 0.649
validation accuracy = 0.103		average validation NDCG = 0.691

epoch 2
average train loss = -0.018343    	average train batch reward = 0.651
validation accuracy = 0.065		average validation NDCG = 0.687

epoch 3
average train loss = -0.000000    	average train batch reward = 0.646
validation accuracy = 0.065		average validation NDCG = 0.688

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.353395    	average train batch reward = 0.647
validation accuracy = 0.089		average validation NDCG = 0.692

epoch 2
average train loss = 0.429677    	average train batch reward = 0.642
validation accuracy = 0.093		average validation NDCG = 0.665

epoch 3
average train loss = -0.075380    	average train batch reward = 0.639
validation accuracy = 0.088		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011081    	average train batch reward = 0.644
validation accuracy = 0.100		average validation NDCG = 0.690

epoch 2
average train loss = 0.568147    	average train batch reward = 0.643
validation accuracy = 0.100		average validation NDCG = 0.670

epoch 3
average train loss = -0.000011    	average train batch reward = 0.641
validation accuracy = 0.100		average validation NDCG = 0.669

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.187248    	average train batch reward = 0.641
validation accuracy = 0.099		average validation NDCG = 0.672

epoch 2
average train loss = -0.289082    	average train batch reward = 0.643
validation accuracy = 0.110		average validation NDCG = 0.675

epoch 3
average train loss = 0.000000    	average train batch reward = 0.642
validation accuracy = 0.110		average validation NDCG = 0.675

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 2.332607    	average train batch reward = 0.646
validation accuracy = 0.107		average validation NDCG = 0.688

epoch 2
average train loss = 0.000009    	average train batch reward = 0.647
validation accuracy = 0.107		average validation NDCG = 0.697

epoch 3
average train loss = 0.029657    	average train batch reward = 0.646
validation accuracy = 0.099		average validation NDCG = 0.694

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.750000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b4b8191a320>
Reward function = <function ndcg_full at 0x2b4b8191a398>
Greedy action = <function sample at 0x2b4b7a71d9b0>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.426906    	average train batch reward = 0.640
validation accuracy = 0.113		average validation NDCG = 0.663

epoch 2
average train loss = -0.019908    	average train batch reward = 0.640
validation accuracy = 0.098		average validation NDCG = 0.664

epoch 3
average train loss = -0.000000    	average train batch reward = 0.640
validation accuracy = 0.098		average validation NDCG = 0.664

========
Currently the best setups are [(0.0001, 0.1, 0.2), (0.0001, 0.25, 1.0), (0.0001, 0.1, 1.5)], which got scores of [0.85350300897460818, 0.81446360112953486, 0.81391615281314267]
========
2017-07-03 10:31:38
