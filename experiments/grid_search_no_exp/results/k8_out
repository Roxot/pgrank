2017-06-30 08:50:34
Finding best parameters for k = 8
=========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.166111    	average train batch reward = 0.583
validation accuracy = 0.125		average validation NDCG = 0.683

epoch 2
average train loss = -0.117705    	average train batch reward = 0.586
validation accuracy = 0.126		average validation NDCG = 0.683

epoch 3
average train loss = -0.158139    	average train batch reward = 0.585
validation accuracy = 0.126		average validation NDCG = 0.683

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (), ()], which got scores of [0.68332767842217701, -1, -1]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.095533    	average train batch reward = 0.579
validation accuracy = 0.104		average validation NDCG = 0.672

epoch 2
average train loss = -0.046463    	average train batch reward = 0.581
validation accuracy = 0.105		average validation NDCG = 0.672

epoch 3
average train loss = -0.072200    	average train batch reward = 0.583
validation accuracy = 0.105		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.05), ()], which got scores of [0.68332767842217701, 0.67231155416100363, -1]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.049186    	average train batch reward = 0.573
validation accuracy = 0.117		average validation NDCG = 0.676

epoch 2
average train loss = 0.028797    	average train batch reward = 0.574
validation accuracy = 0.117		average validation NDCG = 0.676

epoch 3
average train loss = -0.004743    	average train batch reward = 0.574
validation accuracy = 0.118		average validation NDCG = 0.676

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.68332767842217701, 0.67623896930997185, 0.67231155416100363]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.051521    	average train batch reward = 0.529
validation accuracy = 0.091		average validation NDCG = 0.650

epoch 2
average train loss = 0.023418    	average train batch reward = 0.531
validation accuracy = 0.091		average validation NDCG = 0.650

epoch 3
average train loss = 0.063336    	average train batch reward = 0.530
validation accuracy = 0.091		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.68332767842217701, 0.67623896930997185, 0.67231155416100363]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.000135    	average train batch reward = 0.559
validation accuracy = 0.116		average validation NDCG = 0.670

epoch 2
average train loss = -0.052343    	average train batch reward = 0.561
validation accuracy = 0.117		average validation NDCG = 0.670

epoch 3
average train loss = -0.026534    	average train batch reward = 0.561
validation accuracy = 0.117		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.68332767842217701, 0.67623896930997185, 0.67231155416100363]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.083740    	average train batch reward = 0.592
validation accuracy = 0.118		average validation NDCG = 0.689

epoch 2
average train loss = -0.112720    	average train batch reward = 0.592
validation accuracy = 0.118		average validation NDCG = 0.690

epoch 3
average train loss = -0.204300    	average train batch reward = 0.592
validation accuracy = 0.118		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.69004622761634182, 0.68332767842217701, 0.67231155416100363]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.032721    	average train batch reward = 0.587
validation accuracy = 0.105		average validation NDCG = 0.684

epoch 2
average train loss = 0.010917    	average train batch reward = 0.587
validation accuracy = 0.105		average validation NDCG = 0.684

epoch 3
average train loss = -0.068596    	average train batch reward = 0.586
validation accuracy = 0.105		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69004622761634182, 0.68414387645469388, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.055537    	average train batch reward = 0.551
validation accuracy = 0.076		average validation NDCG = 0.666

epoch 2
average train loss = 0.050137    	average train batch reward = 0.552
validation accuracy = 0.076		average validation NDCG = 0.666

epoch 3
average train loss = 0.061915    	average train batch reward = 0.553
validation accuracy = 0.076		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69004622761634182, 0.68414387645469388, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.171277    	average train batch reward = 0.563
validation accuracy = 0.137		average validation NDCG = 0.672

epoch 2
average train loss = -0.053797    	average train batch reward = 0.564
validation accuracy = 0.137		average validation NDCG = 0.672

epoch 3
average train loss = 0.007834    	average train batch reward = 0.564
validation accuracy = 0.137		average validation NDCG = 0.672

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69004622761634182, 0.68414387645469388, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.087324    	average train batch reward = 0.552
validation accuracy = 0.107		average validation NDCG = 0.657

epoch 2
average train loss = -0.074953    	average train batch reward = 0.553
validation accuracy = 0.107		average validation NDCG = 0.657

epoch 3
average train loss = 0.013776    	average train batch reward = 0.555
validation accuracy = 0.107		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69004622761634182, 0.68414387645469388, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.155105    	average train batch reward = 0.595
validation accuracy = 0.123		average validation NDCG = 0.691

epoch 2
average train loss = -0.100794    	average train batch reward = 0.595
validation accuracy = 0.123		average validation NDCG = 0.691

epoch 3
average train loss = -0.119893    	average train batch reward = 0.597
validation accuracy = 0.123		average validation NDCG = 0.691

========
Currently the best setups are [(9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69148462060924987, 0.69004622761634182, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.051251    	average train batch reward = 0.559
validation accuracy = 0.057		average validation NDCG = 0.674

epoch 2
average train loss = 0.157320    	average train batch reward = 0.559
validation accuracy = 0.058		average validation NDCG = 0.674

epoch 3
average train loss = 0.175138    	average train batch reward = 0.561
validation accuracy = 0.058		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69148462060924987, 0.69004622761634182, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.037431    	average train batch reward = 0.578
validation accuracy = 0.097		average validation NDCG = 0.673

epoch 2
average train loss = 0.127901    	average train batch reward = 0.579
validation accuracy = 0.097		average validation NDCG = 0.673

epoch 3
average train loss = 0.115604    	average train batch reward = 0.578
validation accuracy = 0.097		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69148462060924987, 0.69004622761634182, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.046954    	average train batch reward = 0.550
validation accuracy = 0.081		average validation NDCG = 0.658

epoch 2
average train loss = -0.048729    	average train batch reward = 0.552
validation accuracy = 0.081		average validation NDCG = 0.658

epoch 3
average train loss = 0.106944    	average train batch reward = 0.551
validation accuracy = 0.081		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69148462060924987, 0.69004622761634182, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.012559    	average train batch reward = 0.571
validation accuracy = 0.093		average validation NDCG = 0.681

epoch 2
average train loss = 0.044872    	average train batch reward = 0.570
validation accuracy = 0.093		average validation NDCG = 0.681

epoch 3
average train loss = -0.006488    	average train batch reward = 0.571
validation accuracy = 0.093		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69148462060924987, 0.69004622761634182, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.075823    	average train batch reward = 0.611
validation accuracy = 0.129		average validation NDCG = 0.692

epoch 2
average train loss = -0.052026    	average train batch reward = 0.609
validation accuracy = 0.129		average validation NDCG = 0.692

epoch 3
average train loss = 0.043593    	average train batch reward = 0.611
validation accuracy = 0.129		average validation NDCG = 0.692

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.074119    	average train batch reward = 0.579
validation accuracy = 0.113		average validation NDCG = 0.674

epoch 2
average train loss = 0.069593    	average train batch reward = 0.580
validation accuracy = 0.113		average validation NDCG = 0.674

epoch 3
average train loss = 0.004538    	average train batch reward = 0.581
validation accuracy = 0.113		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.68332767842217701]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.008764    	average train batch reward = 0.580
validation accuracy = 0.100		average validation NDCG = 0.691

epoch 2
average train loss = 0.025250    	average train batch reward = 0.580
validation accuracy = 0.100		average validation NDCG = 0.691

epoch 3
average train loss = -0.016213    	average train batch reward = 0.581
validation accuracy = 0.100		average validation NDCG = 0.691

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.061263    	average train batch reward = 0.556
validation accuracy = 0.112		average validation NDCG = 0.659

epoch 2
average train loss = -0.075839    	average train batch reward = 0.562
validation accuracy = 0.115		average validation NDCG = 0.662

epoch 3
average train loss = 0.000670    	average train batch reward = 0.568
validation accuracy = 0.122		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.039525    	average train batch reward = 0.549
validation accuracy = 0.077		average validation NDCG = 0.664

epoch 2
average train loss = -0.011112    	average train batch reward = 0.553
validation accuracy = 0.080		average validation NDCG = 0.667

epoch 3
average train loss = -0.053168    	average train batch reward = 0.555
validation accuracy = 0.081		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.099322    	average train batch reward = 0.567
validation accuracy = 0.087		average validation NDCG = 0.669

epoch 2
average train loss = -0.081046    	average train batch reward = 0.569
validation accuracy = 0.087		average validation NDCG = 0.672

epoch 3
average train loss = -0.020715    	average train batch reward = 0.574
validation accuracy = 0.088		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.044992    	average train batch reward = 0.570
validation accuracy = 0.058		average validation NDCG = 0.679

epoch 2
average train loss = 0.018305    	average train batch reward = 0.574
validation accuracy = 0.062		average validation NDCG = 0.683

epoch 3
average train loss = -0.018614    	average train batch reward = 0.578
validation accuracy = 0.075		average validation NDCG = 0.687

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.079711    	average train batch reward = 0.579
validation accuracy = 0.144		average validation NDCG = 0.682

epoch 2
average train loss = -0.033321    	average train batch reward = 0.582
validation accuracy = 0.147		average validation NDCG = 0.684

epoch 3
average train loss = -0.116074    	average train batch reward = 0.586
validation accuracy = 0.152		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.033427    	average train batch reward = 0.542
validation accuracy = 0.085		average validation NDCG = 0.656

epoch 2
average train loss = -0.059662    	average train batch reward = 0.548
validation accuracy = 0.085		average validation NDCG = 0.658

epoch 3
average train loss = 0.004695    	average train batch reward = 0.549
validation accuracy = 0.086		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010132    	average train batch reward = 0.543
validation accuracy = 0.109		average validation NDCG = 0.656

epoch 2
average train loss = 0.011000    	average train batch reward = 0.545
validation accuracy = 0.110		average validation NDCG = 0.657

epoch 3
average train loss = -0.077136    	average train batch reward = 0.545
validation accuracy = 0.111		average validation NDCG = 0.657

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.202627    	average train batch reward = 0.569
validation accuracy = 0.122		average validation NDCG = 0.676

epoch 2
average train loss = -0.130897    	average train batch reward = 0.571
validation accuracy = 0.125		average validation NDCG = 0.677

epoch 3
average train loss = -0.118567    	average train batch reward = 0.570
validation accuracy = 0.128		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 512, 1.0), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.69208559133383973, 0.69148462060924987, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015181    	average train batch reward = 0.596
validation accuracy = 0.120		average validation NDCG = 0.698

epoch 2
average train loss = 0.062649    	average train batch reward = 0.599
validation accuracy = 0.123		average validation NDCG = 0.700

epoch 3
average train loss = 0.000353    	average train batch reward = 0.601
validation accuracy = 0.126		average validation NDCG = 0.701

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.70109424072240079, 0.69208559133383973, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.010878    	average train batch reward = 0.577
validation accuracy = 0.103		average validation NDCG = 0.686

epoch 2
average train loss = 0.038559    	average train batch reward = 0.578
validation accuracy = 0.104		average validation NDCG = 0.686

epoch 3
average train loss = -0.082472    	average train batch reward = 0.581
validation accuracy = 0.105		average validation NDCG = 0.687

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.70109424072240079, 0.69208559133383973, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.035552    	average train batch reward = 0.575
validation accuracy = 0.091		average validation NDCG = 0.676

epoch 2
average train loss = -0.036990    	average train batch reward = 0.574
validation accuracy = 0.093		average validation NDCG = 0.677

epoch 3
average train loss = 0.010059    	average train batch reward = 0.577
validation accuracy = 0.094		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-08, 5012, 0.5), (9.9999999999999995e-08, 5012, 1.5)], which got scores of [0.70109424072240079, 0.69208559133383973, 0.69070932519464168]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.116083    	average train batch reward = 0.595
validation accuracy = 0.138		average validation NDCG = 0.691

epoch 2
average train loss = 0.025717    	average train batch reward = 0.597
validation accuracy = 0.139		average validation NDCG = 0.692

epoch 3
average train loss = -0.079831    	average train batch reward = 0.601
validation accuracy = 0.141		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.095164    	average train batch reward = 0.556
validation accuracy = 0.083		average validation NDCG = 0.666

epoch 2
average train loss = -0.090517    	average train batch reward = 0.557
validation accuracy = 0.083		average validation NDCG = 0.666

epoch 3
average train loss = 0.145936    	average train batch reward = 0.558
validation accuracy = 0.083		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.059797    	average train batch reward = 0.552
validation accuracy = 0.063		average validation NDCG = 0.659

epoch 2
average train loss = 0.041615    	average train batch reward = 0.553
validation accuracy = 0.063		average validation NDCG = 0.659

epoch 3
average train loss = 0.026166    	average train batch reward = 0.551
validation accuracy = 0.063		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.079997    	average train batch reward = 0.569
validation accuracy = 0.098		average validation NDCG = 0.669

epoch 2
average train loss = 0.102392    	average train batch reward = 0.568
validation accuracy = 0.098		average validation NDCG = 0.669

epoch 3
average train loss = -0.116995    	average train batch reward = 0.567
validation accuracy = 0.098		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.039126    	average train batch reward = 0.549
validation accuracy = 0.055		average validation NDCG = 0.665

epoch 2
average train loss = 0.083159    	average train batch reward = 0.550
validation accuracy = 0.056		average validation NDCG = 0.665

epoch 3
average train loss = 0.092755    	average train batch reward = 0.550
validation accuracy = 0.057		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.072704    	average train batch reward = 0.583
validation accuracy = 0.127		average validation NDCG = 0.673

epoch 2
average train loss = 0.040167    	average train batch reward = 0.582
validation accuracy = 0.127		average validation NDCG = 0.673

epoch 3
average train loss = 0.001986    	average train batch reward = 0.582
validation accuracy = 0.127		average validation NDCG = 0.673

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.006690    	average train batch reward = 0.553
validation accuracy = 0.042		average validation NDCG = 0.659

epoch 2
average train loss = 0.137459    	average train batch reward = 0.554
validation accuracy = 0.042		average validation NDCG = 0.659

epoch 3
average train loss = 0.099449    	average train batch reward = 0.555
validation accuracy = 0.042		average validation NDCG = 0.659

========
Currently the best setups are [(9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 1.5), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.70109424072240079, 0.69282533052542949, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.047889    	average train batch reward = 0.571
validation accuracy = 0.118		average validation NDCG = 0.681

epoch 2
average train loss = -0.209365    	average train batch reward = 0.594
validation accuracy = 0.183		average validation NDCG = 0.701

epoch 3
average train loss = -0.600197    	average train batch reward = 0.616
validation accuracy = 0.239		average validation NDCG = 0.720

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.71991252307278797, 0.70109424072240079, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.154432    	average train batch reward = 0.561
validation accuracy = 0.134		average validation NDCG = 0.688

epoch 2
average train loss = -0.353773    	average train batch reward = 0.599
validation accuracy = 0.171		average validation NDCG = 0.722

epoch 3
average train loss = -0.442692    	average train batch reward = 0.640
validation accuracy = 0.198		average validation NDCG = 0.757

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.0), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.75676686740922194, 0.71991252307278797, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.083723    	average train batch reward = 0.595
validation accuracy = 0.141		average validation NDCG = 0.723

epoch 2
average train loss = -0.406710    	average train batch reward = 0.637
validation accuracy = 0.229		average validation NDCG = 0.757

epoch 3
average train loss = -0.851692    	average train batch reward = 0.668
validation accuracy = 0.295		average validation NDCG = 0.781

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.05), (9.9999999999999995e-08, 5012, 0.5)], which got scores of [0.78067341533355528, 0.75676686740922194, 0.69208559133383973]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.064804    	average train batch reward = 0.573
validation accuracy = 0.154		average validation NDCG = 0.690

epoch 2
average train loss = -0.273544    	average train batch reward = 0.610
validation accuracy = 0.238		average validation NDCG = 0.716

epoch 3
average train loss = -0.692726    	average train batch reward = 0.641
validation accuracy = 0.273		average validation NDCG = 0.744

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.78067341533355528, 0.75676686740922194, 0.74378935488390696]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.022902    	average train batch reward = 0.601
validation accuracy = 0.198		average validation NDCG = 0.711

epoch 2
average train loss = -0.413752    	average train batch reward = 0.641
validation accuracy = 0.262		average validation NDCG = 0.746

epoch 3
average train loss = -0.890030    	average train batch reward = 0.673
validation accuracy = 0.330		average validation NDCG = 0.768

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.087173    	average train batch reward = 0.564
validation accuracy = 0.143		average validation NDCG = 0.687

epoch 2
average train loss = -0.499986    	average train batch reward = 0.602
validation accuracy = 0.206		average validation NDCG = 0.712

epoch 3
average train loss = -0.643340    	average train batch reward = 0.632
validation accuracy = 0.229		average validation NDCG = 0.732

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.116300    	average train batch reward = 0.542
validation accuracy = 0.069		average validation NDCG = 0.666

epoch 2
average train loss = -0.027172    	average train batch reward = 0.563
validation accuracy = 0.075		average validation NDCG = 0.676

epoch 3
average train loss = -0.217458    	average train batch reward = 0.577
validation accuracy = 0.098		average validation NDCG = 0.684

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.245688    	average train batch reward = 0.592
validation accuracy = 0.140		average validation NDCG = 0.694

epoch 2
average train loss = -0.263182    	average train batch reward = 0.607
validation accuracy = 0.162		average validation NDCG = 0.708

epoch 3
average train loss = -0.285460    	average train batch reward = 0.622
validation accuracy = 0.182		average validation NDCG = 0.720

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.005511    	average train batch reward = 0.550
validation accuracy = 0.118		average validation NDCG = 0.661

epoch 2
average train loss = -0.146454    	average train batch reward = 0.562
validation accuracy = 0.128		average validation NDCG = 0.668

epoch 3
average train loss = -0.197792    	average train batch reward = 0.576
validation accuracy = 0.137		average validation NDCG = 0.679

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.037104    	average train batch reward = 0.586
validation accuracy = 0.120		average validation NDCG = 0.693

epoch 2
average train loss = 0.000574    	average train batch reward = 0.606
validation accuracy = 0.147		average validation NDCG = 0.706

epoch 3
average train loss = -0.137579    	average train batch reward = 0.621
validation accuracy = 0.181		average validation NDCG = 0.716

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.017769    	average train batch reward = 0.557
validation accuracy = 0.082		average validation NDCG = 0.665

epoch 2
average train loss = -0.058653    	average train batch reward = 0.570
validation accuracy = 0.091		average validation NDCG = 0.673

epoch 3
average train loss = -0.063808    	average train batch reward = 0.582
validation accuracy = 0.100		average validation NDCG = 0.684

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.094447    	average train batch reward = 0.594
validation accuracy = 0.103		average validation NDCG = 0.704

epoch 2
average train loss = -0.113197    	average train batch reward = 0.614
validation accuracy = 0.135		average validation NDCG = 0.719

epoch 3
average train loss = -0.248195    	average train batch reward = 0.630
validation accuracy = 0.167		average validation NDCG = 0.732

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.064328    	average train batch reward = 0.580
validation accuracy = 0.137		average validation NDCG = 0.678

epoch 2
average train loss = -0.045204    	average train batch reward = 0.585
validation accuracy = 0.143		average validation NDCG = 0.680

epoch 3
average train loss = -0.078448    	average train batch reward = 0.590
validation accuracy = 0.148		average validation NDCG = 0.683

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011758    	average train batch reward = 0.571
validation accuracy = 0.120		average validation NDCG = 0.680

epoch 2
average train loss = -0.128876    	average train batch reward = 0.574
validation accuracy = 0.123		average validation NDCG = 0.682

epoch 3
average train loss = -0.138796    	average train batch reward = 0.577
validation accuracy = 0.127		average validation NDCG = 0.684

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.080801    	average train batch reward = 0.559
validation accuracy = 0.108		average validation NDCG = 0.663

epoch 2
average train loss = -0.165352    	average train batch reward = 0.561
validation accuracy = 0.112		average validation NDCG = 0.665

epoch 3
average train loss = -0.064309    	average train batch reward = 0.563
validation accuracy = 0.115		average validation NDCG = 0.667

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.082893    	average train batch reward = 0.581
validation accuracy = 0.114		average validation NDCG = 0.682

epoch 2
average train loss = -0.093756    	average train batch reward = 0.585
validation accuracy = 0.118		average validation NDCG = 0.684

epoch 3
average train loss = -0.079861    	average train batch reward = 0.585
validation accuracy = 0.124		average validation NDCG = 0.687

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.024466    	average train batch reward = 0.585
validation accuracy = 0.120		average validation NDCG = 0.675

epoch 2
average train loss = 0.007142    	average train batch reward = 0.587
validation accuracy = 0.125		average validation NDCG = 0.677

epoch 3
average train loss = -0.034115    	average train batch reward = 0.591
validation accuracy = 0.129		average validation NDCG = 0.679

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022545    	average train batch reward = 0.569
validation accuracy = 0.093		average validation NDCG = 0.667

epoch 2
average train loss = 0.027975    	average train batch reward = 0.571
validation accuracy = 0.098		average validation NDCG = 0.668

epoch 3
average train loss = -0.115091    	average train batch reward = 0.574
validation accuracy = 0.103		average validation NDCG = 0.670

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.78067341533355528, 0.76842647395701769, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.429516    	average train batch reward = 0.645
validation accuracy = 0.211		average validation NDCG = 0.779

epoch 2
average train loss = -5.994275    	average train batch reward = 0.728
validation accuracy = 0.257		average validation NDCG = 0.830

epoch 3
average train loss = -7.382134    	average train batch reward = 0.757
validation accuracy = 0.315		average validation NDCG = 0.857

========
Currently the best setups are [(0.0001, 50, 0.0), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.85668328922540604, 0.78067341533355528, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.548844    	average train batch reward = 0.720
validation accuracy = 0.480		average validation NDCG = 0.872

epoch 2
average train loss = -4.341769    	average train batch reward = 0.795
validation accuracy = 0.507		average validation NDCG = 0.885

epoch 3
average train loss = -6.366278    	average train batch reward = 0.799
validation accuracy = 0.501		average validation NDCG = 0.889

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 0.0), (1.0000000000000001e-05, 50, 0.05)], which got scores of [0.88857946269704491, 0.85668328922540604, 0.75676686740922194]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.621970    	average train batch reward = 0.643
validation accuracy = 0.309		average validation NDCG = 0.788

epoch 2
average train loss = -6.096456    	average train batch reward = 0.710
validation accuracy = 0.349		average validation NDCG = 0.823

epoch 3
average train loss = -7.036871    	average train batch reward = 0.737
validation accuracy = 0.387		average validation NDCG = 0.846

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 0.0), (0.0001, 50, 0.2)], which got scores of [0.88857946269704491, 0.85668328922540604, 0.84599526650510304]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.387529    	average train batch reward = 0.702
validation accuracy = 0.450		average validation NDCG = 0.826

epoch 2
average train loss = -5.462883    	average train batch reward = 0.741
validation accuracy = 0.438		average validation NDCG = 0.831

epoch 3
average train loss = -9.537366    	average train batch reward = 0.749
validation accuracy = 0.461		average validation NDCG = 0.835

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 0.0), (0.0001, 50, 0.2)], which got scores of [0.88857946269704491, 0.85668328922540604, 0.84599526650510304]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.301150    	average train batch reward = 0.711
validation accuracy = 0.422		average validation NDCG = 0.833

epoch 2
average train loss = -4.460136    	average train batch reward = 0.764
validation accuracy = 0.424		average validation NDCG = 0.870

epoch 3
average train loss = -6.368350    	average train batch reward = 0.779
validation accuracy = 0.477		average validation NDCG = 0.876

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 0.0)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.85668328922540604]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.072557    	average train batch reward = 0.704
validation accuracy = 0.354		average validation NDCG = 0.828

epoch 2
average train loss = -5.472888    	average train batch reward = 0.754
validation accuracy = 0.388		average validation NDCG = 0.862

epoch 3
average train loss = -10.084919    	average train batch reward = 0.774
validation accuracy = 0.429		average validation NDCG = 0.869

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.211893    	average train batch reward = 0.590
validation accuracy = 0.246		average validation NDCG = 0.729

epoch 2
average train loss = -1.288289    	average train batch reward = 0.659
validation accuracy = 0.296		average validation NDCG = 0.770

epoch 3
average train loss = -1.813007    	average train batch reward = 0.687
validation accuracy = 0.335		average validation NDCG = 0.793

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.450350    	average train batch reward = 0.611
validation accuracy = 0.317		average validation NDCG = 0.760

epoch 2
average train loss = -1.585751    	average train batch reward = 0.707
validation accuracy = 0.460		average validation NDCG = 0.818

epoch 3
average train loss = -2.574496    	average train batch reward = 0.738
validation accuracy = 0.484		average validation NDCG = 0.831

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.575681    	average train batch reward = 0.619
validation accuracy = 0.198		average validation NDCG = 0.758

epoch 2
average train loss = -1.323849    	average train batch reward = 0.687
validation accuracy = 0.263		average validation NDCG = 0.800

epoch 3
average train loss = -2.518558    	average train batch reward = 0.712
validation accuracy = 0.285		average validation NDCG = 0.825

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.646105    	average train batch reward = 0.633
validation accuracy = 0.314		average validation NDCG = 0.771

epoch 2
average train loss = -1.623094    	average train batch reward = 0.682
validation accuracy = 0.388		average validation NDCG = 0.799

epoch 3
average train loss = -2.611070    	average train batch reward = 0.709
validation accuracy = 0.396		average validation NDCG = 0.812

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.230935    	average train batch reward = 0.621
validation accuracy = 0.290		average validation NDCG = 0.766

epoch 2
average train loss = -1.057815    	average train batch reward = 0.705
validation accuracy = 0.414		average validation NDCG = 0.803

epoch 3
average train loss = -1.793499    	average train batch reward = 0.736
validation accuracy = 0.459		average validation NDCG = 0.829

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.431784    	average train batch reward = 0.637
validation accuracy = 0.237		average validation NDCG = 0.770

epoch 2
average train loss = -0.796567    	average train batch reward = 0.712
validation accuracy = 0.349		average validation NDCG = 0.825

epoch 3
average train loss = -1.606691    	average train batch reward = 0.745
validation accuracy = 0.432		average validation NDCG = 0.843

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.099716    	average train batch reward = 0.564
validation accuracy = 0.117		average validation NDCG = 0.674

epoch 2
average train loss = -0.184482    	average train batch reward = 0.590
validation accuracy = 0.139		average validation NDCG = 0.694

epoch 3
average train loss = -0.476176    	average train batch reward = 0.623
validation accuracy = 0.173		average validation NDCG = 0.720

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.030785    	average train batch reward = 0.561
validation accuracy = 0.096		average validation NDCG = 0.669

epoch 2
average train loss = -0.177659    	average train batch reward = 0.584
validation accuracy = 0.148		average validation NDCG = 0.692

epoch 3
average train loss = -0.444652    	average train batch reward = 0.609
validation accuracy = 0.186		average validation NDCG = 0.714

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.059403    	average train batch reward = 0.588
validation accuracy = 0.141		average validation NDCG = 0.699

epoch 2
average train loss = -0.227555    	average train batch reward = 0.614
validation accuracy = 0.201		average validation NDCG = 0.721

epoch 3
average train loss = -0.509699    	average train batch reward = 0.643
validation accuracy = 0.235		average validation NDCG = 0.748

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.173958    	average train batch reward = 0.579
validation accuracy = 0.111		average validation NDCG = 0.691

epoch 2
average train loss = -0.178165    	average train batch reward = 0.599
validation accuracy = 0.144		average validation NDCG = 0.714

epoch 3
average train loss = -0.347636    	average train batch reward = 0.630
validation accuracy = 0.177		average validation NDCG = 0.737

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.088445    	average train batch reward = 0.601
validation accuracy = 0.181		average validation NDCG = 0.718

epoch 2
average train loss = -0.368125    	average train batch reward = 0.633
validation accuracy = 0.214		average validation NDCG = 0.742

epoch 3
average train loss = -0.596575    	average train batch reward = 0.661
validation accuracy = 0.258		average validation NDCG = 0.765

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.096329    	average train batch reward = 0.570
validation accuracy = 0.115		average validation NDCG = 0.681

epoch 2
average train loss = -0.210610    	average train batch reward = 0.595
validation accuracy = 0.137		average validation NDCG = 0.701

epoch 3
average train loss = -0.406080    	average train batch reward = 0.617
validation accuracy = 0.154		average validation NDCG = 0.724

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -71.465630    	average train batch reward = 0.621
validation accuracy = 0.154		average validation NDCG = 0.738

epoch 2
average train loss = -317.790436    	average train batch reward = 0.643
validation accuracy = 0.190		average validation NDCG = 0.740

epoch 3
average train loss = -570.458252    	average train batch reward = 0.645
validation accuracy = 0.193		average validation NDCG = 0.741

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -15.975162    	average train batch reward = 0.646
validation accuracy = 0.217		average validation NDCG = 0.779

epoch 2
average train loss = -112.971855    	average train batch reward = 0.686
validation accuracy = 0.242		average validation NDCG = 0.786

epoch 3
average train loss = -199.986038    	average train batch reward = 0.694
validation accuracy = 0.316		average validation NDCG = 0.786

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -17.099470    	average train batch reward = 0.641
validation accuracy = 0.345		average validation NDCG = 0.779

epoch 2
average train loss = -111.921776    	average train batch reward = 0.681
validation accuracy = 0.371		average validation NDCG = 0.802

epoch 3
average train loss = -285.994659    	average train batch reward = 0.712
validation accuracy = 0.361		average validation NDCG = 0.809

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -25.857946    	average train batch reward = 0.663
validation accuracy = 0.124		average validation NDCG = 0.796

epoch 2
average train loss = -128.964706    	average train batch reward = 0.708
validation accuracy = 0.263		average validation NDCG = 0.815

epoch 3
average train loss = -248.857025    	average train batch reward = 0.719
validation accuracy = 0.293		average validation NDCG = 0.813

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -12.661463    	average train batch reward = 0.650
validation accuracy = 0.283		average validation NDCG = 0.779

epoch 2
average train loss = -100.867882    	average train batch reward = 0.676
validation accuracy = 0.308		average validation NDCG = 0.780

epoch 3
average train loss = -207.901321    	average train batch reward = 0.680
validation accuracy = 0.296		average validation NDCG = 0.784

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -26.665951    	average train batch reward = 0.643
validation accuracy = 0.252		average validation NDCG = 0.775

epoch 2
average train loss = -131.499207    	average train batch reward = 0.680
validation accuracy = 0.245		average validation NDCG = 0.783

epoch 3
average train loss = -301.124146    	average train batch reward = 0.688
validation accuracy = 0.261		average validation NDCG = 0.789

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.992194    	average train batch reward = 0.642
validation accuracy = 0.245		average validation NDCG = 0.811

epoch 2
average train loss = -20.396332    	average train batch reward = 0.724
validation accuracy = 0.251		average validation NDCG = 0.847

epoch 3
average train loss = -30.652807    	average train batch reward = 0.749
validation accuracy = 0.244		average validation NDCG = 0.859

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.503278    	average train batch reward = 0.644
validation accuracy = 0.361		average validation NDCG = 0.781

epoch 2
average train loss = -14.520958    	average train batch reward = 0.696
validation accuracy = 0.393		average validation NDCG = 0.802

epoch 3
average train loss = -25.389263    	average train batch reward = 0.711
validation accuracy = 0.386		average validation NDCG = 0.821

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4.703650    	average train batch reward = 0.685
validation accuracy = 0.382		average validation NDCG = 0.815

epoch 2
average train loss = -17.321110    	average train batch reward = 0.729
validation accuracy = 0.382		average validation NDCG = 0.822

epoch 3
average train loss = -50.204128    	average train batch reward = 0.731
validation accuracy = 0.444		average validation NDCG = 0.818

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 1.0), (0.0001, 50, 1.5)], which got scores of [0.88857946269704491, 0.87647544463331717, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.163088    	average train batch reward = 0.722
validation accuracy = 0.485		average validation NDCG = 0.896

epoch 2
average train loss = -12.794568    	average train batch reward = 0.808
validation accuracy = 0.508		average validation NDCG = 0.904

epoch 3
average train loss = -29.209440    	average train batch reward = 0.820
validation accuracy = 0.421		average validation NDCG = 0.914

========
Currently the best setups are [(0.001, 512, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 1.5)], which got scores of [0.91386324070764968, 0.88857946269704491, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.858342    	average train batch reward = 0.643
validation accuracy = 0.217		average validation NDCG = 0.803

epoch 2
average train loss = -13.010067    	average train batch reward = 0.720
validation accuracy = 0.248		average validation NDCG = 0.842

epoch 3
average train loss = -35.109539    	average train batch reward = 0.753
validation accuracy = 0.315		average validation NDCG = 0.853

========
Currently the best setups are [(0.001, 512, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 1.5)], which got scores of [0.91386324070764968, 0.88857946269704491, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.649917    	average train batch reward = 0.648
validation accuracy = 0.336		average validation NDCG = 0.795

epoch 2
average train loss = -14.719807    	average train batch reward = 0.701
validation accuracy = 0.398		average validation NDCG = 0.819

epoch 3
average train loss = -29.291279    	average train batch reward = 0.720
validation accuracy = 0.381		average validation NDCG = 0.826

========
Currently the best setups are [(0.001, 512, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 1.5)], which got scores of [0.91386324070764968, 0.88857946269704491, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.442309    	average train batch reward = 0.608
validation accuracy = 0.250		average validation NDCG = 0.759

epoch 2
average train loss = -1.964488    	average train batch reward = 0.685
validation accuracy = 0.328		average validation NDCG = 0.801

epoch 3
average train loss = -3.006389    	average train batch reward = 0.711
validation accuracy = 0.410		average validation NDCG = 0.823

========
Currently the best setups are [(0.001, 512, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 1.5)], which got scores of [0.91386324070764968, 0.88857946269704491, 0.86866363606773245]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.662142    	average train batch reward = 0.654
validation accuracy = 0.303		average validation NDCG = 0.822

epoch 2
average train loss = -2.294312    	average train batch reward = 0.750
validation accuracy = 0.292		average validation NDCG = 0.875

epoch 3
average train loss = -3.382296    	average train batch reward = 0.811
validation accuracy = 0.415		average validation NDCG = 0.914

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.322860    	average train batch reward = 0.612
validation accuracy = 0.320		average validation NDCG = 0.757

epoch 2
average train loss = -2.000495    	average train batch reward = 0.695
validation accuracy = 0.415		average validation NDCG = 0.804

epoch 3
average train loss = -3.387646    	average train batch reward = 0.723
validation accuracy = 0.451		average validation NDCG = 0.819

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.411724    	average train batch reward = 0.635
validation accuracy = 0.317		average validation NDCG = 0.781

epoch 2
average train loss = -2.074828    	average train batch reward = 0.721
validation accuracy = 0.429		average validation NDCG = 0.842

epoch 3
average train loss = -3.968559    	average train batch reward = 0.766
validation accuracy = 0.482		average validation NDCG = 0.864

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.431556    	average train batch reward = 0.626
validation accuracy = 0.276		average validation NDCG = 0.780

epoch 2
average train loss = -1.888517    	average train batch reward = 0.724
validation accuracy = 0.327		average validation NDCG = 0.834

epoch 3
average train loss = -3.536878    	average train batch reward = 0.776
validation accuracy = 0.451		average validation NDCG = 0.886

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.383774    	average train batch reward = 0.571
validation accuracy = 0.193		average validation NDCG = 0.748

epoch 2
average train loss = -1.514015    	average train batch reward = 0.684
validation accuracy = 0.224		average validation NDCG = 0.819

epoch 3
average train loss = -2.600543    	average train batch reward = 0.724
validation accuracy = 0.283		average validation NDCG = 0.841

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1353.949219    	average train batch reward = 0.617
validation accuracy = 0.111		average validation NDCG = 0.747

epoch 2
average train loss = -20135.126953    	average train batch reward = 0.637
validation accuracy = 0.143		average validation NDCG = 0.748

epoch 3
average train loss = -41327.242188    	average train batch reward = 0.645
validation accuracy = 0.136		average validation NDCG = 0.749

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -142.007889    	average train batch reward = 0.608
validation accuracy = 0.170		average validation NDCG = 0.720

epoch 2
average train loss = -1937.893311    	average train batch reward = 0.626
validation accuracy = 0.103		average validation NDCG = 0.727

epoch 3
average train loss = -11355.093750    	average train batch reward = 0.626
validation accuracy = 0.105		average validation NDCG = 0.721

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1234.374146    	average train batch reward = 0.620
validation accuracy = 0.263		average validation NDCG = 0.748

epoch 2
average train loss = -6639.011230    	average train batch reward = 0.652
validation accuracy = 0.269		average validation NDCG = 0.751

epoch 3
average train loss = -13724.662109    	average train batch reward = 0.654
validation accuracy = 0.254		average validation NDCG = 0.752

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2491.998535    	average train batch reward = 0.595
validation accuracy = 0.194		average validation NDCG = 0.698

epoch 2
average train loss = -9337.979492    	average train batch reward = 0.602
validation accuracy = 0.205		average validation NDCG = 0.700

epoch 3
average train loss = -32128.816406    	average train batch reward = 0.601
validation accuracy = 0.204		average validation NDCG = 0.700

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -434.497589    	average train batch reward = 0.593
validation accuracy = 0.096		average validation NDCG = 0.702

epoch 2
average train loss = -6502.992188    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -23319.611328    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -965.304810    	average train batch reward = 0.593
validation accuracy = 0.154		average validation NDCG = 0.697

epoch 2
average train loss = -5860.910645    	average train batch reward = 0.610
validation accuracy = 0.164		average validation NDCG = 0.717

epoch 3
average train loss = -15044.034180    	average train batch reward = 0.612
validation accuracy = 0.151		average validation NDCG = 0.706

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -48.697739    	average train batch reward = 0.662
validation accuracy = 0.239		average validation NDCG = 0.780

epoch 2
average train loss = -779.974731    	average train batch reward = 0.686
validation accuracy = 0.132		average validation NDCG = 0.776

epoch 3
average train loss = -2902.517334    	average train batch reward = 0.672
validation accuracy = 0.174		average validation NDCG = 0.779

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -52.553017    	average train batch reward = 0.602
validation accuracy = 0.176		average validation NDCG = 0.736

epoch 2
average train loss = -382.902008    	average train batch reward = 0.636
validation accuracy = 0.170		average validation NDCG = 0.748

epoch 3
average train loss = -1969.129517    	average train batch reward = 0.646
validation accuracy = 0.116		average validation NDCG = 0.748

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -246.357346    	average train batch reward = 0.632
validation accuracy = 0.140		average validation NDCG = 0.757

epoch 2
average train loss = -837.983459    	average train batch reward = 0.660
validation accuracy = 0.183		average validation NDCG = 0.778

epoch 3
average train loss = -2596.591064    	average train batch reward = 0.675
validation accuracy = 0.193		average validation NDCG = 0.771

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -88.254303    	average train batch reward = 0.627
validation accuracy = 0.247		average validation NDCG = 0.738

epoch 2
average train loss = -515.804993    	average train batch reward = 0.660
validation accuracy = 0.274		average validation NDCG = 0.760

epoch 3
average train loss = -1551.082642    	average train batch reward = 0.663
validation accuracy = 0.292		average validation NDCG = 0.765

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -113.219986    	average train batch reward = 0.623
validation accuracy = 0.151		average validation NDCG = 0.746

epoch 2
average train loss = -654.570251    	average train batch reward = 0.651
validation accuracy = 0.169		average validation NDCG = 0.755

epoch 3
average train loss = -1940.743408    	average train batch reward = 0.656
validation accuracy = 0.203		average validation NDCG = 0.758

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -82.443840    	average train batch reward = 0.603
validation accuracy = 0.099		average validation NDCG = 0.724

epoch 2
average train loss = -1068.809937    	average train batch reward = 0.616
validation accuracy = 0.103		average validation NDCG = 0.714

epoch 3
average train loss = -4567.821289    	average train batch reward = 0.620
validation accuracy = 0.138		average validation NDCG = 0.724

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.538962    	average train batch reward = 0.640
validation accuracy = 0.365		average validation NDCG = 0.816

epoch 2
average train loss = -19.235922    	average train batch reward = 0.740
validation accuracy = 0.476		average validation NDCG = 0.853

epoch 3
average train loss = -49.893784    	average train batch reward = 0.763
validation accuracy = 0.507		average validation NDCG = 0.862

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6.840528    	average train batch reward = 0.614
validation accuracy = 0.175		average validation NDCG = 0.769

epoch 2
average train loss = -38.510372    	average train batch reward = 0.682
validation accuracy = 0.244		average validation NDCG = 0.808

epoch 3
average train loss = -81.007622    	average train batch reward = 0.711
validation accuracy = 0.293		average validation NDCG = 0.820

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.778019    	average train batch reward = 0.625
validation accuracy = 0.239		average validation NDCG = 0.796

epoch 2
average train loss = -16.809654    	average train batch reward = 0.705
validation accuracy = 0.249		average validation NDCG = 0.830

epoch 3
average train loss = -39.834995    	average train batch reward = 0.726
validation accuracy = 0.373		average validation NDCG = 0.836

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.456758    	average train batch reward = 0.661
validation accuracy = 0.305		average validation NDCG = 0.840

epoch 2
average train loss = -24.762562    	average train batch reward = 0.759
validation accuracy = 0.422		average validation NDCG = 0.861

epoch 3
average train loss = -60.702793    	average train batch reward = 0.776
validation accuracy = 0.457		average validation NDCG = 0.882

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.343684    	average train batch reward = 0.645
validation accuracy = 0.232		average validation NDCG = 0.821

epoch 2
average train loss = -16.654518    	average train batch reward = 0.738
validation accuracy = 0.287		average validation NDCG = 0.836

epoch 3
average train loss = -37.974262    	average train batch reward = 0.746
validation accuracy = 0.415		average validation NDCG = 0.843

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.492801    	average train batch reward = 0.646
validation accuracy = 0.240		average validation NDCG = 0.822

epoch 2
average train loss = -31.374168    	average train batch reward = 0.727
validation accuracy = 0.251		average validation NDCG = 0.836

epoch 3
average train loss = -65.159058    	average train batch reward = 0.748
validation accuracy = 0.290		average validation NDCG = 0.855

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -156862.968750    	average train batch reward = 0.594
validation accuracy = 0.096		average validation NDCG = 0.702

epoch 2
average train loss = -2550858.250000    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -4950230.500000    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -86303.093750    	average train batch reward = 0.607
validation accuracy = 0.189		average validation NDCG = 0.722

epoch 2
average train loss = -254780.734375    	average train batch reward = 0.617
validation accuracy = 0.181		average validation NDCG = 0.716

epoch 3
average train loss = -1199164.500000    	average train batch reward = 0.614
validation accuracy = 0.140		average validation NDCG = 0.721

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -126410.765625    	average train batch reward = 0.644
validation accuracy = 0.205		average validation NDCG = 0.763

epoch 2
average train loss = -949049.875000    	average train batch reward = 0.671
validation accuracy = 0.223		average validation NDCG = 0.782

epoch 3
average train loss = -2168890.000000    	average train batch reward = 0.686
validation accuracy = 0.220		average validation NDCG = 0.786

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -345414.843750    	average train batch reward = 0.593
validation accuracy = 0.107		average validation NDCG = 0.707

epoch 2
average train loss = -2596190.000000    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -7590842.500000    	average train batch reward = 0.600
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 180.856277    	average train batch reward = 0.567
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 2
average train loss = 0.000000    	average train batch reward = 0.569
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 3
average train loss = 0.000000    	average train batch reward = 0.567
validation accuracy = 0.096		average validation NDCG = 0.672

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -34503.601562    	average train batch reward = 0.597
validation accuracy = 0.150		average validation NDCG = 0.715

epoch 2
average train loss = -569650.187500    	average train batch reward = 0.616
validation accuracy = 0.196		average validation NDCG = 0.726

epoch 3
average train loss = -1089815.875000    	average train batch reward = 0.623
validation accuracy = 0.194		average validation NDCG = 0.730

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -5364.181641    	average train batch reward = 0.593
validation accuracy = 0.132		average validation NDCG = 0.700

epoch 2
average train loss = -67059.562500    	average train batch reward = 0.599
validation accuracy = 0.099		average validation NDCG = 0.700

epoch 3
average train loss = -276465.781250    	average train batch reward = 0.597
validation accuracy = 0.099		average validation NDCG = 0.700

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7160.997559    	average train batch reward = 0.607
validation accuracy = 0.190		average validation NDCG = 0.727

epoch 2
average train loss = -66686.367188    	average train batch reward = 0.624
validation accuracy = 0.200		average validation NDCG = 0.726

epoch 3
average train loss = -212366.468750    	average train batch reward = 0.627
validation accuracy = 0.198		average validation NDCG = 0.727

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -288.000885    	average train batch reward = 0.584
validation accuracy = 0.099		average validation NDCG = 0.692

epoch 2
average train loss = -5455.843262    	average train batch reward = 0.591
validation accuracy = 0.178		average validation NDCG = 0.694

epoch 3
average train loss = -14693.645508    	average train batch reward = 0.594
validation accuracy = 0.122		average validation NDCG = 0.698

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -18560.363281    	average train batch reward = 0.595
validation accuracy = 0.131		average validation NDCG = 0.717

epoch 2
average train loss = -81921.531250    	average train batch reward = 0.614
validation accuracy = 0.159		average validation NDCG = 0.720

epoch 3
average train loss = -235119.390625    	average train batch reward = 0.617
validation accuracy = 0.163		average validation NDCG = 0.721

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9515.165039    	average train batch reward = 0.621
validation accuracy = 0.102		average validation NDCG = 0.725

epoch 2
average train loss = -49125.156250    	average train batch reward = 0.650
validation accuracy = 0.201		average validation NDCG = 0.751

epoch 3
average train loss = -202961.687500    	average train batch reward = 0.662
validation accuracy = 0.161		average validation NDCG = 0.752

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6714.350586    	average train batch reward = 0.585
validation accuracy = 0.103		average validation NDCG = 0.701

epoch 2
average train loss = -101707.000000    	average train batch reward = 0.596
validation accuracy = 0.106		average validation NDCG = 0.701

epoch 3
average train loss = -295669.937500    	average train batch reward = 0.599
validation accuracy = 0.108		average validation NDCG = 0.702

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -158.315613    	average train batch reward = 0.643
validation accuracy = 0.226		average validation NDCG = 0.785

epoch 2
average train loss = -1504.299316    	average train batch reward = 0.687
validation accuracy = 0.282		average validation NDCG = 0.797

epoch 3
average train loss = -6893.068848    	average train batch reward = 0.699
validation accuracy = 0.293		average validation NDCG = 0.795

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -34.764954    	average train batch reward = 0.591
validation accuracy = 0.204		average validation NDCG = 0.723

epoch 2
average train loss = -596.394470    	average train batch reward = 0.637
validation accuracy = 0.218		average validation NDCG = 0.749

epoch 3
average train loss = -1825.347900    	average train batch reward = 0.654
validation accuracy = 0.223		average validation NDCG = 0.749

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -146.035385    	average train batch reward = 0.632
validation accuracy = 0.285		average validation NDCG = 0.807

epoch 2
average train loss = -1132.936646    	average train batch reward = 0.721
validation accuracy = 0.432		average validation NDCG = 0.816

epoch 3
average train loss = -3205.070557    	average train batch reward = 0.747
validation accuracy = 0.448		average validation NDCG = 0.852

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -84.103188    	average train batch reward = 0.626
validation accuracy = 0.118		average validation NDCG = 0.777

epoch 2
average train loss = -1203.850830    	average train batch reward = 0.707
validation accuracy = 0.320		average validation NDCG = 0.818

epoch 3
average train loss = -5120.702148    	average train batch reward = 0.729
validation accuracy = 0.259		average validation NDCG = 0.827

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -131.069016    	average train batch reward = 0.599
validation accuracy = 0.170		average validation NDCG = 0.731

epoch 2
average train loss = -1746.755249    	average train batch reward = 0.638
validation accuracy = 0.184		average validation NDCG = 0.751

epoch 3
average train loss = -4810.201660    	average train batch reward = 0.649
validation accuracy = 0.221		average validation NDCG = 0.759

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -67.312447    	average train batch reward = 0.651
validation accuracy = 0.445		average validation NDCG = 0.829

epoch 2
average train loss = -821.837463    	average train batch reward = 0.755
validation accuracy = 0.366		average validation NDCG = 0.874

epoch 3
average train loss = -3769.521240    	average train batch reward = 0.783
validation accuracy = 0.414		average validation NDCG = 0.887

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 849.090698    	average train batch reward = 0.570
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 2
average train loss = 0.000000    	average train batch reward = 0.568
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 3
average train loss = 0.000000    	average train batch reward = 0.569
validation accuracy = 0.096		average validation NDCG = 0.672

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4281528.500000    	average train batch reward = 0.589
validation accuracy = 0.099		average validation NDCG = 0.696

epoch 2
average train loss = -18405134.000000    	average train batch reward = 0.596
validation accuracy = 0.102		average validation NDCG = 0.702

epoch 3
average train loss = -45393300.000000    	average train batch reward = 0.599
validation accuracy = 0.108		average validation NDCG = 0.702

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -8729834.000000    	average train batch reward = 0.595
validation accuracy = 0.127		average validation NDCG = 0.698

epoch 2
average train loss = -64237884.000000    	average train batch reward = 0.598
validation accuracy = 0.137		average validation NDCG = 0.697

epoch 3
average train loss = -70702904.000000    	average train batch reward = 0.600
validation accuracy = 0.195		average validation NDCG = 0.700

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -5599916.500000    	average train batch reward = 0.613
validation accuracy = 0.159		average validation NDCG = 0.730

epoch 2
average train loss = -51800032.000000    	average train batch reward = 0.629
validation accuracy = 0.180		average validation NDCG = 0.732

epoch 3
average train loss = -240034208.000000    	average train batch reward = 0.631
validation accuracy = 0.181		average validation NDCG = 0.731

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1613731.125000    	average train batch reward = 0.588
validation accuracy = 0.092		average validation NDCG = 0.696

epoch 2
average train loss = -13929021.000000    	average train batch reward = 0.587
validation accuracy = 0.092		average validation NDCG = 0.698

epoch 3
average train loss = -54053488.000000    	average train batch reward = 0.591
validation accuracy = 0.092		average validation NDCG = 0.699

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 214.989182    	average train batch reward = 0.569
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 2
average train loss = 0.000000    	average train batch reward = 0.569
validation accuracy = 0.096		average validation NDCG = 0.672

epoch 3
average train loss = 0.000000    	average train batch reward = 0.568
validation accuracy = 0.096		average validation NDCG = 0.672

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -783786.812500    	average train batch reward = 0.618
validation accuracy = 0.151		average validation NDCG = 0.737

epoch 2
average train loss = -11264703.000000    	average train batch reward = 0.650
validation accuracy = 0.153		average validation NDCG = 0.751

epoch 3
average train loss = -27324024.000000    	average train batch reward = 0.641
validation accuracy = 0.197		average validation NDCG = 0.750

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1066020.000000    	average train batch reward = 0.599
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 2
average train loss = -27027378.000000    	average train batch reward = 0.599
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -82974352.000000    	average train batch reward = 0.601
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2153998.750000    	average train batch reward = 0.602
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 2
average train loss = -29527080.000000    	average train batch reward = 0.600
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -67644632.000000    	average train batch reward = 0.600
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -235784.453125    	average train batch reward = 0.606
validation accuracy = 0.133		average validation NDCG = 0.737

epoch 2
average train loss = -3147473.250000    	average train batch reward = 0.623
validation accuracy = 0.163		average validation NDCG = 0.728

epoch 3
average train loss = -19297434.000000    	average train batch reward = 0.627
validation accuracy = 0.180		average validation NDCG = 0.734

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -252535.828125    	average train batch reward = 0.598
validation accuracy = 0.267		average validation NDCG = 0.732

epoch 2
average train loss = -5774308.000000    	average train batch reward = 0.649
validation accuracy = 0.222		average validation NDCG = 0.751

epoch 3
average train loss = -26642932.000000    	average train batch reward = 0.656
validation accuracy = 0.240		average validation NDCG = 0.751

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -464869.500000    	average train batch reward = 0.589
validation accuracy = 0.098		average validation NDCG = 0.700

epoch 2
average train loss = -5183574.500000    	average train batch reward = 0.596
validation accuracy = 0.098		average validation NDCG = 0.699

epoch 3
average train loss = -14094626.000000    	average train batch reward = 0.598
validation accuracy = 0.098		average validation NDCG = 0.700

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -463.227417    	average train batch reward = 0.584
validation accuracy = 0.099		average validation NDCG = 0.695

epoch 2
average train loss = -46101.300781    	average train batch reward = 0.595
validation accuracy = 0.099		average validation NDCG = 0.697

epoch 3
average train loss = -114627.132812    	average train batch reward = 0.593
validation accuracy = 0.103		average validation NDCG = 0.702

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6477.812500    	average train batch reward = 0.606
validation accuracy = 0.098		average validation NDCG = 0.734

epoch 2
average train loss = -110248.210938    	average train batch reward = 0.634
validation accuracy = 0.119		average validation NDCG = 0.741

epoch 3
average train loss = -505701.562500    	average train batch reward = 0.638
validation accuracy = 0.269		average validation NDCG = 0.743

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6145.746094    	average train batch reward = 0.638
validation accuracy = 0.226		average validation NDCG = 0.805

epoch 2
average train loss = -108743.781250    	average train batch reward = 0.712
validation accuracy = 0.288		average validation NDCG = 0.824

epoch 3
average train loss = -429173.906250    	average train batch reward = 0.719
validation accuracy = 0.299		average validation NDCG = 0.826

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4471.000000    	average train batch reward = 0.604
validation accuracy = 0.236		average validation NDCG = 0.752

epoch 2
average train loss = -82299.382812    	average train batch reward = 0.661
validation accuracy = 0.267		average validation NDCG = 0.759

epoch 3
average train loss = -413574.218750    	average train batch reward = 0.664
validation accuracy = 0.280		average validation NDCG = 0.757

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -10364.854492    	average train batch reward = 0.616
validation accuracy = 0.202		average validation NDCG = 0.779

epoch 2
average train loss = -139191.468750    	average train batch reward = 0.682
validation accuracy = 0.245		average validation NDCG = 0.780

epoch 3
average train loss = -504017.062500    	average train batch reward = 0.681
validation accuracy = 0.291		average validation NDCG = 0.778

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
Hyperparameters:
k = 8
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2ac6973c30c8>
Reward function = <function ndcg_full at 0x2ac6973c3140>
Greedy action = <function sample at 0x2ac690219758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7711.520996    	average train batch reward = 0.619
validation accuracy = 0.265		average validation NDCG = 0.770

epoch 2
average train loss = -80405.421875    	average train batch reward = 0.676
validation accuracy = 0.367		average validation NDCG = 0.784

epoch 3
average train loss = -375689.750000    	average train batch reward = 0.683
validation accuracy = 0.243		average validation NDCG = 0.792

========
Currently the best setups are [(0.001, 512, 0.5), (0.001, 5012, 0.05), (0.0001, 50, 0.05)], which got scores of [0.91386324070764968, 0.91367309988507872, 0.88857946269704491]
========
2017-06-30 14:33:29
