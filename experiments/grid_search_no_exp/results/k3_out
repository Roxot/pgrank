2017-06-30 08:42:16
Finding best parameters for k = 3
=========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015333    	average train batch reward = 0.742
validation accuracy = 0.100		average validation NDCG = 0.664

epoch 2
average train loss = 0.034294    	average train batch reward = 0.745
validation accuracy = 0.102		average validation NDCG = 0.666

epoch 3
average train loss = 0.011254    	average train batch reward = 0.747
validation accuracy = 0.103		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (), ()], which got scores of [0.66753127979341864, -1, -1]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.009943    	average train batch reward = 0.750
validation accuracy = 0.106		average validation NDCG = 0.675

epoch 2
average train loss = -0.021260    	average train batch reward = 0.754
validation accuracy = 0.108		average validation NDCG = 0.676

epoch 3
average train loss = -0.039126    	average train batch reward = 0.753
validation accuracy = 0.112		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.0), ()], which got scores of [0.67735445844791098, 0.66753127979341864, -1]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.138459    	average train batch reward = 0.721
validation accuracy = 0.073		average validation NDCG = 0.664

epoch 2
average train loss = 0.106108    	average train batch reward = 0.722
validation accuracy = 0.074		average validation NDCG = 0.666

epoch 3
average train loss = 0.109977    	average train batch reward = 0.724
validation accuracy = 0.076		average validation NDCG = 0.667

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.0), (9.9999999999999995e-08, 50, 0.2)], which got scores of [0.67735445844791098, 0.66753127979341864, 0.66671568259879321]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.038752    	average train batch reward = 0.748
validation accuracy = 0.111		average validation NDCG = 0.675

epoch 2
average train loss = -0.060087    	average train batch reward = 0.749
validation accuracy = 0.113		average validation NDCG = 0.676

epoch 3
average train loss = -0.086424    	average train batch reward = 0.752
validation accuracy = 0.114		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.67735445844791098, 0.67711116868170962, 0.66753127979341864]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.061316    	average train batch reward = 0.738
validation accuracy = 0.104		average validation NDCG = 0.657

epoch 2
average train loss = 0.018856    	average train batch reward = 0.740
validation accuracy = 0.107		average validation NDCG = 0.659

epoch 3
average train loss = 0.044372    	average train batch reward = 0.740
validation accuracy = 0.112		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.5), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.67735445844791098, 0.67711116868170962, 0.66753127979341864]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.115515    	average train batch reward = 0.764
validation accuracy = 0.097		average validation NDCG = 0.698

epoch 2
average train loss = -0.115637    	average train batch reward = 0.768
validation accuracy = 0.099		average validation NDCG = 0.701

epoch 3
average train loss = -0.113920    	average train batch reward = 0.769
validation accuracy = 0.101		average validation NDCG = 0.704

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.0)], which got scores of [0.70358985822920417, 0.67735445844791098, 0.66753127979341864]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.016171    	average train batch reward = 0.741
validation accuracy = 0.096		average validation NDCG = 0.670

epoch 2
average train loss = 0.017118    	average train batch reward = 0.740
validation accuracy = 0.097		average validation NDCG = 0.671

epoch 3
average train loss = -0.043306    	average train batch reward = 0.742
validation accuracy = 0.098		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 512, 0.0)], which got scores of [0.70358985822920417, 0.67735445844791098, 0.67120942733508449]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.049504    	average train batch reward = 0.765
validation accuracy = 0.132		average validation NDCG = 0.689

epoch 2
average train loss = -0.084282    	average train batch reward = 0.768
validation accuracy = 0.132		average validation NDCG = 0.690

epoch 3
average train loss = -0.062109    	average train batch reward = 0.769
validation accuracy = 0.133		average validation NDCG = 0.690

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.67735445844791098]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.081293    	average train batch reward = 0.724
validation accuracy = 0.113		average validation NDCG = 0.653

epoch 2
average train loss = 0.099398    	average train batch reward = 0.725
validation accuracy = 0.113		average validation NDCG = 0.653

epoch 3
average train loss = 0.061692    	average train batch reward = 0.726
validation accuracy = 0.113		average validation NDCG = 0.654

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.67735445844791098]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.000746    	average train batch reward = 0.744
validation accuracy = 0.093		average validation NDCG = 0.670

epoch 2
average train loss = 0.003384    	average train batch reward = 0.745
validation accuracy = 0.094		average validation NDCG = 0.670

epoch 3
average train loss = -0.032750    	average train batch reward = 0.746
validation accuracy = 0.094		average validation NDCG = 0.670

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.67735445844791098]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036526    	average train batch reward = 0.739
validation accuracy = 0.080		average validation NDCG = 0.667

epoch 2
average train loss = 0.033634    	average train batch reward = 0.739
validation accuracy = 0.080		average validation NDCG = 0.668

epoch 3
average train loss = 0.038948    	average train batch reward = 0.740
validation accuracy = 0.081		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.05)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.67735445844791098]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.016429    	average train batch reward = 0.739
validation accuracy = 0.122		average validation NDCG = 0.680

epoch 2
average train loss = -0.051595    	average train batch reward = 0.741
validation accuracy = 0.124		average validation NDCG = 0.680

epoch 3
average train loss = -0.071002    	average train batch reward = 0.741
validation accuracy = 0.125		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.5)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.68066802745191324]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.012220    	average train batch reward = 0.741
validation accuracy = 0.089		average validation NDCG = 0.678

epoch 2
average train loss = -0.025227    	average train batch reward = 0.743
validation accuracy = 0.089		average validation NDCG = 0.678

epoch 3
average train loss = -0.016900    	average train batch reward = 0.743
validation accuracy = 0.089		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.5)], which got scores of [0.70358985822920417, 0.69045852736847868, 0.68066802745191324]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.093794    	average train batch reward = 0.764
validation accuracy = 0.166		average validation NDCG = 0.696

epoch 2
average train loss = -0.137699    	average train batch reward = 0.765
validation accuracy = 0.166		average validation NDCG = 0.696

epoch 3
average train loss = -0.132539    	average train batch reward = 0.765
validation accuracy = 0.166		average validation NDCG = 0.696

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 5012, 0.05), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.70358985822920417, 0.69593636114003077, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.119172    	average train batch reward = 0.730
validation accuracy = 0.059		average validation NDCG = 0.658

epoch 2
average train loss = 0.153267    	average train batch reward = 0.731
validation accuracy = 0.059		average validation NDCG = 0.658

epoch 3
average train loss = 0.095346    	average train batch reward = 0.732
validation accuracy = 0.059		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 5012, 0.05), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.70358985822920417, 0.69593636114003077, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.055353    	average train batch reward = 0.747
validation accuracy = 0.130		average validation NDCG = 0.677

epoch 2
average train loss = -0.061458    	average train batch reward = 0.749
validation accuracy = 0.130		average validation NDCG = 0.677

epoch 3
average train loss = -0.037382    	average train batch reward = 0.747
validation accuracy = 0.130		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 5012, 0.05), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.70358985822920417, 0.69593636114003077, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.048589    	average train batch reward = 0.718
validation accuracy = 0.098		average validation NDCG = 0.658

epoch 2
average train loss = -0.045194    	average train batch reward = 0.720
validation accuracy = 0.098		average validation NDCG = 0.658

epoch 3
average train loss = -0.064393    	average train batch reward = 0.720
validation accuracy = 0.099		average validation NDCG = 0.658

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 5012, 0.05), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.70358985822920417, 0.69593636114003077, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.103674    	average train batch reward = 0.749
validation accuracy = 0.128		average validation NDCG = 0.683

epoch 2
average train loss = -0.216885    	average train batch reward = 0.751
validation accuracy = 0.129		average validation NDCG = 0.683

epoch 3
average train loss = -0.205258    	average train batch reward = 0.751
validation accuracy = 0.129		average validation NDCG = 0.683

========
Currently the best setups are [(9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 5012, 0.05), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.70358985822920417, 0.69593636114003077, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.214615    	average train batch reward = 0.767
validation accuracy = 0.210		average validation NDCG = 0.704

epoch 2
average train loss = -0.392649    	average train batch reward = 0.786
validation accuracy = 0.245		average validation NDCG = 0.725

epoch 3
average train loss = -0.616297    	average train batch reward = 0.800
validation accuracy = 0.270		average validation NDCG = 0.742

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-08, 50, 1.5), (9.9999999999999995e-08, 512, 0.05)], which got scores of [0.74153372417540842, 0.70358985822920417, 0.69045852736847868]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.043897    	average train batch reward = 0.747
validation accuracy = 0.101		average validation NDCG = 0.680

epoch 2
average train loss = -0.173824    	average train batch reward = 0.763
validation accuracy = 0.118		average validation NDCG = 0.696

epoch 3
average train loss = -0.372947    	average train batch reward = 0.782
validation accuracy = 0.138		average validation NDCG = 0.718

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 50, 0.05), (9.9999999999999995e-08, 50, 1.5)], which got scores of [0.74153372417540842, 0.71799775417239253, 0.70358985822920417]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.111706    	average train batch reward = 0.763
validation accuracy = 0.133		average validation NDCG = 0.704

epoch 2
average train loss = -0.245819    	average train batch reward = 0.780
validation accuracy = 0.161		average validation NDCG = 0.726

epoch 3
average train loss = -0.393076    	average train batch reward = 0.797
validation accuracy = 0.191		average validation NDCG = 0.749

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-08, 50, 1.5)], which got scores of [0.74931944195543065, 0.74153372417540842, 0.70358985822920417]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.001919    	average train batch reward = 0.733
validation accuracy = 0.112		average validation NDCG = 0.676

epoch 2
average train loss = -0.105051    	average train batch reward = 0.749
validation accuracy = 0.134		average validation NDCG = 0.694

epoch 3
average train loss = -0.299216    	average train batch reward = 0.767
validation accuracy = 0.166		average validation NDCG = 0.714

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 50, 0.5)], which got scores of [0.74931944195543065, 0.74153372417540842, 0.71442460590532553]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.086940    	average train batch reward = 0.766
validation accuracy = 0.146		average validation NDCG = 0.710

epoch 2
average train loss = -0.274190    	average train batch reward = 0.782
validation accuracy = 0.167		average validation NDCG = 0.728

epoch 3
average train loss = -0.490033    	average train batch reward = 0.798
validation accuracy = 0.194		average validation NDCG = 0.746

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.002341    	average train batch reward = 0.738
validation accuracy = 0.087		average validation NDCG = 0.679

epoch 2
average train loss = -0.233742    	average train batch reward = 0.753
validation accuracy = 0.113		average validation NDCG = 0.693

epoch 3
average train loss = -0.468236    	average train batch reward = 0.768
validation accuracy = 0.127		average validation NDCG = 0.707

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.102395    	average train batch reward = 0.722
validation accuracy = 0.051		average validation NDCG = 0.654

epoch 2
average train loss = 0.086661    	average train batch reward = 0.727
validation accuracy = 0.056		average validation NDCG = 0.657

epoch 3
average train loss = 0.029403    	average train batch reward = 0.731
validation accuracy = 0.061		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.128171    	average train batch reward = 0.709
validation accuracy = 0.077		average validation NDCG = 0.651

epoch 2
average train loss = 0.141667    	average train batch reward = 0.715
validation accuracy = 0.082		average validation NDCG = 0.654

epoch 3
average train loss = 0.138670    	average train batch reward = 0.719
validation accuracy = 0.087		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.024292    	average train batch reward = 0.746
validation accuracy = 0.081		average validation NDCG = 0.691

epoch 2
average train loss = -0.111899    	average train batch reward = 0.754
validation accuracy = 0.088		average validation NDCG = 0.696

epoch 3
average train loss = -0.114033    	average train batch reward = 0.758
validation accuracy = 0.097		average validation NDCG = 0.702

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.054935    	average train batch reward = 0.725
validation accuracy = 0.074		average validation NDCG = 0.658

epoch 2
average train loss = 0.030681    	average train batch reward = 0.730
validation accuracy = 0.079		average validation NDCG = 0.661

epoch 3
average train loss = 0.021192    	average train batch reward = 0.733
validation accuracy = 0.085		average validation NDCG = 0.664

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.031956    	average train batch reward = 0.751
validation accuracy = 0.102		average validation NDCG = 0.677

epoch 2
average train loss = -0.049250    	average train batch reward = 0.758
validation accuracy = 0.105		average validation NDCG = 0.680

epoch 3
average train loss = -0.129641    	average train batch reward = 0.761
validation accuracy = 0.110		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.029796    	average train batch reward = 0.731
validation accuracy = 0.106		average validation NDCG = 0.662

epoch 2
average train loss = -0.099032    	average train batch reward = 0.735
validation accuracy = 0.115		average validation NDCG = 0.665

epoch 3
average train loss = -0.078970    	average train batch reward = 0.740
validation accuracy = 0.124		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.154087    	average train batch reward = 0.710
validation accuracy = 0.037		average validation NDCG = 0.645

epoch 2
average train loss = 0.202457    	average train batch reward = 0.712
validation accuracy = 0.038		average validation NDCG = 0.645

epoch 3
average train loss = 0.181504    	average train batch reward = 0.713
validation accuracy = 0.038		average validation NDCG = 0.646

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015962    	average train batch reward = 0.718
validation accuracy = 0.130		average validation NDCG = 0.654

epoch 2
average train loss = 0.038626    	average train batch reward = 0.722
validation accuracy = 0.132		average validation NDCG = 0.654

epoch 3
average train loss = 0.075587    	average train batch reward = 0.722
validation accuracy = 0.133		average validation NDCG = 0.655

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.045010    	average train batch reward = 0.728
validation accuracy = 0.072		average validation NDCG = 0.660

epoch 2
average train loss = 0.125490    	average train batch reward = 0.730
validation accuracy = 0.072		average validation NDCG = 0.660

epoch 3
average train loss = 0.120689    	average train batch reward = 0.731
validation accuracy = 0.073		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.050123    	average train batch reward = 0.758
validation accuracy = 0.099		average validation NDCG = 0.679

epoch 2
average train loss = -0.101700    	average train batch reward = 0.758
validation accuracy = 0.099		average validation NDCG = 0.680

epoch 3
average train loss = -0.138563    	average train batch reward = 0.760
validation accuracy = 0.099		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.110097    	average train batch reward = 0.739
validation accuracy = 0.047		average validation NDCG = 0.687

epoch 2
average train loss = 0.151203    	average train batch reward = 0.740
validation accuracy = 0.048		average validation NDCG = 0.688

epoch 3
average train loss = 0.156712    	average train batch reward = 0.741
validation accuracy = 0.049		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.003697    	average train batch reward = 0.731
validation accuracy = 0.071		average validation NDCG = 0.667

epoch 2
average train loss = 0.033140    	average train batch reward = 0.732
validation accuracy = 0.073		average validation NDCG = 0.668

epoch 3
average train loss = 0.019398    	average train batch reward = 0.733
validation accuracy = 0.074		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 1.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.74931944195543065, 0.74572053870216159, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.158384    	average train batch reward = 0.813
validation accuracy = 0.412		average validation NDCG = 0.820

epoch 2
average train loss = -3.441442    	average train batch reward = 0.878
validation accuracy = 0.461		average validation NDCG = 0.865

epoch 3
average train loss = -5.135543    	average train batch reward = 0.897
validation accuracy = 0.478		average validation NDCG = 0.887

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (9.9999999999999995e-07, 50, 0.2), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.88736281348980162, 0.74931944195543065, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.029914    	average train batch reward = 0.814
validation accuracy = 0.457		average validation NDCG = 0.837

epoch 2
average train loss = -3.056925    	average train batch reward = 0.897
validation accuracy = 0.549		average validation NDCG = 0.890

epoch 3
average train loss = -4.383344    	average train batch reward = 0.916
validation accuracy = 0.554		average validation NDCG = 0.910

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.0), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.90959903043790136, 0.88736281348980162, 0.74153372417540842]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.034889    	average train batch reward = 0.820
validation accuracy = 0.366		average validation NDCG = 0.837

epoch 2
average train loss = -2.795060    	average train batch reward = 0.890
validation accuracy = 0.545		average validation NDCG = 0.887

epoch 3
average train loss = -4.262277    	average train batch reward = 0.914
validation accuracy = 0.608		average validation NDCG = 0.905

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.210895    	average train batch reward = 0.804
validation accuracy = 0.284		average validation NDCG = 0.789

epoch 2
average train loss = -3.454978    	average train batch reward = 0.854
validation accuracy = 0.380		average validation NDCG = 0.829

epoch 3
average train loss = -6.027155    	average train batch reward = 0.871
validation accuracy = 0.417		average validation NDCG = 0.839

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.815208    	average train batch reward = 0.790
validation accuracy = 0.367		average validation NDCG = 0.797

epoch 2
average train loss = -2.860888    	average train batch reward = 0.871
validation accuracy = 0.451		average validation NDCG = 0.867

epoch 3
average train loss = -4.552453    	average train batch reward = 0.896
validation accuracy = 0.489		average validation NDCG = 0.885

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.156168    	average train batch reward = 0.807
validation accuracy = 0.384		average validation NDCG = 0.806

epoch 2
average train loss = -3.521114    	average train batch reward = 0.875
validation accuracy = 0.443		average validation NDCG = 0.861

epoch 3
average train loss = -5.364467    	average train batch reward = 0.898
validation accuracy = 0.478		average validation NDCG = 0.880

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.272624    	average train batch reward = 0.772
validation accuracy = 0.178		average validation NDCG = 0.729

epoch 2
average train loss = -0.788425    	average train batch reward = 0.815
validation accuracy = 0.265		average validation NDCG = 0.773

epoch 3
average train loss = -1.402333    	average train batch reward = 0.843
validation accuracy = 0.316		average validation NDCG = 0.805

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.263319    	average train batch reward = 0.780
validation accuracy = 0.199		average validation NDCG = 0.737

epoch 2
average train loss = -0.846637    	average train batch reward = 0.814
validation accuracy = 0.309		average validation NDCG = 0.777

epoch 3
average train loss = -1.384634    	average train batch reward = 0.839
validation accuracy = 0.365		average validation NDCG = 0.808

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.134242    	average train batch reward = 0.769
validation accuracy = 0.161		average validation NDCG = 0.726

epoch 2
average train loss = -0.674937    	average train batch reward = 0.822
validation accuracy = 0.272		average validation NDCG = 0.783

epoch 3
average train loss = -1.321308    	average train batch reward = 0.863
validation accuracy = 0.386		average validation NDCG = 0.823

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.240786    	average train batch reward = 0.763
validation accuracy = 0.215		average validation NDCG = 0.703

epoch 2
average train loss = -0.782664    	average train batch reward = 0.797
validation accuracy = 0.284		average validation NDCG = 0.745

epoch 3
average train loss = -1.317664    	average train batch reward = 0.829
validation accuracy = 0.364		average validation NDCG = 0.788

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.175317    	average train batch reward = 0.767
validation accuracy = 0.175		average validation NDCG = 0.717

epoch 2
average train loss = -0.755678    	average train batch reward = 0.799
validation accuracy = 0.270		average validation NDCG = 0.749

epoch 3
average train loss = -1.302870    	average train batch reward = 0.828
validation accuracy = 0.345		average validation NDCG = 0.780

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.266315    	average train batch reward = 0.767
validation accuracy = 0.179		average validation NDCG = 0.730

epoch 2
average train loss = -0.856321    	average train batch reward = 0.812
validation accuracy = 0.289		average validation NDCG = 0.780

epoch 3
average train loss = -1.507207    	average train batch reward = 0.838
validation accuracy = 0.360		average validation NDCG = 0.815

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.011672    	average train batch reward = 0.747
validation accuracy = 0.095		average validation NDCG = 0.680

epoch 2
average train loss = -0.056185    	average train batch reward = 0.756
validation accuracy = 0.104		average validation NDCG = 0.686

epoch 3
average train loss = -0.150372    	average train batch reward = 0.763
validation accuracy = 0.115		average validation NDCG = 0.693

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.045872    	average train batch reward = 0.752
validation accuracy = 0.105		average validation NDCG = 0.697

epoch 2
average train loss = -0.144963    	average train batch reward = 0.759
validation accuracy = 0.122		average validation NDCG = 0.703

epoch 3
average train loss = -0.252913    	average train batch reward = 0.765
validation accuracy = 0.136		average validation NDCG = 0.710

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.100650    	average train batch reward = 0.735
validation accuracy = 0.101		average validation NDCG = 0.669

epoch 2
average train loss = 0.049165    	average train batch reward = 0.744
validation accuracy = 0.116		average validation NDCG = 0.676

epoch 3
average train loss = -0.048352    	average train batch reward = 0.750
validation accuracy = 0.129		average validation NDCG = 0.683

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.093579    	average train batch reward = 0.760
validation accuracy = 0.153		average validation NDCG = 0.687

epoch 2
average train loss = -0.204067    	average train batch reward = 0.765
validation accuracy = 0.168		average validation NDCG = 0.695

epoch 3
average train loss = -0.295623    	average train batch reward = 0.773
validation accuracy = 0.184		average validation NDCG = 0.704

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.051062    	average train batch reward = 0.734
validation accuracy = 0.091		average validation NDCG = 0.669

epoch 2
average train loss = 0.051991    	average train batch reward = 0.739
validation accuracy = 0.098		average validation NDCG = 0.676

epoch 3
average train loss = -0.039727    	average train batch reward = 0.745
validation accuracy = 0.105		average validation NDCG = 0.682

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.034578    	average train batch reward = 0.738
validation accuracy = 0.145		average validation NDCG = 0.677

epoch 2
average train loss = -0.063072    	average train batch reward = 0.747
validation accuracy = 0.167		average validation NDCG = 0.683

epoch 3
average train loss = -0.175203    	average train batch reward = 0.753
validation accuracy = 0.179		average validation NDCG = 0.691

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9.162318    	average train batch reward = 0.883
validation accuracy = 0.536		average validation NDCG = 0.870

epoch 2
average train loss = -36.178406    	average train batch reward = 0.898
validation accuracy = 0.530		average validation NDCG = 0.868

epoch 3
average train loss = -74.765991    	average train batch reward = 0.897
validation accuracy = 0.505		average validation NDCG = 0.870

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.90959903043790136, 0.90478860866227229, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7.000690    	average train batch reward = 0.915
validation accuracy = 0.587		average validation NDCG = 0.931

epoch 2
average train loss = -21.418581    	average train batch reward = 0.943
validation accuracy = 0.538		average validation NDCG = 0.938

epoch 3
average train loss = -40.531277    	average train batch reward = 0.943
validation accuracy = 0.499		average validation NDCG = 0.938

========
Currently the best setups are [(0.0001, 50, 0.05), (1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.0)], which got scores of [0.93835850234987705, 0.90959903043790136, 0.88736281348980162]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -11.181150    	average train batch reward = 0.887
validation accuracy = 0.512		average validation NDCG = 0.902

epoch 2
average train loss = -41.404282    	average train batch reward = 0.918
validation accuracy = 0.497		average validation NDCG = 0.908

epoch 3
average train loss = -87.207176    	average train batch reward = 0.919
validation accuracy = 0.449		average validation NDCG = 0.908

========
Currently the best setups are [(0.0001, 50, 0.05), (1.0000000000000001e-05, 50, 0.05), (0.0001, 50, 0.2)], which got scores of [0.93835850234987705, 0.90959903043790136, 0.90810064109819089]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9.872910    	average train batch reward = 0.898
validation accuracy = 0.543		average validation NDCG = 0.897

epoch 2
average train loss = -37.177719    	average train batch reward = 0.920
validation accuracy = 0.474		average validation NDCG = 0.902

epoch 3
average train loss = -78.570091    	average train batch reward = 0.920
validation accuracy = 0.445		average validation NDCG = 0.901

========
Currently the best setups are [(0.0001, 50, 0.05), (1.0000000000000001e-05, 50, 0.05), (0.0001, 50, 0.2)], which got scores of [0.93835850234987705, 0.90959903043790136, 0.90810064109819089]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -12.504489    	average train batch reward = 0.874
validation accuracy = 0.551		average validation NDCG = 0.874

epoch 2
average train loss = -52.843464    	average train batch reward = 0.899
validation accuracy = 0.514		average validation NDCG = 0.875

epoch 3
average train loss = -119.329445    	average train batch reward = 0.899
validation accuracy = 0.467		average validation NDCG = 0.875

========
Currently the best setups are [(0.0001, 50, 0.05), (1.0000000000000001e-05, 50, 0.05), (0.0001, 50, 0.2)], which got scores of [0.93835850234987705, 0.90959903043790136, 0.90810064109819089]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9.361548    	average train batch reward = 0.897
validation accuracy = 0.480		average validation NDCG = 0.900

epoch 2
average train loss = -34.216747    	average train batch reward = 0.915
validation accuracy = 0.446		average validation NDCG = 0.904

epoch 3
average train loss = -73.918053    	average train batch reward = 0.918
validation accuracy = 0.405		average validation NDCG = 0.904

========
Currently the best setups are [(0.0001, 50, 0.05), (1.0000000000000001e-05, 50, 0.05), (0.0001, 50, 0.2)], which got scores of [0.93835850234987705, 0.90959903043790136, 0.90810064109819089]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.021218    	average train batch reward = 0.862
validation accuracy = 0.505		average validation NDCG = 0.923

epoch 2
average train loss = -5.166457    	average train batch reward = 0.950
validation accuracy = 0.642		average validation NDCG = 0.955

epoch 3
average train loss = -7.366200    	average train batch reward = 0.962
validation accuracy = 0.662		average validation NDCG = 0.962

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 50, 0.05), (0.0001, 50, 0.2)], which got scores of [0.96212134609091693, 0.93835850234987705, 0.90810064109819089]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.673151    	average train batch reward = 0.852
validation accuracy = 0.520		average validation NDCG = 0.895

epoch 2
average train loss = -6.676719    	average train batch reward = 0.931
validation accuracy = 0.586		average validation NDCG = 0.925

epoch 3
average train loss = -9.789796    	average train batch reward = 0.938
validation accuracy = 0.605		average validation NDCG = 0.933

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 50, 0.05), (0.0001, 512, 0.05)], which got scores of [0.96212134609091693, 0.93835850234987705, 0.93262363987844155]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.371315    	average train batch reward = 0.839
validation accuracy = 0.476		average validation NDCG = 0.853

epoch 2
average train loss = -7.534484    	average train batch reward = 0.878
validation accuracy = 0.493		average validation NDCG = 0.869

epoch 3
average train loss = -14.018606    	average train batch reward = 0.886
validation accuracy = 0.486		average validation NDCG = 0.875

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 50, 0.05), (0.0001, 512, 0.05)], which got scores of [0.96212134609091693, 0.93835850234987705, 0.93262363987844155]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.649489    	average train batch reward = 0.859
validation accuracy = 0.489		average validation NDCG = 0.881

epoch 2
average train loss = -6.990363    	average train batch reward = 0.911
validation accuracy = 0.541		average validation NDCG = 0.899

epoch 3
average train loss = -11.483830    	average train batch reward = 0.918
validation accuracy = 0.565		average validation NDCG = 0.903

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 50, 0.05), (0.0001, 512, 0.05)], which got scores of [0.96212134609091693, 0.93835850234987705, 0.93262363987844155]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.586532    	average train batch reward = 0.843
validation accuracy = 0.459		average validation NDCG = 0.913

epoch 2
average train loss = -7.184923    	average train batch reward = 0.939
validation accuracy = 0.591		average validation NDCG = 0.955

epoch 3
average train loss = -10.282930    	average train batch reward = 0.956
validation accuracy = 0.648		average validation NDCG = 0.961

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.414442    	average train batch reward = 0.844
validation accuracy = 0.456		average validation NDCG = 0.848

epoch 2
average train loss = -7.370764    	average train batch reward = 0.890
validation accuracy = 0.515		average validation NDCG = 0.864

epoch 3
average train loss = -12.789784    	average train batch reward = 0.892
validation accuracy = 0.510		average validation NDCG = 0.867

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.103507    	average train batch reward = 0.768
validation accuracy = 0.165		average validation NDCG = 0.732

epoch 2
average train loss = -0.961282    	average train batch reward = 0.839
validation accuracy = 0.264		average validation NDCG = 0.808

epoch 3
average train loss = -1.664727    	average train batch reward = 0.890
validation accuracy = 0.361		average validation NDCG = 0.871

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.360835    	average train batch reward = 0.776
validation accuracy = 0.198		average validation NDCG = 0.755

epoch 2
average train loss = -1.351572    	average train batch reward = 0.827
validation accuracy = 0.274		average validation NDCG = 0.812

epoch 3
average train loss = -2.181482    	average train batch reward = 0.860
validation accuracy = 0.368		average validation NDCG = 0.845

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.251217    	average train batch reward = 0.777
validation accuracy = 0.170		average validation NDCG = 0.734

epoch 2
average train loss = -0.990073    	average train batch reward = 0.820
validation accuracy = 0.297		average validation NDCG = 0.799

epoch 3
average train loss = -1.673474    	average train batch reward = 0.850
validation accuracy = 0.363		average validation NDCG = 0.832

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.258443    	average train batch reward = 0.775
validation accuracy = 0.243		average validation NDCG = 0.737

epoch 2
average train loss = -1.107001    	average train batch reward = 0.824
validation accuracy = 0.343		average validation NDCG = 0.792

epoch 3
average train loss = -1.862464    	average train batch reward = 0.849
validation accuracy = 0.395		average validation NDCG = 0.822

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.239675    	average train batch reward = 0.757
validation accuracy = 0.127		average validation NDCG = 0.712

epoch 2
average train loss = -1.066022    	average train batch reward = 0.809
validation accuracy = 0.200		average validation NDCG = 0.774

epoch 3
average train loss = -1.805520    	average train batch reward = 0.840
validation accuracy = 0.265		average validation NDCG = 0.811

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.112892    	average train batch reward = 0.763
validation accuracy = 0.197		average validation NDCG = 0.733

epoch 2
average train loss = -0.907509    	average train batch reward = 0.823
validation accuracy = 0.350		average validation NDCG = 0.794

epoch 3
average train loss = -1.844892    	average train batch reward = 0.856
validation accuracy = 0.399		average validation NDCG = 0.832

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -611.957153    	average train batch reward = 0.868
validation accuracy = 0.404		average validation NDCG = 0.840

epoch 2
average train loss = -4639.062012    	average train batch reward = 0.871
validation accuracy = 0.387		average validation NDCG = 0.839

epoch 3
average train loss = -11917.983398    	average train batch reward = 0.869
validation accuracy = 0.394		average validation NDCG = 0.838

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -598.944031    	average train batch reward = 0.873
validation accuracy = 0.393		average validation NDCG = 0.857

epoch 2
average train loss = -4217.631348    	average train batch reward = 0.884
validation accuracy = 0.364		average validation NDCG = 0.856

epoch 3
average train loss = -10246.102539    	average train batch reward = 0.885
validation accuracy = 0.361		average validation NDCG = 0.854

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -456.794800    	average train batch reward = 0.907
validation accuracy = 0.293		average validation NDCG = 0.889

epoch 2
average train loss = -2829.145020    	average train batch reward = 0.915
validation accuracy = 0.324		average validation NDCG = 0.888

epoch 3
average train loss = -7657.224609    	average train batch reward = 0.915
validation accuracy = 0.303		average validation NDCG = 0.891

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -679.134583    	average train batch reward = 0.878
validation accuracy = 0.332		average validation NDCG = 0.858

epoch 2
average train loss = -4631.443848    	average train batch reward = 0.883
validation accuracy = 0.290		average validation NDCG = 0.854

epoch 3
average train loss = -12420.321289    	average train batch reward = 0.883
validation accuracy = 0.280		average validation NDCG = 0.852

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -428.159210    	average train batch reward = 0.914
validation accuracy = 0.360		average validation NDCG = 0.899

epoch 2
average train loss = -2991.378906    	average train batch reward = 0.916
validation accuracy = 0.330		average validation NDCG = 0.894

epoch 3
average train loss = -7765.352051    	average train batch reward = 0.917
validation accuracy = 0.319		average validation NDCG = 0.897

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -328.841736    	average train batch reward = 0.925
validation accuracy = 0.309		average validation NDCG = 0.924

epoch 2
average train loss = -1898.237427    	average train batch reward = 0.937
validation accuracy = 0.287		average validation NDCG = 0.923

epoch 3
average train loss = -4454.663574    	average train batch reward = 0.938
validation accuracy = 0.288		average validation NDCG = 0.922

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -27.805639    	average train batch reward = 0.901
validation accuracy = 0.612		average validation NDCG = 0.900

epoch 2
average train loss = -141.669571    	average train batch reward = 0.920
validation accuracy = 0.593		average validation NDCG = 0.904

epoch 3
average train loss = -389.608246    	average train batch reward = 0.922
validation accuracy = 0.564		average validation NDCG = 0.905

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -24.420134    	average train batch reward = 0.909
validation accuracy = 0.558		average validation NDCG = 0.923

epoch 2
average train loss = -110.182526    	average train batch reward = 0.938
validation accuracy = 0.582		average validation NDCG = 0.928

epoch 3
average train loss = -245.218918    	average train batch reward = 0.940
validation accuracy = 0.578		average validation NDCG = 0.930

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -30.562441    	average train batch reward = 0.895
validation accuracy = 0.524		average validation NDCG = 0.893

epoch 2
average train loss = -169.917679    	average train batch reward = 0.915
validation accuracy = 0.502		average validation NDCG = 0.894

epoch 3
average train loss = -410.103333    	average train batch reward = 0.917
validation accuracy = 0.465		average validation NDCG = 0.894

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -25.308371    	average train batch reward = 0.885
validation accuracy = 0.567		average validation NDCG = 0.889

epoch 2
average train loss = -129.901398    	average train batch reward = 0.908
validation accuracy = 0.539		average validation NDCG = 0.891

epoch 3
average train loss = -339.767609    	average train batch reward = 0.910
validation accuracy = 0.522		average validation NDCG = 0.893

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -24.524485    	average train batch reward = 0.896
validation accuracy = 0.539		average validation NDCG = 0.899

epoch 2
average train loss = -116.277306    	average train batch reward = 0.911
validation accuracy = 0.511		average validation NDCG = 0.897

epoch 3
average train loss = -327.291504    	average train batch reward = 0.910
validation accuracy = 0.499		average validation NDCG = 0.892

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -21.653879    	average train batch reward = 0.916
validation accuracy = 0.643		average validation NDCG = 0.931

epoch 2
average train loss = -94.862709    	average train batch reward = 0.943
validation accuracy = 0.592		average validation NDCG = 0.934

epoch 3
average train loss = -240.926392    	average train batch reward = 0.942
validation accuracy = 0.520		average validation NDCG = 0.931

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.0001, 50, 0.05)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.93835850234987705]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.112637    	average train batch reward = 0.820
validation accuracy = 0.477		average validation NDCG = 0.907

epoch 2
average train loss = -8.563355    	average train batch reward = 0.936
validation accuracy = 0.622		average validation NDCG = 0.947

epoch 3
average train loss = -14.069643    	average train batch reward = 0.955
validation accuracy = 0.651		average validation NDCG = 0.959

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.220900    	average train batch reward = 0.847
validation accuracy = 0.645		average validation NDCG = 0.890

epoch 2
average train loss = -8.459112    	average train batch reward = 0.915
validation accuracy = 0.658		average validation NDCG = 0.898

epoch 3
average train loss = -15.414467    	average train batch reward = 0.919
validation accuracy = 0.645		average validation NDCG = 0.904

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.450399    	average train batch reward = 0.829
validation accuracy = 0.452		average validation NDCG = 0.869

epoch 2
average train loss = -9.704191    	average train batch reward = 0.908
validation accuracy = 0.480		average validation NDCG = 0.905

epoch 3
average train loss = -17.017384    	average train batch reward = 0.922
validation accuracy = 0.521		average validation NDCG = 0.915

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.141408    	average train batch reward = 0.846
validation accuracy = 0.621		average validation NDCG = 0.893

epoch 2
average train loss = -8.162574    	average train batch reward = 0.922
validation accuracy = 0.656		average validation NDCG = 0.918

epoch 3
average train loss = -14.669495    	average train batch reward = 0.937
validation accuracy = 0.667		average validation NDCG = 0.931

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.427662    	average train batch reward = 0.833
validation accuracy = 0.507		average validation NDCG = 0.895

epoch 2
average train loss = -9.081686    	average train batch reward = 0.917
validation accuracy = 0.563		average validation NDCG = 0.921

epoch 3
average train loss = -15.909116    	average train batch reward = 0.932
validation accuracy = 0.587		average validation NDCG = 0.927

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -2.322913    	average train batch reward = 0.836
validation accuracy = 0.501		average validation NDCG = 0.881

epoch 2
average train loss = -8.690689    	average train batch reward = 0.911
validation accuracy = 0.620		average validation NDCG = 0.901

epoch 3
average train loss = -16.114145    	average train batch reward = 0.918
validation accuracy = 0.648		average validation NDCG = 0.906

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -78184.921875    	average train batch reward = 0.881
validation accuracy = 0.274		average validation NDCG = 0.843

epoch 2
average train loss = -530110.812500    	average train batch reward = 0.887
validation accuracy = 0.256		average validation NDCG = 0.861

epoch 3
average train loss = -1306426.875000    	average train batch reward = 0.887
validation accuracy = 0.255		average validation NDCG = 0.859

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -57770.152344    	average train batch reward = 0.842
validation accuracy = 0.345		average validation NDCG = 0.789

epoch 2
average train loss = -388976.062500    	average train batch reward = 0.843
validation accuracy = 0.338		average validation NDCG = 0.791

epoch 3
average train loss = -971977.500000    	average train batch reward = 0.844
validation accuracy = 0.336		average validation NDCG = 0.791

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -73777.773438    	average train batch reward = 0.871
validation accuracy = 0.303		average validation NDCG = 0.830

epoch 2
average train loss = -503260.593750    	average train batch reward = 0.872
validation accuracy = 0.278		average validation NDCG = 0.829

epoch 3
average train loss = -1288981.750000    	average train batch reward = 0.872
validation accuracy = 0.273		average validation NDCG = 0.827

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -59280.921875    	average train batch reward = 0.849
validation accuracy = 0.357		average validation NDCG = 0.796

epoch 2
average train loss = -427745.062500    	average train batch reward = 0.851
validation accuracy = 0.361		average validation NDCG = 0.795

epoch 3
average train loss = -1106050.500000    	average train batch reward = 0.849
validation accuracy = 0.359		average validation NDCG = 0.795

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -102803.570312    	average train batch reward = 0.840
validation accuracy = 0.222		average validation NDCG = 0.804

epoch 2
average train loss = -735260.187500    	average train batch reward = 0.844
validation accuracy = 0.229		average validation NDCG = 0.802

epoch 3
average train loss = -1840953.125000    	average train batch reward = 0.843
validation accuracy = 0.225		average validation NDCG = 0.797

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -89320.101562    	average train batch reward = 0.848
validation accuracy = 0.203		average validation NDCG = 0.789

epoch 2
average train loss = -677397.187500    	average train batch reward = 0.845
validation accuracy = 0.194		average validation NDCG = 0.789

epoch 3
average train loss = -1688509.125000    	average train batch reward = 0.845
validation accuracy = 0.192		average validation NDCG = 0.790

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1032.165283    	average train batch reward = 0.924
validation accuracy = 0.428		average validation NDCG = 0.917

epoch 2
average train loss = -7902.791504    	average train batch reward = 0.937
validation accuracy = 0.384		average validation NDCG = 0.919

epoch 3
average train loss = -24575.847656    	average train batch reward = 0.935
validation accuracy = 0.360		average validation NDCG = 0.921

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1991.565186    	average train batch reward = 0.876
validation accuracy = 0.391		average validation NDCG = 0.843

epoch 2
average train loss = -18573.136719    	average train batch reward = 0.882
validation accuracy = 0.359		average validation NDCG = 0.849

epoch 3
average train loss = -53042.496094    	average train batch reward = 0.885
validation accuracy = 0.365		average validation NDCG = 0.846

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1767.892212    	average train batch reward = 0.892
validation accuracy = 0.515		average validation NDCG = 0.871

epoch 2
average train loss = -16700.513672    	average train batch reward = 0.901
validation accuracy = 0.489		average validation NDCG = 0.874

epoch 3
average train loss = -48969.730469    	average train batch reward = 0.901
validation accuracy = 0.481		average validation NDCG = 0.873

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1480.543213    	average train batch reward = 0.899
validation accuracy = 0.353		average validation NDCG = 0.886

epoch 2
average train loss = -13016.498047    	average train batch reward = 0.909
validation accuracy = 0.390		average validation NDCG = 0.885

epoch 3
average train loss = -37316.472656    	average train batch reward = 0.909
validation accuracy = 0.348		average validation NDCG = 0.882

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1422.710693    	average train batch reward = 0.902
validation accuracy = 0.425		average validation NDCG = 0.898

epoch 2
average train loss = -12220.413086    	average train batch reward = 0.915
validation accuracy = 0.396		average validation NDCG = 0.895

epoch 3
average train loss = -38692.562500    	average train batch reward = 0.914
validation accuracy = 0.366		average validation NDCG = 0.895

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -765.452332    	average train batch reward = 0.921
validation accuracy = 0.540		average validation NDCG = 0.920

epoch 2
average train loss = -5468.161621    	average train batch reward = 0.934
validation accuracy = 0.503		average validation NDCG = 0.920

epoch 3
average train loss = -16181.973633    	average train batch reward = 0.936
validation accuracy = 0.464		average validation NDCG = 0.921

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -23.593098    	average train batch reward = 0.880
validation accuracy = 0.513		average validation NDCG = 0.909

epoch 2
average train loss = -135.182495    	average train batch reward = 0.932
validation accuracy = 0.512		average validation NDCG = 0.918

epoch 3
average train loss = -326.825623    	average train batch reward = 0.936
validation accuracy = 0.507		average validation NDCG = 0.923

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -24.517904    	average train batch reward = 0.855
validation accuracy = 0.496		average validation NDCG = 0.855

epoch 2
average train loss = -168.120850    	average train batch reward = 0.884
validation accuracy = 0.495		average validation NDCG = 0.854

epoch 3
average train loss = -487.466888    	average train batch reward = 0.885
validation accuracy = 0.497		average validation NDCG = 0.853

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -20.810455    	average train batch reward = 0.828
validation accuracy = 0.432		average validation NDCG = 0.827

epoch 2
average train loss = -151.063141    	average train batch reward = 0.861
validation accuracy = 0.434		average validation NDCG = 0.828

epoch 3
average train loss = -436.604553    	average train batch reward = 0.863
validation accuracy = 0.408		average validation NDCG = 0.826

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -24.878071    	average train batch reward = 0.883
validation accuracy = 0.559		average validation NDCG = 0.920

epoch 2
average train loss = -133.650452    	average train batch reward = 0.936
validation accuracy = 0.580		average validation NDCG = 0.923

epoch 3
average train loss = -316.757996    	average train batch reward = 0.937
validation accuracy = 0.603		average validation NDCG = 0.926

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -26.974457    	average train batch reward = 0.866
validation accuracy = 0.510		average validation NDCG = 0.878

epoch 2
average train loss = -167.437576    	average train batch reward = 0.903
validation accuracy = 0.516		average validation NDCG = 0.881

epoch 3
average train loss = -427.632141    	average train batch reward = 0.906
validation accuracy = 0.493		average validation NDCG = 0.885

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -23.944260    	average train batch reward = 0.868
validation accuracy = 0.467		average validation NDCG = 0.892

epoch 2
average train loss = -150.227280    	average train batch reward = 0.910
validation accuracy = 0.548		average validation NDCG = 0.886

epoch 3
average train loss = -420.936432    	average train batch reward = 0.911
validation accuracy = 0.518		average validation NDCG = 0.891

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -11942137.000000    	average train batch reward = 0.808
validation accuracy = 0.210		average validation NDCG = 0.760

epoch 2
average train loss = -92221328.000000    	average train batch reward = 0.809
validation accuracy = 0.198		average validation NDCG = 0.760

epoch 3
average train loss = -237979248.000000    	average train batch reward = 0.809
validation accuracy = 0.193		average validation NDCG = 0.760

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -10899486.000000    	average train batch reward = 0.803
validation accuracy = 0.149		average validation NDCG = 0.756

epoch 2
average train loss = -78598552.000000    	average train batch reward = 0.810
validation accuracy = 0.142		average validation NDCG = 0.756

epoch 3
average train loss = -201235696.000000    	average train batch reward = 0.809
validation accuracy = 0.222		average validation NDCG = 0.755

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9044719.000000    	average train batch reward = 0.821
validation accuracy = 0.228		average validation NDCG = 0.767

epoch 2
average train loss = -69816248.000000    	average train batch reward = 0.822
validation accuracy = 0.222		average validation NDCG = 0.765

epoch 3
average train loss = -173174064.000000    	average train batch reward = 0.820
validation accuracy = 0.224		average validation NDCG = 0.766

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6686779.000000    	average train batch reward = 0.819
validation accuracy = 0.204		average validation NDCG = 0.773

epoch 2
average train loss = -45024136.000000    	average train batch reward = 0.820
validation accuracy = 0.278		average validation NDCG = 0.772

epoch 3
average train loss = -113990792.000000    	average train batch reward = 0.822
validation accuracy = 0.273		average validation NDCG = 0.771

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -6851621.500000    	average train batch reward = 0.810
validation accuracy = 0.177		average validation NDCG = 0.757

epoch 2
average train loss = -42133340.000000    	average train batch reward = 0.811
validation accuracy = 0.189		average validation NDCG = 0.758

epoch 3
average train loss = -113640424.000000    	average train batch reward = 0.814
validation accuracy = 0.185		average validation NDCG = 0.757

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -5957324.500000    	average train batch reward = 0.816
validation accuracy = 0.234		average validation NDCG = 0.751

epoch 2
average train loss = -38178740.000000    	average train batch reward = 0.817
validation accuracy = 0.235		average validation NDCG = 0.751

epoch 3
average train loss = -101097216.000000    	average train batch reward = 0.817
validation accuracy = 0.247		average validation NDCG = 0.750

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -182287.250000    	average train batch reward = 0.847
validation accuracy = 0.302		average validation NDCG = 0.813

epoch 2
average train loss = -1585282.875000    	average train batch reward = 0.857
validation accuracy = 0.367		average validation NDCG = 0.824

epoch 3
average train loss = -4729633.500000    	average train batch reward = 0.859
validation accuracy = 0.355		average validation NDCG = 0.822

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -183534.812500    	average train batch reward = 0.879
validation accuracy = 0.373		average validation NDCG = 0.849

epoch 2
average train loss = -1725565.000000    	average train batch reward = 0.888
validation accuracy = 0.349		average validation NDCG = 0.849

epoch 3
average train loss = -5385729.000000    	average train batch reward = 0.888
validation accuracy = 0.350		average validation NDCG = 0.850

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -128280.953125    	average train batch reward = 0.900
validation accuracy = 0.395		average validation NDCG = 0.892

epoch 2
average train loss = -1225783.500000    	average train batch reward = 0.911
validation accuracy = 0.354		average validation NDCG = 0.895

epoch 3
average train loss = -3889681.250000    	average train batch reward = 0.912
validation accuracy = 0.317		average validation NDCG = 0.895

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -205997.921875    	average train batch reward = 0.823
validation accuracy = 0.333		average validation NDCG = 0.780

epoch 2
average train loss = -1930981.000000    	average train batch reward = 0.830
validation accuracy = 0.328		average validation NDCG = 0.781

epoch 3
average train loss = -5861622.500000    	average train batch reward = 0.829
validation accuracy = 0.320		average validation NDCG = 0.781

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -160076.437500    	average train batch reward = 0.855
validation accuracy = 0.364		average validation NDCG = 0.819

epoch 2
average train loss = -1399610.625000    	average train batch reward = 0.866
validation accuracy = 0.365		average validation NDCG = 0.820

epoch 3
average train loss = -4264357.500000    	average train batch reward = 0.866
validation accuracy = 0.368		average validation NDCG = 0.820

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -232655.031250    	average train batch reward = 0.835
validation accuracy = 0.333		average validation NDCG = 0.791

epoch 2
average train loss = -2211493.750000    	average train batch reward = 0.842
validation accuracy = 0.303		average validation NDCG = 0.791

epoch 3
average train loss = -6679860.500000    	average train batch reward = 0.842
validation accuracy = 0.300		average validation NDCG = 0.794

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -768.733032    	average train batch reward = 0.854
validation accuracy = 0.560		average validation NDCG = 0.874

epoch 2
average train loss = -8310.108398    	average train batch reward = 0.911
validation accuracy = 0.600		average validation NDCG = 0.882

epoch 3
average train loss = -29248.691406    	average train batch reward = 0.913
validation accuracy = 0.619		average validation NDCG = 0.884

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1062.704102    	average train batch reward = 0.860
validation accuracy = 0.504		average validation NDCG = 0.864

epoch 2
average train loss = -11708.013672    	average train batch reward = 0.895
validation accuracy = 0.517		average validation NDCG = 0.870

epoch 3
average train loss = -39772.085938    	average train batch reward = 0.895
validation accuracy = 0.526		average validation NDCG = 0.870

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -855.620483    	average train batch reward = 0.842
validation accuracy = 0.568		average validation NDCG = 0.841

epoch 2
average train loss = -11643.289062    	average train batch reward = 0.877
validation accuracy = 0.569		average validation NDCG = 0.842

epoch 3
average train loss = -41466.550781    	average train batch reward = 0.878
validation accuracy = 0.559		average validation NDCG = 0.843

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -735.408325    	average train batch reward = 0.843
validation accuracy = 0.335		average validation NDCG = 0.837

epoch 2
average train loss = -9456.603516    	average train batch reward = 0.878
validation accuracy = 0.434		average validation NDCG = 0.839

epoch 3
average train loss = -32850.843750    	average train batch reward = 0.878
validation accuracy = 0.435		average validation NDCG = 0.842

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -874.655090    	average train batch reward = 0.820
validation accuracy = 0.391		average validation NDCG = 0.798

epoch 2
average train loss = -12169.158203    	average train batch reward = 0.844
validation accuracy = 0.412		average validation NDCG = 0.798

epoch 3
average train loss = -42925.109375    	average train batch reward = 0.845
validation accuracy = 0.394		average validation NDCG = 0.799

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1042.247803    	average train batch reward = 0.814
validation accuracy = 0.299		average validation NDCG = 0.787

epoch 2
average train loss = -13458.237305    	average train batch reward = 0.842
validation accuracy = 0.332		average validation NDCG = 0.788

epoch 3
average train loss = -51636.273438    	average train batch reward = 0.844
validation accuracy = 0.327		average validation NDCG = 0.789

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1013320256.000000    	average train batch reward = 0.802
validation accuracy = 0.196		average validation NDCG = 0.756

epoch 2
average train loss = -6947161600.000000    	average train batch reward = 0.804
validation accuracy = 0.188		average validation NDCG = 0.754

epoch 3
average train loss = -16049391616.000000    	average train batch reward = 0.803
validation accuracy = 0.189		average validation NDCG = 0.753

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -668449472.000000    	average train batch reward = 0.800
validation accuracy = 0.215		average validation NDCG = 0.746

epoch 2
average train loss = -4215985920.000000    	average train batch reward = 0.801
validation accuracy = 0.204		average validation NDCG = 0.747

epoch 3
average train loss = -10263255040.000000    	average train batch reward = 0.801
validation accuracy = 0.229		average validation NDCG = 0.747

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1089094016.000000    	average train batch reward = 0.815
validation accuracy = 0.126		average validation NDCG = 0.778

epoch 2
average train loss = -6934927872.000000    	average train batch reward = 0.825
validation accuracy = 0.129		average validation NDCG = 0.782

epoch 3
average train loss = -17411014656.000000    	average train batch reward = 0.824
validation accuracy = 0.138		average validation NDCG = 0.782

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1208151680.000000    	average train batch reward = 0.794
validation accuracy = 0.149		average validation NDCG = 0.732

epoch 2
average train loss = -9019873280.000000    	average train batch reward = 0.797
validation accuracy = 0.140		average validation NDCG = 0.734

epoch 3
average train loss = -23762843648.000000    	average train batch reward = 0.797
validation accuracy = 0.139		average validation NDCG = 0.736

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -599971648.000000    	average train batch reward = 0.825
validation accuracy = 0.249		average validation NDCG = 0.764

epoch 2
average train loss = -3921546496.000000    	average train batch reward = 0.828
validation accuracy = 0.261		average validation NDCG = 0.764

epoch 3
average train loss = -9428505600.000000    	average train batch reward = 0.829
validation accuracy = 0.266		average validation NDCG = 0.764

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -571274688.000000    	average train batch reward = 0.835
validation accuracy = 0.228		average validation NDCG = 0.790

epoch 2
average train loss = -3714943232.000000    	average train batch reward = 0.837
validation accuracy = 0.243		average validation NDCG = 0.791

epoch 3
average train loss = -9016564736.000000    	average train batch reward = 0.838
validation accuracy = 0.248		average validation NDCG = 0.793

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -26555080.000000    	average train batch reward = 0.840
validation accuracy = 0.294		average validation NDCG = 0.794

epoch 2
average train loss = -240889280.000000    	average train batch reward = 0.849
validation accuracy = 0.293		average validation NDCG = 0.810

epoch 3
average train loss = -716817216.000000    	average train batch reward = 0.849
validation accuracy = 0.294		average validation NDCG = 0.804

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -23601956.000000    	average train batch reward = 0.850
validation accuracy = 0.237		average validation NDCG = 0.815

epoch 2
average train loss = -218718128.000000    	average train batch reward = 0.857
validation accuracy = 0.256		average validation NDCG = 0.816

epoch 3
average train loss = -668171776.000000    	average train batch reward = 0.858
validation accuracy = 0.256		average validation NDCG = 0.820

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -16797094.000000    	average train batch reward = 0.833
validation accuracy = 0.353		average validation NDCG = 0.787

epoch 2
average train loss = -170308544.000000    	average train batch reward = 0.840
validation accuracy = 0.308		average validation NDCG = 0.789

epoch 3
average train loss = -508193152.000000    	average train batch reward = 0.839
validation accuracy = 0.323		average validation NDCG = 0.789

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -24363916.000000    	average train batch reward = 0.818
validation accuracy = 0.284		average validation NDCG = 0.782

epoch 2
average train loss = -257810768.000000    	average train batch reward = 0.824
validation accuracy = 0.272		average validation NDCG = 0.781

epoch 3
average train loss = -798999680.000000    	average train batch reward = 0.824
validation accuracy = 0.281		average validation NDCG = 0.779

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -16244804.000000    	average train batch reward = 0.823
validation accuracy = 0.366		average validation NDCG = 0.783

epoch 2
average train loss = -164210624.000000    	average train batch reward = 0.829
validation accuracy = 0.361		average validation NDCG = 0.783

epoch 3
average train loss = -522076128.000000    	average train batch reward = 0.827
validation accuracy = 0.364		average validation NDCG = 0.783

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -23287402.000000    	average train batch reward = 0.801
validation accuracy = 0.271		average validation NDCG = 0.748

epoch 2
average train loss = -235555584.000000    	average train batch reward = 0.801
validation accuracy = 0.261		average validation NDCG = 0.748

epoch 3
average train loss = -742980160.000000    	average train batch reward = 0.802
validation accuracy = 0.262		average validation NDCG = 0.749

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -65434.238281    	average train batch reward = 0.809
validation accuracy = 0.378		average validation NDCG = 0.789

epoch 2
average train loss = -959357.500000    	average train batch reward = 0.847
validation accuracy = 0.424		average validation NDCG = 0.793

epoch 3
average train loss = -3797696.500000    	average train batch reward = 0.846
validation accuracy = 0.444		average validation NDCG = 0.793

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -61661.394531    	average train batch reward = 0.817
validation accuracy = 0.370		average validation NDCG = 0.829

epoch 2
average train loss = -865038.000000    	average train batch reward = 0.879
validation accuracy = 0.420		average validation NDCG = 0.838

epoch 3
average train loss = -3112792.500000    	average train batch reward = 0.879
validation accuracy = 0.435		average validation NDCG = 0.837

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -75311.539062    	average train batch reward = 0.824
validation accuracy = 0.406		average validation NDCG = 0.814

epoch 2
average train loss = -1047333.375000    	average train batch reward = 0.862
validation accuracy = 0.420		average validation NDCG = 0.817

epoch 3
average train loss = -4077190.500000    	average train batch reward = 0.861
validation accuracy = 0.441		average validation NDCG = 0.820

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -64596.101562    	average train batch reward = 0.803
validation accuracy = 0.331		average validation NDCG = 0.777

epoch 2
average train loss = -1007574.125000    	average train batch reward = 0.828
validation accuracy = 0.313		average validation NDCG = 0.775

epoch 3
average train loss = -3987832.500000    	average train batch reward = 0.827
validation accuracy = 0.304		average validation NDCG = 0.772

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -77832.453125    	average train batch reward = 0.828
validation accuracy = 0.493		average validation NDCG = 0.822

epoch 2
average train loss = -1127334.875000    	average train batch reward = 0.868
validation accuracy = 0.481		average validation NDCG = 0.825

epoch 3
average train loss = -4177441.250000    	average train batch reward = 0.868
validation accuracy = 0.495		average validation NDCG = 0.827

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
Hyperparameters:
k = 3
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b01183c60c8>
Reward function = <function ndcg_full at 0x2b01183c6140>
Greedy action = <function sample at 0x2b011121a758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -63980.355469    	average train batch reward = 0.833
validation accuracy = 0.393		average validation NDCG = 0.848

epoch 2
average train loss = -944660.687500    	average train batch reward = 0.881
validation accuracy = 0.436		average validation NDCG = 0.850

epoch 3
average train loss = -3351324.000000    	average train batch reward = 0.881
validation accuracy = 0.460		average validation NDCG = 0.851

========
Currently the best setups are [(0.0001, 512, 0.0), (0.0001, 512, 1.0), (0.001, 5012, 0.0)], which got scores of [0.96212134609091693, 0.96118452892737394, 0.9590007785778415]
========
2017-06-30 13:31:41
