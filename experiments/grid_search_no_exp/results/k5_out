2017-06-30 08:48:20
Finding best parameters for k = 5
=========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.095159    	average train batch reward = 0.632
validation accuracy = 0.099		average validation NDCG = 0.666

epoch 2
average train loss = 0.066757    	average train batch reward = 0.633
validation accuracy = 0.100		average validation NDCG = 0.667

epoch 3
average train loss = 0.091204    	average train batch reward = 0.631
validation accuracy = 0.100		average validation NDCG = 0.668

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.0), (), ()], which got scores of [0.66773054633884288, -1, -1]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.008578    	average train batch reward = 0.651
validation accuracy = 0.107		average validation NDCG = 0.680

epoch 2
average train loss = -0.032392    	average train batch reward = 0.651
validation accuracy = 0.107		average validation NDCG = 0.681

epoch 3
average train loss = -0.058787    	average train batch reward = 0.653
validation accuracy = 0.108		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.0), ()], which got scores of [0.68137584428266429, 0.66773054633884288, -1]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.107232    	average train batch reward = 0.638
validation accuracy = 0.069		average validation NDCG = 0.681

epoch 2
average train loss = 0.119478    	average train batch reward = 0.640
validation accuracy = 0.071		average validation NDCG = 0.681

epoch 3
average train loss = 0.067180    	average train batch reward = 0.641
validation accuracy = 0.071		average validation NDCG = 0.682

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05), ()], which got scores of [0.68215263401558857, 0.68137584428266429, -1]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.093844    	average train batch reward = 0.610
validation accuracy = 0.103		average validation NDCG = 0.650

epoch 2
average train loss = 0.105742    	average train batch reward = 0.609
validation accuracy = 0.104		average validation NDCG = 0.651

epoch 3
average train loss = 0.011575    	average train batch reward = 0.611
validation accuracy = 0.105		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 0.5)], which got scores of [0.68215263401558857, 0.68137584428266429, 0.65113596083962721]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015124    	average train batch reward = 0.629
validation accuracy = 0.088		average validation NDCG = 0.661

epoch 2
average train loss = 0.062514    	average train batch reward = 0.631
validation accuracy = 0.088		average validation NDCG = 0.661

epoch 3
average train loss = 0.042279    	average train batch reward = 0.631
validation accuracy = 0.088		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 1.0)], which got scores of [0.68215263401558857, 0.68137584428266429, 0.66167129523574708]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.091541    	average train batch reward = 0.612
validation accuracy = 0.059		average validation NDCG = 0.654

epoch 2
average train loss = 0.106597    	average train batch reward = 0.615
validation accuracy = 0.060		average validation NDCG = 0.655

epoch 3
average train loss = 0.115123    	average train batch reward = 0.616
validation accuracy = 0.060		average validation NDCG = 0.656

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 50, 1.0)], which got scores of [0.68215263401558857, 0.68137584428266429, 0.66167129523574708]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.134835    	average train batch reward = 0.627
validation accuracy = 0.073		average validation NDCG = 0.670

epoch 2
average train loss = 0.013561    	average train batch reward = 0.629
validation accuracy = 0.073		average validation NDCG = 0.671

epoch 3
average train loss = 0.020190    	average train batch reward = 0.627
validation accuracy = 0.074		average validation NDCG = 0.671

========
Currently the best setups are [(9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 50, 0.05), (9.9999999999999995e-08, 512, 0.0)], which got scores of [0.68215263401558857, 0.68137584428266429, 0.6710542703750707]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.085498    	average train batch reward = 0.650
validation accuracy = 0.084		average validation NDCG = 0.685

epoch 2
average train loss = 0.008353    	average train batch reward = 0.651
validation accuracy = 0.085		average validation NDCG = 0.686

epoch 3
average train loss = 0.024303    	average train batch reward = 0.651
validation accuracy = 0.086		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 512, 0.0)], which got scores of [0.68582643197905213, 0.68215263401558857, 0.6710542703750707]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.061601    	average train batch reward = 0.647
validation accuracy = 0.114		average validation NDCG = 0.679

epoch 2
average train loss = 0.015322    	average train batch reward = 0.647
validation accuracy = 0.115		average validation NDCG = 0.679

epoch 3
average train loss = -0.072858    	average train batch reward = 0.646
validation accuracy = 0.115		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 50, 0.2), (9.9999999999999995e-08, 512, 0.2)], which got scores of [0.68582643197905213, 0.68215263401558857, 0.67884367544406032]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.046833    	average train batch reward = 0.668
validation accuracy = 0.097		average validation NDCG = 0.688

epoch 2
average train loss = 0.040823    	average train batch reward = 0.668
validation accuracy = 0.097		average validation NDCG = 0.688

epoch 3
average train loss = 0.087122    	average train batch reward = 0.669
validation accuracy = 0.097		average validation NDCG = 0.689

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 0.2)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.67884367544406032]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.039111    	average train batch reward = 0.663
validation accuracy = 0.165		average validation NDCG = 0.681

epoch 2
average train loss = -0.070213    	average train batch reward = 0.662
validation accuracy = 0.166		average validation NDCG = 0.681

epoch 3
average train loss = -0.122057    	average train batch reward = 0.663
validation accuracy = 0.166		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036397    	average train batch reward = 0.627
validation accuracy = 0.081		average validation NDCG = 0.661

epoch 2
average train loss = 0.075540    	average train batch reward = 0.630
validation accuracy = 0.081		average validation NDCG = 0.661

epoch 3
average train loss = 0.115350    	average train batch reward = 0.630
validation accuracy = 0.081		average validation NDCG = 0.661

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.024572    	average train batch reward = 0.631
validation accuracy = 0.126		average validation NDCG = 0.666

epoch 2
average train loss = -0.037270    	average train batch reward = 0.632
validation accuracy = 0.126		average validation NDCG = 0.666

epoch 3
average train loss = -0.028284    	average train batch reward = 0.631
validation accuracy = 0.126		average validation NDCG = 0.666

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.029850    	average train batch reward = 0.655
validation accuracy = 0.094		average validation NDCG = 0.677

epoch 2
average train loss = 0.053896    	average train batch reward = 0.651
validation accuracy = 0.094		average validation NDCG = 0.677

epoch 3
average train loss = 0.092075    	average train batch reward = 0.653
validation accuracy = 0.094		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.015545    	average train batch reward = 0.638
validation accuracy = 0.105		average validation NDCG = 0.665

epoch 2
average train loss = 0.056650    	average train batch reward = 0.636
validation accuracy = 0.105		average validation NDCG = 0.665

epoch 3
average train loss = 0.067045    	average train batch reward = 0.637
validation accuracy = 0.105		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.037256    	average train batch reward = 0.617
validation accuracy = 0.082		average validation NDCG = 0.660

epoch 2
average train loss = 0.129238    	average train batch reward = 0.619
validation accuracy = 0.082		average validation NDCG = 0.660

epoch 3
average train loss = 0.084874    	average train batch reward = 0.617
validation accuracy = 0.082		average validation NDCG = 0.660

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.026697    	average train batch reward = 0.636
validation accuracy = 0.122		average validation NDCG = 0.663

epoch 2
average train loss = -0.007890    	average train batch reward = 0.636
validation accuracy = 0.122		average validation NDCG = 0.663

epoch 3
average train loss = 0.106494    	average train batch reward = 0.636
validation accuracy = 0.122		average validation NDCG = 0.663

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.045893    	average train batch reward = 0.635
validation accuracy = 0.108		average validation NDCG = 0.669

epoch 2
average train loss = 0.007132    	average train batch reward = 0.634
validation accuracy = 0.108		average validation NDCG = 0.669

epoch 3
average train loss = 0.002469    	average train batch reward = 0.633
validation accuracy = 0.108		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 0.05), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.68852804634210063, 0.68582643197905213, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.108288    	average train batch reward = 0.666
validation accuracy = 0.150		average validation NDCG = 0.690

epoch 2
average train loss = -0.192235    	average train batch reward = 0.675
validation accuracy = 0.162		average validation NDCG = 0.698

epoch 3
average train loss = -0.285024    	average train batch reward = 0.685
validation accuracy = 0.172		average validation NDCG = 0.706

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.70633349591617578, 0.68852804634210063, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.046700    	average train batch reward = 0.619
validation accuracy = 0.092		average validation NDCG = 0.655

epoch 2
average train loss = -0.030326    	average train batch reward = 0.625
validation accuracy = 0.097		average validation NDCG = 0.658

epoch 3
average train loss = -0.083234    	average train batch reward = 0.629
validation accuracy = 0.102		average validation NDCG = 0.662

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-08, 512, 1.0)], which got scores of [0.70633349591617578, 0.68852804634210063, 0.68134299795443787]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.013927    	average train batch reward = 0.641
validation accuracy = 0.123		average validation NDCG = 0.670

epoch 2
average train loss = -0.052868    	average train batch reward = 0.648
validation accuracy = 0.127		average validation NDCG = 0.676

epoch 3
average train loss = -0.208156    	average train batch reward = 0.656
validation accuracy = 0.132		average validation NDCG = 0.686

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-08, 512, 0.5), (9.9999999999999995e-07, 50, 0.2)], which got scores of [0.70633349591617578, 0.68852804634210063, 0.68572778910233922]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.150843    	average train batch reward = 0.655
validation accuracy = 0.096		average validation NDCG = 0.683

epoch 2
average train loss = -0.134656    	average train batch reward = 0.659
validation accuracy = 0.101		average validation NDCG = 0.687

epoch 3
average train loss = -0.218994    	average train batch reward = 0.666
validation accuracy = 0.106		average validation NDCG = 0.692

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 50, 0.5), (9.9999999999999995e-08, 512, 0.5)], which got scores of [0.70633349591617578, 0.69218058818513162, 0.68852804634210063]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.036315    	average train batch reward = 0.633
validation accuracy = 0.090		average validation NDCG = 0.671

epoch 2
average train loss = -0.026165    	average train batch reward = 0.643
validation accuracy = 0.094		average validation NDCG = 0.676

epoch 3
average train loss = -0.050717    	average train batch reward = 0.647
validation accuracy = 0.101		average validation NDCG = 0.681

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 50, 0.5), (9.9999999999999995e-08, 512, 0.5)], which got scores of [0.70633349591617578, 0.69218058818513162, 0.68852804634210063]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.088336    	average train batch reward = 0.640
validation accuracy = 0.114		average validation NDCG = 0.671

epoch 2
average train loss = -0.120872    	average train batch reward = 0.647
validation accuracy = 0.117		average validation NDCG = 0.677

epoch 3
average train loss = -0.222388    	average train batch reward = 0.654
validation accuracy = 0.119		average validation NDCG = 0.684

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 50, 0.5), (9.9999999999999995e-08, 512, 0.5)], which got scores of [0.70633349591617578, 0.69218058818513162, 0.68852804634210063]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.066702    	average train batch reward = 0.662
validation accuracy = 0.112		average validation NDCG = 0.689

epoch 2
average train loss = -0.170302    	average train batch reward = 0.667
validation accuracy = 0.114		average validation NDCG = 0.691

epoch 3
average train loss = -0.127374    	average train batch reward = 0.670
validation accuracy = 0.116		average validation NDCG = 0.693

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.0), (9.9999999999999995e-07, 50, 0.5)], which got scores of [0.70633349591617578, 0.6931649401228156, 0.69218058818513162]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.107426    	average train batch reward = 0.651
validation accuracy = 0.135		average validation NDCG = 0.688

epoch 2
average train loss = -0.064381    	average train batch reward = 0.656
validation accuracy = 0.142		average validation NDCG = 0.690

epoch 3
average train loss = -0.086861    	average train batch reward = 0.658
validation accuracy = 0.146		average validation NDCG = 0.692

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.0), (9.9999999999999995e-07, 512, 0.05)], which got scores of [0.70633349591617578, 0.6931649401228156, 0.69246773722030186]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.209845    	average train batch reward = 0.667
validation accuracy = 0.089		average validation NDCG = 0.692

epoch 2
average train loss = -0.135000    	average train batch reward = 0.671
validation accuracy = 0.089		average validation NDCG = 0.695

epoch 3
average train loss = -0.164404    	average train batch reward = 0.672
validation accuracy = 0.090		average validation NDCG = 0.698

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.6931649401228156]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.044724    	average train batch reward = 0.646
validation accuracy = 0.099		average validation NDCG = 0.670

epoch 2
average train loss = -0.044065    	average train batch reward = 0.649
validation accuracy = 0.103		average validation NDCG = 0.672

epoch 3
average train loss = 0.040030    	average train batch reward = 0.651
validation accuracy = 0.105		average validation NDCG = 0.674

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.6931649401228156]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.073967    	average train batch reward = 0.629
validation accuracy = 0.102		average validation NDCG = 0.665

epoch 2
average train loss = -0.039555    	average train batch reward = 0.632
validation accuracy = 0.108		average validation NDCG = 0.667

epoch 3
average train loss = -0.116605    	average train batch reward = 0.633
validation accuracy = 0.118		average validation NDCG = 0.669

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.6931649401228156]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.013422    	average train batch reward = 0.647
validation accuracy = 0.114		average validation NDCG = 0.671

epoch 2
average train loss = -0.021132    	average train batch reward = 0.651
validation accuracy = 0.118		average validation NDCG = 0.673

epoch 3
average train loss = -0.038107    	average train batch reward = 0.653
validation accuracy = 0.123		average validation NDCG = 0.675

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 512, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.6931649401228156]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.193693    	average train batch reward = 0.666
validation accuracy = 0.156		average validation NDCG = 0.693

epoch 2
average train loss = -0.238304    	average train batch reward = 0.665
validation accuracy = 0.159		average validation NDCG = 0.693

epoch 3
average train loss = -0.175466    	average train batch reward = 0.666
validation accuracy = 0.160		average validation NDCG = 0.694

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.103359    	average train batch reward = 0.641
validation accuracy = 0.099		average validation NDCG = 0.678

epoch 2
average train loss = 0.133344    	average train batch reward = 0.643
validation accuracy = 0.099		average validation NDCG = 0.678

epoch 3
average train loss = 0.122040    	average train batch reward = 0.644
validation accuracy = 0.099		average validation NDCG = 0.679

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.021770    	average train batch reward = 0.649
validation accuracy = 0.099		average validation NDCG = 0.678

epoch 2
average train loss = -0.010935    	average train batch reward = 0.649
validation accuracy = 0.099		average validation NDCG = 0.678

epoch 3
average train loss = -0.088276    	average train batch reward = 0.653
validation accuracy = 0.099		average validation NDCG = 0.678

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.017599    	average train batch reward = 0.633
validation accuracy = 0.080		average validation NDCG = 0.664

epoch 2
average train loss = 0.004079    	average train batch reward = 0.634
validation accuracy = 0.080		average validation NDCG = 0.665

epoch 3
average train loss = 0.016690    	average train batch reward = 0.635
validation accuracy = 0.080		average validation NDCG = 0.665

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.015459    	average train batch reward = 0.611
validation accuracy = 0.099		average validation NDCG = 0.651

epoch 2
average train loss = 0.017753    	average train batch reward = 0.613
validation accuracy = 0.100		average validation NDCG = 0.651

epoch 3
average train loss = -0.003781    	average train batch reward = 0.614
validation accuracy = 0.101		average validation NDCG = 0.651

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000001
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.035931    	average train batch reward = 0.651
validation accuracy = 0.115		average validation NDCG = 0.677

epoch 2
average train loss = 0.030205    	average train batch reward = 0.654
validation accuracy = 0.115		average validation NDCG = 0.677

epoch 3
average train loss = 0.028856    	average train batch reward = 0.653
validation accuracy = 0.115		average validation NDCG = 0.677

========
Currently the best setups are [(9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 512, 0.2), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.70633349591617578, 0.69800791337858958, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.339823    	average train batch reward = 0.658
validation accuracy = 0.229		average validation NDCG = 0.722

epoch 2
average train loss = -1.155009    	average train batch reward = 0.729
validation accuracy = 0.294		average validation NDCG = 0.788

epoch 3
average train loss = -2.283805    	average train batch reward = 0.784
validation accuracy = 0.369		average validation NDCG = 0.834

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (9.9999999999999995e-07, 50, 0.0), (9.9999999999999995e-07, 5012, 0.0)], which got scores of [0.83382088014002154, 0.70633349591617578, 0.69371618535809054]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.363702    	average train batch reward = 0.671
validation accuracy = 0.251		average validation NDCG = 0.732

epoch 2
average train loss = -1.134432    	average train batch reward = 0.739
validation accuracy = 0.308		average validation NDCG = 0.796

epoch 3
average train loss = -1.949471    	average train batch reward = 0.785
validation accuracy = 0.359		average validation NDCG = 0.834

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.05), (9.9999999999999995e-07, 50, 0.0)], which got scores of [0.83382088014002154, 0.83370545089533876, 0.70633349591617578]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.211942    	average train batch reward = 0.643
validation accuracy = 0.164		average validation NDCG = 0.717

epoch 2
average train loss = -1.288914    	average train batch reward = 0.719
validation accuracy = 0.278		average validation NDCG = 0.783

epoch 3
average train loss = -2.250545    	average train batch reward = 0.765
validation accuracy = 0.338		average validation NDCG = 0.809

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.2)], which got scores of [0.83382088014002154, 0.83370545089533876, 0.80942578741386872]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.257797    	average train batch reward = 0.658
validation accuracy = 0.176		average validation NDCG = 0.719

epoch 2
average train loss = -1.035124    	average train batch reward = 0.726
validation accuracy = 0.269		average validation NDCG = 0.790

epoch 3
average train loss = -1.945967    	average train batch reward = 0.780
validation accuracy = 0.343		average validation NDCG = 0.826

========
Currently the best setups are [(1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.05), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.83382088014002154, 0.83370545089533876, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.384971    	average train batch reward = 0.682
validation accuracy = 0.245		average validation NDCG = 0.756

epoch 2
average train loss = -1.365928    	average train batch reward = 0.757
validation accuracy = 0.359		average validation NDCG = 0.816

epoch 3
average train loss = -2.187026    	average train batch reward = 0.805
validation accuracy = 0.444		average validation NDCG = 0.856

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.473257    	average train batch reward = 0.655
validation accuracy = 0.202		average validation NDCG = 0.720

epoch 2
average train loss = -1.362810    	average train batch reward = 0.736
validation accuracy = 0.375		average validation NDCG = 0.777

epoch 3
average train loss = -2.110704    	average train batch reward = 0.782
validation accuracy = 0.446		average validation NDCG = 0.820

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.042951    	average train batch reward = 0.627
validation accuracy = 0.103		average validation NDCG = 0.676

epoch 2
average train loss = -0.250263    	average train batch reward = 0.651
validation accuracy = 0.111		average validation NDCG = 0.697

epoch 3
average train loss = -0.479117    	average train batch reward = 0.676
validation accuracy = 0.125		average validation NDCG = 0.719

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.137900    	average train batch reward = 0.659
validation accuracy = 0.117		average validation NDCG = 0.696

epoch 2
average train loss = -0.281606    	average train batch reward = 0.681
validation accuracy = 0.144		average validation NDCG = 0.716

epoch 3
average train loss = -0.412283    	average train batch reward = 0.703
validation accuracy = 0.187		average validation NDCG = 0.736

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.131682    	average train batch reward = 0.650
validation accuracy = 0.153		average validation NDCG = 0.698

epoch 2
average train loss = -0.370443    	average train batch reward = 0.675
validation accuracy = 0.190		average validation NDCG = 0.724

epoch 3
average train loss = -0.700264    	average train batch reward = 0.701
validation accuracy = 0.215		average validation NDCG = 0.748

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.171800    	average train batch reward = 0.643
validation accuracy = 0.117		average validation NDCG = 0.691

epoch 2
average train loss = -0.290000    	average train batch reward = 0.667
validation accuracy = 0.149		average validation NDCG = 0.712

epoch 3
average train loss = -0.615624    	average train batch reward = 0.695
validation accuracy = 0.179		average validation NDCG = 0.744

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.115693    	average train batch reward = 0.670
validation accuracy = 0.155		average validation NDCG = 0.727

epoch 2
average train loss = -0.505442    	average train batch reward = 0.705
validation accuracy = 0.195		average validation NDCG = 0.746

epoch 3
average train loss = -0.703838    	average train batch reward = 0.726
validation accuracy = 0.235		average validation NDCG = 0.766

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.047116    	average train batch reward = 0.655
validation accuracy = 0.111		average validation NDCG = 0.688

epoch 2
average train loss = -0.177125    	average train batch reward = 0.673
validation accuracy = 0.146		average validation NDCG = 0.704

epoch 3
average train loss = -0.390935    	average train batch reward = 0.692
validation accuracy = 0.190		average validation NDCG = 0.724

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011744    	average train batch reward = 0.664
validation accuracy = 0.112		average validation NDCG = 0.681

epoch 2
average train loss = 0.031430    	average train batch reward = 0.671
validation accuracy = 0.115		average validation NDCG = 0.686

epoch 3
average train loss = -0.090871    	average train batch reward = 0.679
validation accuracy = 0.117		average validation NDCG = 0.693

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.006975    	average train batch reward = 0.653
validation accuracy = 0.092		average validation NDCG = 0.687

epoch 2
average train loss = -0.079462    	average train batch reward = 0.659
validation accuracy = 0.100		average validation NDCG = 0.691

epoch 3
average train loss = -0.056558    	average train batch reward = 0.667
validation accuracy = 0.111		average validation NDCG = 0.697

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.051769    	average train batch reward = 0.650
validation accuracy = 0.093		average validation NDCG = 0.685

epoch 2
average train loss = 0.043966    	average train batch reward = 0.654
validation accuracy = 0.099		average validation NDCG = 0.689

epoch 3
average train loss = -0.151730    	average train batch reward = 0.661
validation accuracy = 0.106		average validation NDCG = 0.694

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.036838    	average train batch reward = 0.672
validation accuracy = 0.129		average validation NDCG = 0.698

epoch 2
average train loss = -0.122278    	average train batch reward = 0.680
validation accuracy = 0.134		average validation NDCG = 0.705

epoch 3
average train loss = -0.102109    	average train batch reward = 0.686
validation accuracy = 0.141		average validation NDCG = 0.712

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = 0.022278    	average train batch reward = 0.642
validation accuracy = 0.082		average validation NDCG = 0.677

epoch 2
average train loss = 0.026990    	average train batch reward = 0.649
validation accuracy = 0.094		average validation NDCG = 0.682

epoch 3
average train loss = -0.030782    	average train batch reward = 0.655
validation accuracy = 0.106		average validation NDCG = 0.688

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000010
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.011265    	average train batch reward = 0.638
validation accuracy = 0.093		average validation NDCG = 0.678

epoch 2
average train loss = -0.064144    	average train batch reward = 0.644
validation accuracy = 0.104		average validation NDCG = 0.684

epoch 3
average train loss = -0.144306    	average train batch reward = 0.651
validation accuracy = 0.113		average validation NDCG = 0.690

========
Currently the best setups are [(1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.85556135744537476, 0.83382088014002154, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4.306931    	average train batch reward = 0.796
validation accuracy = 0.417		average validation NDCG = 0.857

epoch 2
average train loss = -11.927614    	average train batch reward = 0.835
validation accuracy = 0.485		average validation NDCG = 0.870

epoch 3
average train loss = -24.559849    	average train batch reward = 0.837
validation accuracy = 0.438		average validation NDCG = 0.867

========
Currently the best setups are [(0.0001, 50, 0.0), (1.0000000000000001e-05, 50, 1.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.86977319819413823, 0.85556135744537476, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4.248285    	average train batch reward = 0.810
validation accuracy = 0.553		average validation NDCG = 0.908

epoch 2
average train loss = -11.678100    	average train batch reward = 0.878
validation accuracy = 0.536		average validation NDCG = 0.920

epoch 3
average train loss = -17.881989    	average train batch reward = 0.884
validation accuracy = 0.555		average validation NDCG = 0.924

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 0.0), (1.0000000000000001e-05, 50, 0.5)], which got scores of [0.92367236400430563, 0.86977319819413823, 0.82644657972309654]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.395761    	average train batch reward = 0.795
validation accuracy = 0.481		average validation NDCG = 0.885

epoch 2
average train loss = -10.447138    	average train batch reward = 0.851
validation accuracy = 0.507		average validation NDCG = 0.897

epoch 3
average train loss = -18.236652    	average train batch reward = 0.855
validation accuracy = 0.462		average validation NDCG = 0.902

========
Currently the best setups are [(0.0001, 50, 0.05), (0.0001, 50, 0.2), (0.0001, 50, 0.0)], which got scores of [0.92367236400430563, 0.90157584597857954, 0.86977319819413823]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.564130    	average train batch reward = 0.788
validation accuracy = 0.514		average validation NDCG = 0.900

epoch 2
average train loss = -10.036319    	average train batch reward = 0.880
validation accuracy = 0.583		average validation NDCG = 0.923

epoch 3
average train loss = -18.534588    	average train batch reward = 0.892
validation accuracy = 0.606		average validation NDCG = 0.928

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 0.0)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.86977319819413823]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4.776343    	average train batch reward = 0.768
validation accuracy = 0.379		average validation NDCG = 0.840

epoch 2
average train loss = -15.730275    	average train batch reward = 0.811
validation accuracy = 0.434		average validation NDCG = 0.854

epoch 3
average train loss = -31.473320    	average train batch reward = 0.820
validation accuracy = 0.433		average validation NDCG = 0.862

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 0.0)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.86977319819413823]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3.365555    	average train batch reward = 0.776
validation accuracy = 0.403		average validation NDCG = 0.845

epoch 2
average train loss = -10.963670    	average train batch reward = 0.818
validation accuracy = 0.473		average validation NDCG = 0.863

epoch 3
average train loss = -19.763435    	average train batch reward = 0.833
validation accuracy = 0.467		average validation NDCG = 0.870

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 50, 1.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.87021880561365827]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.673326    	average train batch reward = 0.706
validation accuracy = 0.332		average validation NDCG = 0.812

epoch 2
average train loss = -2.588264    	average train batch reward = 0.814
validation accuracy = 0.477		average validation NDCG = 0.865

epoch 3
average train loss = -4.302800    	average train batch reward = 0.843
validation accuracy = 0.511		average validation NDCG = 0.886

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.0)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.88570018050541166]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.023927    	average train batch reward = 0.750
validation accuracy = 0.443		average validation NDCG = 0.845

epoch 2
average train loss = -3.215733    	average train batch reward = 0.853
validation accuracy = 0.596		average validation NDCG = 0.897

epoch 3
average train loss = -4.860507    	average train batch reward = 0.875
validation accuracy = 0.621		average validation NDCG = 0.916

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.05)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.9161366087893722]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.166298    	average train batch reward = 0.703
validation accuracy = 0.320		average validation NDCG = 0.793

epoch 2
average train loss = -4.586004    	average train batch reward = 0.781
validation accuracy = 0.378		average validation NDCG = 0.827

epoch 3
average train loss = -6.892304    	average train batch reward = 0.795
validation accuracy = 0.391		average validation NDCG = 0.838

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.05)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.9161366087893722]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.100016    	average train batch reward = 0.728
validation accuracy = 0.394		average validation NDCG = 0.832

epoch 2
average train loss = -3.145036    	average train batch reward = 0.837
validation accuracy = 0.474		average validation NDCG = 0.896

epoch 3
average train loss = -4.849453    	average train batch reward = 0.872
validation accuracy = 0.530		average validation NDCG = 0.917

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.302337    	average train batch reward = 0.745
validation accuracy = 0.418		average validation NDCG = 0.824

epoch 2
average train loss = -3.791659    	average train batch reward = 0.808
validation accuracy = 0.429		average validation NDCG = 0.854

epoch 3
average train loss = -5.893460    	average train batch reward = 0.823
validation accuracy = 0.469		average validation NDCG = 0.863

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.988144    	average train batch reward = 0.727
validation accuracy = 0.305		average validation NDCG = 0.811

epoch 2
average train loss = -3.246686    	average train batch reward = 0.813
validation accuracy = 0.406		average validation NDCG = 0.873

epoch 3
average train loss = -5.006734    	average train batch reward = 0.840
validation accuracy = 0.440		average validation NDCG = 0.888

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.034129    	average train batch reward = 0.632
validation accuracy = 0.130		average validation NDCG = 0.691

epoch 2
average train loss = -0.512459    	average train batch reward = 0.682
validation accuracy = 0.240		average validation NDCG = 0.740

epoch 3
average train loss = -0.859019    	average train batch reward = 0.724
validation accuracy = 0.329		average validation NDCG = 0.776

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.221090    	average train batch reward = 0.665
validation accuracy = 0.141		average validation NDCG = 0.713

epoch 2
average train loss = -0.921463    	average train batch reward = 0.707
validation accuracy = 0.173		average validation NDCG = 0.751

epoch 3
average train loss = -1.603886    	average train batch reward = 0.740
validation accuracy = 0.246		average validation NDCG = 0.782

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.194513    	average train batch reward = 0.659
validation accuracy = 0.193		average validation NDCG = 0.701

epoch 2
average train loss = -0.604937    	average train batch reward = 0.707
validation accuracy = 0.290		average validation NDCG = 0.743

epoch 3
average train loss = -1.193609    	average train batch reward = 0.745
validation accuracy = 0.354		average validation NDCG = 0.770

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.230434    	average train batch reward = 0.669
validation accuracy = 0.215		average validation NDCG = 0.718

epoch 2
average train loss = -0.609663    	average train batch reward = 0.727
validation accuracy = 0.293		average validation NDCG = 0.771

epoch 3
average train loss = -1.074711    	average train batch reward = 0.770
validation accuracy = 0.383		average validation NDCG = 0.812

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.153386    	average train batch reward = 0.653
validation accuracy = 0.151		average validation NDCG = 0.694

epoch 2
average train loss = -0.701172    	average train batch reward = 0.702
validation accuracy = 0.220		average validation NDCG = 0.742

epoch 3
average train loss = -1.270909    	average train batch reward = 0.744
validation accuracy = 0.282		average validation NDCG = 0.781

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.000100
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -0.086096    	average train batch reward = 0.654
validation accuracy = 0.159		average validation NDCG = 0.714

epoch 2
average train loss = -0.449593    	average train batch reward = 0.707
validation accuracy = 0.228		average validation NDCG = 0.777

epoch 3
average train loss = -1.230932    	average train batch reward = 0.756
validation accuracy = 0.335		average validation NDCG = 0.819

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -99.174934    	average train batch reward = 0.755
validation accuracy = 0.334		average validation NDCG = 0.825

epoch 2
average train loss = -559.175537    	average train batch reward = 0.809
validation accuracy = 0.350		average validation NDCG = 0.852

epoch 3
average train loss = -1509.576050    	average train batch reward = 0.820
validation accuracy = 0.368		average validation NDCG = 0.861

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -135.751678    	average train batch reward = 0.757
validation accuracy = 0.283		average validation NDCG = 0.808

epoch 2
average train loss = -1209.168213    	average train batch reward = 0.777
validation accuracy = 0.245		average validation NDCG = 0.808

epoch 3
average train loss = -3226.237549    	average train batch reward = 0.776
validation accuracy = 0.248		average validation NDCG = 0.808

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -266.645935    	average train batch reward = 0.755
validation accuracy = 0.240		average validation NDCG = 0.790

epoch 2
average train loss = -1642.060425    	average train batch reward = 0.763
validation accuracy = 0.233		average validation NDCG = 0.803

epoch 3
average train loss = -4080.358887    	average train batch reward = 0.768
validation accuracy = 0.243		average validation NDCG = 0.797

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -133.548782    	average train batch reward = 0.782
validation accuracy = 0.308		average validation NDCG = 0.838

epoch 2
average train loss = -920.937012    	average train batch reward = 0.802
validation accuracy = 0.312		average validation NDCG = 0.835

epoch 3
average train loss = -2553.928223    	average train batch reward = 0.804
validation accuracy = 0.240		average validation NDCG = 0.835

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -210.913361    	average train batch reward = 0.689
validation accuracy = 0.166		average validation NDCG = 0.732

epoch 2
average train loss = -1277.472778    	average train batch reward = 0.695
validation accuracy = 0.138		average validation NDCG = 0.732

epoch 3
average train loss = -4437.444336    	average train batch reward = 0.696
validation accuracy = 0.145		average validation NDCG = 0.732

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -86.084984    	average train batch reward = 0.789
validation accuracy = 0.271		average validation NDCG = 0.839

epoch 2
average train loss = -736.885498    	average train batch reward = 0.804
validation accuracy = 0.301		average validation NDCG = 0.836

epoch 3
average train loss = -1890.947266    	average train batch reward = 0.802
validation accuracy = 0.308		average validation NDCG = 0.840

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -9.986746    	average train batch reward = 0.802
validation accuracy = 0.567		average validation NDCG = 0.897

epoch 2
average train loss = -42.353081    	average train batch reward = 0.862
validation accuracy = 0.572		average validation NDCG = 0.903

epoch 3
average train loss = -93.546883    	average train batch reward = 0.862
validation accuracy = 0.551		average validation NDCG = 0.903

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -14.399619    	average train batch reward = 0.791
validation accuracy = 0.411		average validation NDCG = 0.870

epoch 2
average train loss = -63.432106    	average train batch reward = 0.833
validation accuracy = 0.331		average validation NDCG = 0.877

epoch 3
average train loss = -168.105881    	average train batch reward = 0.835
validation accuracy = 0.384		average validation NDCG = 0.869

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -12.188136    	average train batch reward = 0.729
validation accuracy = 0.319		average validation NDCG = 0.782

epoch 2
average train loss = -61.381374    	average train batch reward = 0.745
validation accuracy = 0.290		average validation NDCG = 0.784

epoch 3
average train loss = -160.533981    	average train batch reward = 0.745
validation accuracy = 0.276		average validation NDCG = 0.783

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -11.951027    	average train batch reward = 0.761
validation accuracy = 0.395		average validation NDCG = 0.830

epoch 2
average train loss = -60.395798    	average train batch reward = 0.802
validation accuracy = 0.418		average validation NDCG = 0.838

epoch 3
average train loss = -141.216736    	average train batch reward = 0.805
validation accuracy = 0.413		average validation NDCG = 0.840

========
Currently the best setups are [(0.0001, 50, 0.5), (0.0001, 50, 0.05), (0.0001, 512, 0.5)], which got scores of [0.92811749220851103, 0.92367236400430563, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -10.789290    	average train batch reward = 0.812
validation accuracy = 0.470		average validation NDCG = 0.909

epoch 2
average train loss = -38.471539    	average train batch reward = 0.880
validation accuracy = 0.481		average validation NDCG = 0.927

epoch 3
average train loss = -84.231407    	average train batch reward = 0.892
validation accuracy = 0.435		average validation NDCG = 0.931

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -11.956913    	average train batch reward = 0.813
validation accuracy = 0.528		average validation NDCG = 0.891

epoch 2
average train loss = -49.250397    	average train batch reward = 0.862
validation accuracy = 0.480		average validation NDCG = 0.900

epoch 3
average train loss = -118.316360    	average train batch reward = 0.867
validation accuracy = 0.430		average validation NDCG = 0.903

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.570490    	average train batch reward = 0.772
validation accuracy = 0.521		average validation NDCG = 0.862

epoch 2
average train loss = -5.264307    	average train batch reward = 0.842
validation accuracy = 0.582		average validation NDCG = 0.892

epoch 3
average train loss = -10.806566    	average train batch reward = 0.864
validation accuracy = 0.608		average validation NDCG = 0.901

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.061216    	average train batch reward = 0.737
validation accuracy = 0.432		average validation NDCG = 0.837

epoch 2
average train loss = -5.474318    	average train batch reward = 0.826
validation accuracy = 0.534		average validation NDCG = 0.865

epoch 3
average train loss = -10.859751    	average train batch reward = 0.837
validation accuracy = 0.541		average validation NDCG = 0.876

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.523667    	average train batch reward = 0.700
validation accuracy = 0.378		average validation NDCG = 0.814

epoch 2
average train loss = -7.309477    	average train batch reward = 0.807
validation accuracy = 0.447		average validation NDCG = 0.866

epoch 3
average train loss = -12.949696    	average train batch reward = 0.849
validation accuracy = 0.523		average validation NDCG = 0.890

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.573329    	average train batch reward = 0.769
validation accuracy = 0.494		average validation NDCG = 0.867

epoch 2
average train loss = -5.671791    	average train batch reward = 0.853
validation accuracy = 0.522		average validation NDCG = 0.888

epoch 3
average train loss = -10.151449    	average train batch reward = 0.863
validation accuracy = 0.532		average validation NDCG = 0.898

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.495734    	average train batch reward = 0.746
validation accuracy = 0.414		average validation NDCG = 0.864

epoch 2
average train loss = -5.501823    	average train batch reward = 0.848
validation accuracy = 0.505		average validation NDCG = 0.890

epoch 3
average train loss = -9.989501    	average train batch reward = 0.865
validation accuracy = 0.548		average validation NDCG = 0.899

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.001000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1.691747    	average train batch reward = 0.751
validation accuracy = 0.382		average validation NDCG = 0.842

epoch 2
average train loss = -5.517830    	average train batch reward = 0.819
validation accuracy = 0.507		average validation NDCG = 0.863

epoch 3
average train loss = -10.927316    	average train batch reward = 0.834
validation accuracy = 0.563		average validation NDCG = 0.871

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -8753.093750    	average train batch reward = 0.750
validation accuracy = 0.247		average validation NDCG = 0.789

epoch 2
average train loss = -64088.457031    	average train batch reward = 0.760
validation accuracy = 0.304		average validation NDCG = 0.790

epoch 3
average train loss = -169337.031250    	average train batch reward = 0.761
validation accuracy = 0.312		average validation NDCG = 0.789

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -20446.478516    	average train batch reward = 0.710
validation accuracy = 0.145		average validation NDCG = 0.757

epoch 2
average train loss = -169315.765625    	average train batch reward = 0.720
validation accuracy = 0.145		average validation NDCG = 0.753

epoch 3
average train loss = -429052.031250    	average train batch reward = 0.723
validation accuracy = 0.145		average validation NDCG = 0.757

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -12240.422852    	average train batch reward = 0.760
validation accuracy = 0.319		average validation NDCG = 0.796

epoch 2
average train loss = -92329.718750    	average train batch reward = 0.774
validation accuracy = 0.245		average validation NDCG = 0.798

epoch 3
average train loss = -205083.859375    	average train batch reward = 0.777
validation accuracy = 0.259		average validation NDCG = 0.799

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -10585.834961    	average train batch reward = 0.713
validation accuracy = 0.175		average validation NDCG = 0.744

epoch 2
average train loss = -71936.914062    	average train batch reward = 0.722
validation accuracy = 0.222		average validation NDCG = 0.749

epoch 3
average train loss = -179128.296875    	average train batch reward = 0.728
validation accuracy = 0.224		average validation NDCG = 0.755

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -14235.931641    	average train batch reward = 0.728
validation accuracy = 0.243		average validation NDCG = 0.758

epoch 2
average train loss = -116621.601562    	average train batch reward = 0.743
validation accuracy = 0.237		average validation NDCG = 0.766

epoch 3
average train loss = -311507.531250    	average train batch reward = 0.746
validation accuracy = 0.252		average validation NDCG = 0.767

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3617.479004    	average train batch reward = 0.706
validation accuracy = 0.198		average validation NDCG = 0.739

epoch 2
average train loss = -44897.976562    	average train batch reward = 0.713
validation accuracy = 0.198		average validation NDCG = 0.739

epoch 3
average train loss = -112869.898438    	average train batch reward = 0.715
validation accuracy = 0.200		average validation NDCG = 0.739

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -421.667145    	average train batch reward = 0.728
validation accuracy = 0.204		average validation NDCG = 0.761

epoch 2
average train loss = -5474.826660    	average train batch reward = 0.733
validation accuracy = 0.182		average validation NDCG = 0.757

epoch 3
average train loss = -14502.114258    	average train batch reward = 0.733
validation accuracy = 0.191		average validation NDCG = 0.760

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -724.304199    	average train batch reward = 0.743
validation accuracy = 0.241		average validation NDCG = 0.783

epoch 2
average train loss = -7096.647461    	average train batch reward = 0.748
validation accuracy = 0.259		average validation NDCG = 0.778

epoch 3
average train loss = -21600.333984    	average train batch reward = 0.747
validation accuracy = 0.256		average validation NDCG = 0.780

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -566.938477    	average train batch reward = 0.782
validation accuracy = 0.308		average validation NDCG = 0.837

epoch 2
average train loss = -4847.430176    	average train batch reward = 0.800
validation accuracy = 0.307		average validation NDCG = 0.842

epoch 3
average train loss = -17110.843750    	average train batch reward = 0.805
validation accuracy = 0.302		average validation NDCG = 0.843

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -439.444794    	average train batch reward = 0.806
validation accuracy = 0.412		average validation NDCG = 0.858

epoch 2
average train loss = -3433.147949    	average train batch reward = 0.830
validation accuracy = 0.406		average validation NDCG = 0.849

epoch 3
average train loss = -11458.959961    	average train batch reward = 0.833
validation accuracy = 0.346		average validation NDCG = 0.861

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -390.410309    	average train batch reward = 0.820
validation accuracy = 0.390		average validation NDCG = 0.870

epoch 2
average train loss = -3488.592529    	average train batch reward = 0.839
validation accuracy = 0.381		average validation NDCG = 0.866

epoch 3
average train loss = -11614.278320    	average train batch reward = 0.838
validation accuracy = 0.344		average validation NDCG = 0.869

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -665.697388    	average train batch reward = 0.718
validation accuracy = 0.260		average validation NDCG = 0.750

epoch 2
average train loss = -6880.030273    	average train batch reward = 0.716
validation accuracy = 0.251		average validation NDCG = 0.756

epoch 3
average train loss = -17923.701172    	average train batch reward = 0.720
validation accuracy = 0.265		average validation NDCG = 0.757

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -13.540820    	average train batch reward = 0.743
validation accuracy = 0.410		average validation NDCG = 0.828

epoch 2
average train loss = -105.223854    	average train batch reward = 0.802
validation accuracy = 0.453		average validation NDCG = 0.835

epoch 3
average train loss = -296.853241    	average train batch reward = 0.806
validation accuracy = 0.499		average validation NDCG = 0.833

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.0001, 512, 0.5)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.91712080284004571]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -18.913971    	average train batch reward = 0.803
validation accuracy = 0.488		average validation NDCG = 0.918

epoch 2
average train loss = -92.201706    	average train batch reward = 0.885
validation accuracy = 0.514		average validation NDCG = 0.924

epoch 3
average train loss = -223.617294    	average train batch reward = 0.891
validation accuracy = 0.539		average validation NDCG = 0.926

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -15.247601    	average train batch reward = 0.727
validation accuracy = 0.400		average validation NDCG = 0.804

epoch 2
average train loss = -109.680054    	average train batch reward = 0.778
validation accuracy = 0.423		average validation NDCG = 0.807

epoch 3
average train loss = -351.320984    	average train batch reward = 0.781
validation accuracy = 0.438		average validation NDCG = 0.806

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -16.009533    	average train batch reward = 0.790
validation accuracy = 0.576		average validation NDCG = 0.881

epoch 2
average train loss = -101.145706    	average train batch reward = 0.854
validation accuracy = 0.526		average validation NDCG = 0.892

epoch 3
average train loss = -258.895874    	average train batch reward = 0.861
validation accuracy = 0.534		average validation NDCG = 0.892

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -12.220524    	average train batch reward = 0.790
validation accuracy = 0.522		average validation NDCG = 0.876

epoch 2
average train loss = -82.607857    	average train batch reward = 0.847
validation accuracy = 0.585		average validation NDCG = 0.881

epoch 3
average train loss = -210.986343    	average train batch reward = 0.854
validation accuracy = 0.517		average validation NDCG = 0.888

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.010000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -17.724415    	average train batch reward = 0.785
validation accuracy = 0.399		average validation NDCG = 0.895

epoch 2
average train loss = -97.771263    	average train batch reward = 0.873
validation accuracy = 0.419		average validation NDCG = 0.919

epoch 3
average train loss = -248.142670    	average train batch reward = 0.878
validation accuracy = 0.486		average validation NDCG = 0.918

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -517402.625000    	average train batch reward = 0.706
validation accuracy = 0.203		average validation NDCG = 0.741

epoch 2
average train loss = -4984331.000000    	average train batch reward = 0.715
validation accuracy = 0.202		average validation NDCG = 0.739

epoch 3
average train loss = -15480320.000000    	average train batch reward = 0.715
validation accuracy = 0.203		average validation NDCG = 0.739

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -390121.562500    	average train batch reward = 0.682
validation accuracy = 0.169		average validation NDCG = 0.720

epoch 2
average train loss = -2776017.500000    	average train batch reward = 0.689
validation accuracy = 0.175		average validation NDCG = 0.724

epoch 3
average train loss = -5476839.500000    	average train batch reward = 0.687
validation accuracy = 0.176		average validation NDCG = 0.724

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -782849.437500    	average train batch reward = 0.726
validation accuracy = 0.295		average validation NDCG = 0.766

epoch 2
average train loss = -5912646.500000    	average train batch reward = 0.740
validation accuracy = 0.290		average validation NDCG = 0.763

epoch 3
average train loss = -15326843.000000    	average train batch reward = 0.742
validation accuracy = 0.292		average validation NDCG = 0.763

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1108265.000000    	average train batch reward = 0.726
validation accuracy = 0.272		average validation NDCG = 0.760

epoch 2
average train loss = -8572850.000000    	average train batch reward = 0.732
validation accuracy = 0.285		average validation NDCG = 0.761

epoch 3
average train loss = -19335896.000000    	average train batch reward = 0.733
validation accuracy = 0.286		average validation NDCG = 0.761

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -579270.875000    	average train batch reward = 0.668
validation accuracy = 0.104		average validation NDCG = 0.700

epoch 2
average train loss = -4857150.000000    	average train batch reward = 0.668
validation accuracy = 0.103		average validation NDCG = 0.701

epoch 3
average train loss = -16994956.000000    	average train batch reward = 0.669
validation accuracy = 0.103		average validation NDCG = 0.701

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -1372763.750000    	average train batch reward = 0.672
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 2
average train loss = -13356777.000000    	average train batch reward = 0.672
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -34772936.000000    	average train batch reward = 0.671
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -77478.531250    	average train batch reward = 0.766
validation accuracy = 0.283		average validation NDCG = 0.807

epoch 2
average train loss = -776024.375000    	average train batch reward = 0.776
validation accuracy = 0.263		average validation NDCG = 0.809

epoch 3
average train loss = -2418901.750000    	average train batch reward = 0.776
validation accuracy = 0.269		average validation NDCG = 0.808

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -44495.296875    	average train batch reward = 0.715
validation accuracy = 0.262		average validation NDCG = 0.759

epoch 2
average train loss = -490314.656250    	average train batch reward = 0.731
validation accuracy = 0.237		average validation NDCG = 0.761

epoch 3
average train loss = -1680717.375000    	average train batch reward = 0.733
validation accuracy = 0.217		average validation NDCG = 0.760

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -32493.177734    	average train batch reward = 0.723
validation accuracy = 0.223		average validation NDCG = 0.776

epoch 2
average train loss = -310230.500000    	average train batch reward = 0.750
validation accuracy = 0.269		average validation NDCG = 0.772

epoch 3
average train loss = -1023203.625000    	average train batch reward = 0.749
validation accuracy = 0.255		average validation NDCG = 0.776

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -33847.843750    	average train batch reward = 0.723
validation accuracy = 0.224		average validation NDCG = 0.765

epoch 2
average train loss = -356970.718750    	average train batch reward = 0.739
validation accuracy = 0.234		average validation NDCG = 0.766

epoch 3
average train loss = -1233551.875000    	average train batch reward = 0.739
validation accuracy = 0.218		average validation NDCG = 0.772

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -86334.312500    	average train batch reward = 0.669
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 2
average train loss = -1140258.000000    	average train batch reward = 0.669
validation accuracy = 0.096		average validation NDCG = 0.703

epoch 3
average train loss = -3201552.500000    	average train batch reward = 0.674
validation accuracy = 0.096		average validation NDCG = 0.703

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -42567.460938    	average train batch reward = 0.717
validation accuracy = 0.206		average validation NDCG = 0.764

epoch 2
average train loss = -452302.781250    	average train batch reward = 0.736
validation accuracy = 0.206		average validation NDCG = 0.764

epoch 3
average train loss = -1403139.500000    	average train batch reward = 0.739
validation accuracy = 0.210		average validation NDCG = 0.769

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -577.197693    	average train batch reward = 0.729
validation accuracy = 0.283		average validation NDCG = 0.823

epoch 2
average train loss = -7746.877930    	average train batch reward = 0.810
validation accuracy = 0.305		average validation NDCG = 0.861

epoch 3
average train loss = -27382.507812    	average train batch reward = 0.820
validation accuracy = 0.300		average validation NDCG = 0.856

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -514.351807    	average train batch reward = 0.720
validation accuracy = 0.230		average validation NDCG = 0.794

epoch 2
average train loss = -6905.666016    	average train batch reward = 0.765
validation accuracy = 0.281		average validation NDCG = 0.804

epoch 3
average train loss = -23939.507812    	average train batch reward = 0.772
validation accuracy = 0.277		average validation NDCG = 0.813

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -485.911163    	average train batch reward = 0.736
validation accuracy = 0.325		average validation NDCG = 0.805

epoch 2
average train loss = -5886.658203    	average train batch reward = 0.786
validation accuracy = 0.333		average validation NDCG = 0.818

epoch 3
average train loss = -24436.607422    	average train batch reward = 0.785
validation accuracy = 0.309		average validation NDCG = 0.813

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -147.865173    	average train batch reward = 0.688
validation accuracy = 0.231		average validation NDCG = 0.764

epoch 2
average train loss = -2708.523438    	average train batch reward = 0.730
validation accuracy = 0.308		average validation NDCG = 0.775

epoch 3
average train loss = -11084.152344    	average train batch reward = 0.737
validation accuracy = 0.337		average validation NDCG = 0.775

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -371.800995    	average train batch reward = 0.719
validation accuracy = 0.286		average validation NDCG = 0.803

epoch 2
average train loss = -5262.966797    	average train batch reward = 0.780
validation accuracy = 0.382		average validation NDCG = 0.832

epoch 3
average train loss = -18781.626953    	average train batch reward = 0.789
validation accuracy = 0.415		average validation NDCG = 0.830

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 0.100000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -350.123016    	average train batch reward = 0.753
validation accuracy = 0.461		average validation NDCG = 0.864

epoch 2
average train loss = -4387.538574    	average train batch reward = 0.834
validation accuracy = 0.493		average validation NDCG = 0.876

epoch 3
average train loss = -15971.218750    	average train batch reward = 0.834
validation accuracy = 0.504		average validation NDCG = 0.873

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -59489208.000000    	average train batch reward = 0.714
validation accuracy = 0.201		average validation NDCG = 0.748

epoch 2
average train loss = -379852640.000000    	average train batch reward = 0.728
validation accuracy = 0.196		average validation NDCG = 0.754

epoch 3
average train loss = -813946496.000000    	average train batch reward = 0.728
validation accuracy = 0.199		average validation NDCG = 0.755

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -226295696.000000    	average train batch reward = 0.710
validation accuracy = 0.131		average validation NDCG = 0.747

epoch 2
average train loss = -1116509696.000000    	average train batch reward = 0.716
validation accuracy = 0.126		average validation NDCG = 0.747

epoch 3
average train loss = -3626846208.000000    	average train batch reward = 0.716
validation accuracy = 0.120		average validation NDCG = 0.747

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -56165780.000000    	average train batch reward = 0.692
validation accuracy = 0.188		average validation NDCG = 0.724

epoch 2
average train loss = -429246976.000000    	average train batch reward = 0.694
validation accuracy = 0.182		average validation NDCG = 0.723

epoch 3
average train loss = -934832064.000000    	average train batch reward = 0.691
validation accuracy = 0.188		average validation NDCG = 0.722

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -28718710.000000    	average train batch reward = 0.665
validation accuracy = 0.118		average validation NDCG = 0.698

epoch 2
average train loss = -235931616.000000    	average train batch reward = 0.668
validation accuracy = 0.120		average validation NDCG = 0.699

epoch 3
average train loss = -441061568.000000    	average train batch reward = 0.667
validation accuracy = 0.131		average validation NDCG = 0.700

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -83463128.000000    	average train batch reward = 0.727
validation accuracy = 0.225		average validation NDCG = 0.764

epoch 2
average train loss = -688906368.000000    	average train batch reward = 0.738
validation accuracy = 0.224		average validation NDCG = 0.767

epoch 3
average train loss = -2069081344.000000    	average train batch reward = 0.740
validation accuracy = 0.214		average validation NDCG = 0.766

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 50
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -18824220.000000    	average train batch reward = 0.663
validation accuracy = 0.093		average validation NDCG = 0.700

epoch 2
average train loss = -169208896.000000    	average train batch reward = 0.665
validation accuracy = 0.093		average validation NDCG = 0.701

epoch 3
average train loss = -451694432.000000    	average train batch reward = 0.666
validation accuracy = 0.094		average validation NDCG = 0.701

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3918246.750000    	average train batch reward = 0.743
validation accuracy = 0.204		average validation NDCG = 0.779

epoch 2
average train loss = -39636204.000000    	average train batch reward = 0.756
validation accuracy = 0.199		average validation NDCG = 0.790

epoch 3
average train loss = -109673568.000000    	average train batch reward = 0.760
validation accuracy = 0.213		average validation NDCG = 0.793

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -7456311.000000    	average train batch reward = 0.738
validation accuracy = 0.313		average validation NDCG = 0.780

epoch 2
average train loss = -71245504.000000    	average train batch reward = 0.747
validation accuracy = 0.287		average validation NDCG = 0.781

epoch 3
average train loss = -215248368.000000    	average train batch reward = 0.749
validation accuracy = 0.268		average validation NDCG = 0.783

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4793836.000000    	average train batch reward = 0.755
validation accuracy = 0.319		average validation NDCG = 0.799

epoch 2
average train loss = -47751648.000000    	average train batch reward = 0.773
validation accuracy = 0.347		average validation NDCG = 0.804

epoch 3
average train loss = -170289600.000000    	average train batch reward = 0.777
validation accuracy = 0.285		average validation NDCG = 0.812

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3075155.500000    	average train batch reward = 0.705
validation accuracy = 0.109		average validation NDCG = 0.752

epoch 2
average train loss = -29795142.000000    	average train batch reward = 0.719
validation accuracy = 0.095		average validation NDCG = 0.752

epoch 3
average train loss = -77047176.000000    	average train batch reward = 0.723
validation accuracy = 0.107		average validation NDCG = 0.753

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -4642567.000000    	average train batch reward = 0.759
validation accuracy = 0.346		average validation NDCG = 0.815

epoch 2
average train loss = -46797684.000000    	average train batch reward = 0.791
validation accuracy = 0.377		average validation NDCG = 0.820

epoch 3
average train loss = -134724528.000000    	average train batch reward = 0.791
validation accuracy = 0.384		average validation NDCG = 0.819

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 512
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -3525112.750000    	average train batch reward = 0.729
validation accuracy = 0.172		average validation NDCG = 0.768

epoch 2
average train loss = -34647492.000000    	average train batch reward = 0.742
validation accuracy = 0.170		average validation NDCG = 0.774

epoch 3
average train loss = -111784728.000000    	average train batch reward = 0.747
validation accuracy = 0.169		average validation NDCG = 0.775

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -27432.574219    	average train batch reward = 0.697
validation accuracy = 0.260		average validation NDCG = 0.750

epoch 2
average train loss = -384176.031250    	average train batch reward = 0.736
validation accuracy = 0.302		average validation NDCG = 0.754

epoch 3
average train loss = -1645960.000000    	average train batch reward = 0.740
validation accuracy = 0.312		average validation NDCG = 0.759

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.050000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -31432.173828    	average train batch reward = 0.686
validation accuracy = 0.233		average validation NDCG = 0.768

epoch 2
average train loss = -391922.718750    	average train batch reward = 0.755
validation accuracy = 0.207		average validation NDCG = 0.785

epoch 3
average train loss = -1477825.750000    	average train batch reward = 0.759
validation accuracy = 0.219		average validation NDCG = 0.791

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.200000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -44071.691406    	average train batch reward = 0.710
validation accuracy = 0.215		average validation NDCG = 0.781

epoch 2
average train loss = -611743.250000    	average train batch reward = 0.757
validation accuracy = 0.211		average validation NDCG = 0.803

epoch 3
average train loss = -2389534.250000    	average train batch reward = 0.765
validation accuracy = 0.224		average validation NDCG = 0.803

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 0.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -20549.320312    	average train batch reward = 0.680
validation accuracy = 0.196		average validation NDCG = 0.730

epoch 2
average train loss = -405613.281250    	average train batch reward = 0.700
validation accuracy = 0.200		average validation NDCG = 0.730

epoch 3
average train loss = -2088702.500000    	average train batch reward = 0.698
validation accuracy = 0.201		average validation NDCG = 0.730

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.000000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -51922.203125    	average train batch reward = 0.728
validation accuracy = 0.306		average validation NDCG = 0.816

epoch 2
average train loss = -712512.750000    	average train batch reward = 0.787
validation accuracy = 0.390		average validation NDCG = 0.822

epoch 3
average train loss = -2549881.250000    	average train batch reward = 0.786
validation accuracy = 0.379		average validation NDCG = 0.818

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
Hyperparameters:
k = 5
Batch size = 5012
Num epochs = 3
Learning rate = 1.000000
Epsilon = 0.000000
Hidden layer dimension = 256
Query function = <function random_from_docs at 0x2b1f18ef20c8>
Reward function = <function ndcg_full at 0x2b1f18ef2140>
Greedy action = <function sample at 0x2b1f11d46758>
Reg strength = 1.500000

Loading dataset.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz

epoch 1
average train loss = -46378.582031    	average train batch reward = 0.746
validation accuracy = 0.441		average validation NDCG = 0.821

epoch 2
average train loss = -719395.437500    	average train batch reward = 0.799
validation accuracy = 0.352		average validation NDCG = 0.827

epoch 3
average train loss = -2445227.000000    	average train batch reward = 0.801
validation accuracy = 0.399		average validation NDCG = 0.827

========
Currently the best setups are [(0.001, 512, 1.0), (0.0001, 50, 0.5), (0.01, 5012, 0.05)], which got scores of [0.93149560724717817, 0.92811749220851103, 0.9263073785293221]
========
2017-06-30 14:42:44
